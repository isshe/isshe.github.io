[{"content":"Valgrind 快速上手 1、介绍 Valgrind 工具集提供了一系列调试和剖析工具，可以帮助我们写出更快更正确的程序。 其中最常用的工具是 Memcheck。可以检测很多 C 或 C++ 程序中导致奔溃或未知行为的内存错误。\n2、准备程序 使用 -g 选项编译程序，使程序包含调试信息（debug info），这样可以让 Memcheck 的错误信息包含详细的行号。 如果可以允许程序变慢，使用 -O0 来编译最好；如果是 -O1 则行号可能有错，不过一般能正常工作，速度相对 -O0 也提升明显；-O2 或以上的优化级别则不建议使用，可能导致 Memcheck 报告未初始化值的错误。\n使用 Valgrind 执行程序 如果程序正常是使用以下方式执行：\nmyprog arg1 arg 则，改为下面的方式：\nvalgrind --leak-check=yes myprog arg1 arg2 这个命令中没有指定 Memcheck，是因为 Memcheck 是默认的工具；--leak-check 选项打开详细的内存泄露检测器。 此时程序可能比平时慢很多（例如 20、30 倍），并且会使用多很多内存。Memcheck 将显示检测到的内存错误或内存泄露信息。\n解释 Memcheck 的输出 // example.c #include \u0026lt;stdlib.h\u0026gt;void f(void) { int* x = malloc(10 * sizeof(int)); x[10] = 0; // problem 1: heap block overrun  // problem 2: memory leak -- x not freed } int main(void) { f(); return 0; } 这是一个有内存泄露和内存错误的程序。\n编译：\ngcc ./example.c -g 执行：\nvalgrind --leak-check=yes ./a.out 内存访问越界 部分输入如下：\n==1765727== Invalid write of size 4 ==1765727== at 0x10916B: f (example.c:5) ==1765727== by 0x109180: main (example.c:11) ==1765727== Address 0x4a4e068 is 0 bytes after a block of size 40 alloc'd ==1765727== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==1765727== by 0x10915E: f (example.c:4) ==1765727== by 0x109180: main (example.c:11) 这部分输出描述了第一个问题：访问越界。索引应该是 0 - 9，实际访问了 10。 输出中：\n 1765727：进程 ID。 Invalid write of size 4：第一行说明错误类型。 at/by 0xxxxxx：调用栈。如果调用栈很深，显示不完全，可以通过 --num-caller 选项来指定。 0x10916B：这些地址通常来说不重要，但是有时候对于追踪一些奇怪的错误特别有用。  Address 0x4a4e068 is 0 bytes after a block of size 40 alloc'd：一些错误消息有第二个组成部分，它描述了涉及的内存地址。这表明写入的内存刚好超过 example.c 第 5 行用 malloc() 分配的块的末尾。  通常应该按照报告的顺序来修复错误，因为后面的错误可能是前面的错误引起的。\n内存泄露 ==1765727== 40 bytes in 1 blocks are definitely lost in loss record 1 of 1 ==1765727== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==1765727== by 0x10915E: f (a.c:4) ==1765727== by 0x109180: main (a.c:11) 调用栈说明了泄漏内存的分配位置。 内存泄露有几种不同的类型，其中最重要的两个是：\n definitely lost：绝对发生了内存泄露，需要进行修复。 probably lost：可能发生了内存泄漏。除非：正在做一些不常见的事情，例如把指向内存的指针指向已分配内存的中间部分。如果不想看到这些报告，可以使用 --show-possibly-lost=no 来关闭。  其他的一些类型：\n indirectly lost：间接泄露，意味着正在泄露给予指针结构中的内存。例如：如果二叉树的根节点 definitely lost，则所有子节点都将 indirectly lost。 still reachable：仍然可访问，意味着程序可能没有问题，只是没有释放一些它可能拥有的内存。这种情况很常见，通常也是合理的。可以使用 --show-reachable=yes/no 选项控制是否展示。 suppressed：表示内存泄露消息已经被抑制，可以在 valgrind.suppress 文件中进行配置。可以忽略这些错误。  Memcheck 也会报告使用未初始化的值（uninitialised values）的错误，最常见的是 Conditional jump or move depends on uninitialised value(s) 。要确定这些错误的根本原因可能很困难，但可以尝试使用 --track-origins=yes 来获得额外的信息。这会导致 Memcheck 运行更慢，但得到额外信息往往可以节省大量的时间来弄清楚未初始化的值来自哪里。\n如果不清楚 Memcheck 展示的信息的含义，可以查看 Valgrind 用户手册中的 Explanation of error messages from Memcheck。\n附加说明 Memcheck 不是完美的，它可能产生误报，可以通过 valgrind.supress 来控制。详见 Valgrind 用户手册中的 Suppressing error。 不过，通常 99% 都是正确的，所以应该谨慎忽略它的错误消息。 Memcheck 不能检测出程序中所有的内存错误，例如，它无法检测到静态分配或栈上分配的数组的越界读/写。 尽量让程序达到 Memcheck 不会报告任何错误的状态，这可以更容易知道程序的修改何时会导致 Memcheck 报告新的错误。\n参考  Valgrind FAQ Valgrind User Manual  ","date":"2023-08-20T20:30:05+08:00","image":"https://isshe.site/p/valgrind-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/image_huf847cb5c306e77516f0a4bc72ff03aec_308630_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/valgrind-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/","title":"Valgrind 快速上手"},{"content":"BPFTool 安装 git clone git@github.com:torvalds/linux.git git checkout v5.4 cd tools/bpf/bpftool make \u0026amp;\u0026amp; make install 使用 特征查看 查看当前系统所支持的所有特征。\nbpftool feature 启用 jit cat /proc/sys/net/core/bpf_jit_enable echo 1 \u0026gt; /proc/sys/net/core/bpf_jit_enable 获取系统中已运行的 BPF 程序 bpftool prog show bpftool prog show id \u0026lt;ID\u0026gt; bpftool prog show id \u0026lt;ID\u0026gt; --json bpftool prog dump xlated id \u0026lt;ID\u0026gt; bpftool prog dump xlated id \u0026lt;ID\u0026gt; visual \u0026amp;\u0026gt; output.out # sudo apt install graphviz dot -Tpng output.out -o visual-graph.png 启用 BPF 统计信息 sysctl -w kernel.bpf_stats_enabled=1 载入并持久化 BPF 程序到 BPF 文件系统 bpftool proc load bpf_proc.o /sys/fs/bpf/bpf_proc 检查 BPF 映射 bpftool map show 创建 BPF 映射 bpftool map create /sys/fs/bpf/counter type array key 4 value 4 entries 5 name counter 更新 BPF 映射 bpftool map update id 1 key 1 0 0 0 value 1 0 0 0 查看 BPF 映射 bpftool map dump id 1 将映射附加到程序上 # 使用名称 bpftool prog load bpf_prog.o /sys/fs/bpf/bpf_prog \\  map name counter /sys/fs/bpf/counter # 使用索引 bpftool prog load bpf_prog.o /sys/fs/bpf/bpf_prog \\  map idx 1 /sys/fs/bpf/counter 查看附加到特定接口的程序 bpftool perf show bpftool net show bpftool cgroup tree ","date":"2023-08-20T20:30:05+08:00","image":"https://isshe.site/p/%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA-bpftool/visual-graph_hued2a87d8227b0716c9dce4b8ec7435a7_37689_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA-bpftool/","title":"动态追踪 —— BPFTool"},{"content":"ssh 隧道 场景：家里内网机器 A 想要访问公司的内网机器 B。 条件：需要一个公网机器 C （假设IP是 1.1.1.1）。\n  打开公网机器的转发\n  在 B 上执行:\n  ssh -p 22 -NR 0.0.0.0:10443:0.0.0.0:443 root@1.1.1.1 # 前面部分 0.0.0.0:10443：C 的信息 # 后面部分 0.0.0.0:443：B 的信息 注意：此时链接会一直保持，终端不会返回。\n 在 A 上执行:  ssh -p 22 -NL 0.0.0.0:10443:0.0.0.0:10443 root@1.1.1.1 # 前面部分 0.0.0.0:10443：A 的信息 # 后面部分 0.0.0.0:10443：C 的信息 注意：此时链接会一直保持，终端不会返回。\n此时，在 A 上通过 localhost:10443 即可访问 B 的 443。\n端口映射 此方法相比上面的更为简化，直接把内网端口映射到外网设备上，直接访问外网设备映射的端口即可。\n 修改公网设备的 ssh 配置  sudo vi /etc/ssh/sshd_config # 设置 GatewayPorts yes # 重启 ssh 服务 sudo systemctl restart sshd  进行端口映射  在内网机器上：\nssh -p 22 -NR 0.0.0.0:10443:0.0.0.0:443 root@1.1.1.1 # 前面部分 0.0.0.0:10443：公网机器信息 # 后面部分 0.0.0.0:443：内网机器信息 注意：此时链接会一直保持，终端不会返回。\n至此，端口映射完成，可以从任意可访问外网的机器上，访问 1.1.1.1:10443 即可访问到 内网机器的 443 端口。\nSSH 问题 SSH 连接慢 # 可以尝试指定算法 ssh -o KexAlgorithms=ecdh-sha2-nistp521 root@192.168.1.102 -v # 也可以尝试修改 mtu sudo ip li set mtu 1200 dev wlan0 # OR sudo ifconfig wlan0 mtu 1200 ","date":"2023-06-19T06:00:05+08:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-ssh/image_hu12db0d530281f422d028abea45bb4587_242967_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-ssh/","title":"Linux 命令 —— ssh"},{"content":"OpenResty 核心技术点 本文档用于汇总学习过程中遇到的核心技术点。 记录逻辑：假设相关功能没有实现，简要描述重新实现的要点。\nTODO: 补充以下相关的\n lua 堆栈解读（或许应该放到 Luajit 那边去）  Lua 接口/数据(变量)注入  有些函数不需要 require 都能进行使用，这是因为 OpenResty 自动进行了相关工作。\n  在初始化 Lua 虚拟机时，进行 Lua 接口注入。 采用表（table）的形式进行组织 —— lua_createtable。 创建一个表，然后设置键值对，把 key（如 \u0026ldquo;get\u0026rdquo;） 和 C 函数（lua_pushcfunction）或值(lua_pushinteger 等)进行绑定。 各个协程可以设置各自独立的全局表。  cosocket  基于 Lua 协程和 Nginx 的事件模型以及异步 I/O：Lua 接口调用 cosocket 相关函数时，底层的 listen、send 等接口采用非阻塞的方式，使这些调用立即返回。根据返回的状态，设置并监听相关读写事件，然后 yield 让出当前 Lua 协程的执行权，继续执行其他协程。当等待的事件发生后，事件处理函数 resume 唤醒对应的协程，继续执行。  详见 OpenResty cosocket。\nPipe 设计要点  开 2 或 3 个 pipe，分别用于 stdin/stdout/stderr —— 把标准输入、输出、错误重定向到这些 pipe 的 fd。 使用 exec 系列函数来执行命令 读或写数据(命令输入或命令输出)时，先进行一次读写，如果无法一次完成，则设置对应的读写事件，然后 yield 让出执行权；后续通过事件模块 resume 获取执行权。  详见 OpenResty Pipe。\nLua 代码加载要点  为用户代码包裹上 \u0026ldquo;return function() \u0026hellip; end\u0026rdquo; 构成闭包工厂，用于生成对应闭包。 在注册表中对 Lua 闭包工厂进行缓存，用 key（用 ngx_http_lua_gen_chunk_cache_key 等函数生成） 或者 reference 进行查找。  详见 OpenResty Lua 代码缓存 或 OpenResty 的 rewrite_by_lua。\nshared dict 设计要点  基于 Nginx 的共享内存(shm) 和 slab 内存管理机制：创建一块共享内存区域，利用 slab 分配机制来进行分配。 访问/修改/分配共享内存时，都采用加锁的方式，保证数据一致性。 键值对使用红黑树和队列（LRU 队列）来进行管理。  详见 OpenResty 共享内存。\n","date":"2023-05-16T13:38:34-03:00","image":"https://isshe.site/p/openresty-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E7%82%B9/image_huff93e60677c963a35780fae817fe9703_270013_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E7%82%B9/","title":"OpenResty 核心技术点"},{"content":"OpenResty 协程/线程  后续都称为协程。\n 通过前面的探索可以看出，ngx_http_lua_run_thread 是相当重要的一个函数，对于协程的调度，都是通过此接口进行。\n目的：\n 了解 OpenResty 协程是什么？ 是否和此函数强关联：ngx_http_lua_run_thread？ OpenResty 的协程与 Luajit 的协程是什么关系？ OpenResty 协程是如何创建的？是何时创建的？（排除前面探究过的轻线程和 coroutine 接口） OpenResty 协程会在何时执行？（排除前面探究过的轻线程和 coroutine 接口） 主协程和其他协程是如何区分的？ Lua VM 和主协程是什么关系？ 这里描述的协程与前面章节中描述的 coroutine 什么关系？  使用  不涉及\n 实现 协程的状态 typedef enum { NGX_HTTP_LUA_CO_RUNNING = 0, /* coroutine running */ NGX_HTTP_LUA_CO_SUSPENDED = 1, /* coroutine suspended */ NGX_HTTP_LUA_CO_NORMAL = 2, /* coroutine normal */ NGX_HTTP_LUA_CO_DEAD = 3, /* coroutine dead */ NGX_HTTP_LUA_CO_ZOMBIE = 4, /* coroutine zombie */ } ngx_http_lua_co_status_t;  NGX_HTTP_LUA_CO_RUNNING：当前协程正在执行 NGX_HTTP_LUA_CO_SUSPENDED：当前协程已挂起，等待恢复 NGX_HTTP_LUA_CO_NORMAL：正常 NGX_HTTP_LUA_CO_DEAD：协程死亡/终止了 NGX_HTTP_LUA_CO_ZOMBIE：是僵尸协程，等待父协程回收  新建协程：ngx_http_lua_new_thread - ngx_http_lua_new_thread \\- ngx_http_get_module_main_conf：获取模块配置 \\- if (L == lmcf-\u0026gt;lua \u0026amp;\u0026amp; !ngx_queue_empty(\u0026amp;lmcf-\u0026gt;cached_lua_threads))：检查是否有缓存的协程，有就直接复用 \\- else \\- lua_pushlightuserdata(L, ngx_http_lua_lightudata_mask(coroutines_key))：把 key 名放到栈顶 \\- lua_rawget(L, LUA_REGISTRYINDEX)：把注册表 L[LUA_REGISTRYINDEX][coroutines_key] 压栈 \\- co = lua_newthread(L)：创建一个协程，并放到 L 的栈顶 \\- ngx_http_lua_create_new_globals_table：为新协程创建全局表并设置 _G 指向自身 \\- ngx_http_lua_set_globals_table：设置新的全局表 \\- *ref = luaL_ref(L, -2)：为 registry[co] 创建一个引用（ref），ref 是一个唯一的整数，后续可通过 lua_rawgeti(L, t, ref) 来获取到对应的对象 \\- lua_settop(L, base)：恢复主协程的堆栈 此函数做了以下事情：\n 创建协程 设置协程的全局表  新建表 t，并设置 t[\u0026quot;_G\u0026quot;] = t，从而在 Lua 代码中可以通过 [\u0026quot;_G\u0026quot;] 访问到全局表 新建表 mt，设置 mt[\u0026quot;__index\u0026quot;] = global_table（当前的全局表） 设置 mt 作为 t 的元表 设置 t 为协程新的全局表 这时候，即可  同时访问 t 和 原 global_table 的内容 子协程可以访问父协程的内容，而子协程之间无法互相访问     为协程创建引用，以能快速在 coroutines_key 注册表中找到协程  运行协程：ngx_http_lua_run_thread 根据代码注释，我们得知： 此函数用于执行一个通过 ctx-\u0026gt;cur_co_ctx-\u0026gt;co 指定的 Lua 协程。 它的返回值有：\n NGX_AGAIN：被 IO 中断。r-\u0026gt;main-\u0026gt;count 不变。 NGX_DONE：被 IO 中断。r-\u0026gt;main-\u0026gt;count 已经 + 1。 NGX_ERROR：出错了 \u0026gt;= 200：HTTP 状态码  执行流程：\n- ngx_http_lua_run_thread \\- lua_atpanic(L, ngx_http_lua_atpanic)：设置 Lua VM 的出错处理程序 \\- if (setjmp(ngx_http_lua_exception) == 0)：第一次调用 setjmp \\- ngx_http_lua_pcre_malloc_init：设置成 lua-nginx-module 自身的 pcre 内存分配/释放函数 \\- lua_resume：恢复 ctx-\u0026gt;cur_co_ctx 协程的执行 \\- ngx_http_lua_pcre_malloc_done：恢复成原来的分配/释放函数 \\- switch (rv)：resume 结果 \\- case LUA_YIELD：协程主动 yield 的 \\- if (r-\u0026gt;uri_changed)：如果 URI 变了，则进行跳转 \\- ngx_http_lua_handle_rewrite_jump \\- if (ctx-\u0026gt;exited)：如果需要退出（ngx.exit），则执行对应的处理程序 \\- ngx_http_lua_handle_exit \\- if (ctx-\u0026gt;exec_uri.len)：如果调用了 ngx.exec，则执行对应的处理程序 \\- switch (ctx-\u0026gt;co_op)：检查是进行了什么操作导致 yield 的 \\- case NGX_HTTP_LUA_USER_CORO_NOP：ngx.socket 和 ngx.sleep 导致。表示不再有协程需要处理了，跳出这一次循环，等待下一次的读写时间，或者定时器到期 \\- ctx-\u0026gt;cur_co_ctx = NULL：接下来没有需要执行的协程了，等待 event 调度吧 \\- case NGX_HTTP_LUA_USER_THREAD_RESUME：ngx.thread.spawn 导致，ctx-\u0026gt;cur_co_ctx 已经在接口里面设置过了，不用再设置了。 \\- case NGX_HTTP_LUA_USER_CORO_RESUME：coroutine.resume 导致，ctx-\u0026gt;cur_co_ctx 已经在接口里面设置过了，不用再设置了。 \\- default（NGX_HTTP_LUA_USER_CORO_YIELD）：coroutine.yield 导致 \\- next_coctx = ctx-\u0026gt;cur_co_ctx-\u0026gt;parent_co_ctx：父协程作为下一次要执行的协程 \\- ctx-\u0026gt;cur_co_ctx = next_coctx：设置成下一次要执行的协程 \\- case 0：协程终止了 \\- ngx_http_lua_cleanup_pending_operation：清理 pending 的操作 \\- ctx-\u0026gt;cur_co_ctx-\u0026gt;co_status = NGX_HTTP_LUA_CO_DEAD：设置状态为 DEAD \\- if (ctx-\u0026gt;cur_co_ctx-\u0026gt;zombie_child_threads)：如果有僵尸子协程，则进行清理 \\- ngx_http_lua_cleanup_zombie_child_uthreads \\- if (ngx_http_lua_is_entry_thread(ctx))：如果是入口协程，则删除协程 \\- ngx_http_lua_del_thread \\- if (ctx-\u0026gt;cur_co_ctx-\u0026gt;is_uthread)：如果是用户协程 \\- if (ngx_http_lua_coroutine_alive(parent_coctx))：父协程存活 \\- if (ctx-\u0026gt;cur_co_ctx-\u0026gt;waited_by_parent)：是否正在被父协程 wait \\- ngx_http_lua_post_zombie_thread：没有被父协程 wait，加入到僵尸协程中 \\- else：父协程也不存在了 \\- ngx_http_lua_del_thread：删除协程 \\- else：协程属于存在父协程的子协程 \\- ctx-\u0026gt;cur_co_ctx = next_coctx：把父协程设置为接下来要执行的协程 \\- case LUA_ERRRUN：运行时错误 \\- case LUA_ERRSYNTAX：Lua 代码存在语法错误 \\- case LUA_ERRMEM：内存分配错误 \\- case LUA_ERRERR：错误处理程序出错 \\- default：未知错误 \\- ngx_http_lua_cleanup_pending_operation：清理 pending 操作 \\- ctx-\u0026gt;cur_co_ctx-\u0026gt;co_status = NGX_HTTP_LUA_CO_DEAD：当前协程状态设置为 DEAD \\- if (orig_coctx-\u0026gt;is_uthread || orig_coctx-\u0026gt;is_wrap || ngx_http_lua_is_entry_thread(ctx)) \\- ngx_http_lua_thread_traceback：如果协程是入口协程或者是 spawn 出来的、或者是 wrap 出来的，则打印堆栈 \\- ... 此函数主要做了以下事情：\n 设置错误处理程序，当 Lua 代码执行出错时，调用该处理程序  疑问：什么时候/什么样的错误会调用此函数呢？   resume 起 ctx-\u0026gt;cur_co_ctx 协程，根据执行结果进行后续的处理  协程 yield 了，则判断 yield 的类型，进行不同的行为。 协程 DEAD 了，则进行相关清理操作或者放到僵尸协程列表中    简而言之，就是唤醒协程，并根据执行结果进行不同的处理。\n错误处理：ngx_http_lua_atpanic - ngx_http_lua_atpanic \\- if (lua_type(L, -1) == LUA_TSTRING)：如果有错误信息，则使用，否则使用 “unknown reason” \\- ngx_log_stderr：打印错误信息到 nginx 错误日志中 \\- ngx_quit = 1：把进程的状态设置成优雅退出（退出后 master 会重新拉起新的进程） \\- NGX_LUA_EXCEPTION_THROW：实际就是 longjmp(ngx_http_lua_exception, (x))，ngx_http_lua_exception 是 setjum 最近保存的执行环境。 此函数作为新的错误处理函数，会覆盖默认的 Lua panic 程序。 它的作用是：\n 输出 Lua VM 奔溃原因到 Nginx 错误日志中 跳到 setjmp 处恢复执行  疑问：所以 ngx_quit 生效了么？最终是恢复执行还是退出了呢？    总结  OpenResty 协程是什么？  答：OpenResty 中的协程是一种轻量级的线程，用于实现在 OpenResty 应用中的并发。协程可以在不阻塞其他请求的情况下执行多个任务，从而提高应用程序的效率和吞吐量。协程是在 Lua 脚本中实现的，可以在 OpenResty 中同时处理多个请求，每个请求都有自己的协程。\n 是否和此函数强关联：ngx_http_lua_run_thread？  答：是，这个函数就是执行/调度 OpenResty 协程的函数，会参与协程的调度。（如继续执行 post thread、设置 ctx-\u0026gt;cur_co_ctx 以调度下一个协程）\n OpenResty 的协程与 Luajit 的协程是什么关系？  答：基于 Luajit 的协程，配合 Nginx 事件模型进行工作。\n OpenResty 协程是如何创建的？是何时创建的？（排除前面探究过的轻线程和 coroutine 接口）  答：access、rewrite、content 等阶段执行 Lua 代码前。header filter、body filter 等阶段不会新建协程来执行 Lua 代码，而是直接调用 Luajit 接口进行执行。\n OpenResty 协程会在何时执行？（排除前面探究过的轻线程和 coroutine 接口）  答：access、rewrite、content 阶段执行 Lua 代码时、ngx.sleep、timer、tcp.socket 时。\n 何时会调用错误处理程序 ngx_http_lua_atpanic？panic 后 ngx_quit 生效了么？最终是恢复执行还是退出了呢？  答：Lua VM 崩溃时。注意语法错误、索引 nil 变量等错误时，不会调用。（或许内存不足时会调用，暂未构造出场景）\n 主协程和其他协程是如何区分的？  答：OpenResty 中的主协程和其他协程是通过创建协程的方式区分的。\n 主协程：每个请求的初始协程就是主协程，它负责处理请求的主流程，并处理请求和响应。 其他协程：主协程可以通过调用 ngx.thread.spawn() 等方式创建其他协程，这些协程可以在独立环境中运行，不会影响主协程的正常工作。 主协程和其他协程之间通过数据共享、信号量等方式进行通信，以实现多线程的并行处理能力。   Lua VM 和主协程是什么关系？  答：OpenResty 中的 Lua VM 和主协程是密切相关的。\n Lua VM：是 OpenResty 运行 Lua 代码的运行环境，它负责编译和执行 Lua 代码，并管理内存分配和回收。 主协程：是 OpenResty 中处理请求的核心协程，它在 Lua VM 中运行，负责读取请求信息、执行 Lua 脚本、生成响应等。 因此，可以说：主协程是在 Lua VM 环境中运行的，它依赖于 Lua VM 提供的运行环境和资源。每次请求都会创建一个独立的主协程，独立运行，互不影响。   这里描述的协程与前面章节中描述的 coroutine 什么关系？  答：前面章节的 coroutine 也是基于本章节描述的协程（ngx_http_lua_run_thread）和 Lua 协程（lua_newthread）。\n","date":"2023-05-16T13:38:34-03:00","image":"https://isshe.site/p/openresty-%E7%BA%BF%E7%A8%8B/image_hu818ee36d4363169fc9a3aaeaa8549fc5_273897_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E7%BA%BF%E7%A8%8B/","title":"OpenResty 线程"},{"content":"OpenResty cosocket 使用 openresty 过程中，常常听说 cosocket，那么，cosocket 是什么呢？\n目的：\n 学习如何使用 cosocket。 cosocket 是什么？ cosocket 的实现方式、原理是什么？  使用 ngx.socket.udp 和 ngx.socket.tcp 都是使用 cosocket 的方式实现的，由于 TCP 更常用，因此下面以 TCP 相关接口为例。\n以下接口的上下文皆是：rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*。\nngx.socket.tcp   语法：tcpsock = ngx.socket.tcp()\n  作用：创建并返回一个 TCP 或 面向流的 UNIX 套接字对象。\n  注意：\n 此 API 创建的 cosocket 对象与创建它的 Lua 处理程序具有完全相同的生命周期。所以永远不要将 cosocket 对象传递给任何其他 Lua 处理程序（包括 ngx.timer 回调函数），也永远不要在不同的 Nginx 请求之间共享 cosocket 对象。 如果没有显式关闭 cosocket 对象的底层连接或把连接放回到连接池，那么连接将在以下情况下自动关闭：  当前请求处理程序（handler）执行完成 Lua cosocket 对象被 Lua GC 回收   发生致命错误时，也会自动关闭连接，读超时是唯一的不致命错误。    tcpsock:bind  此接口需要更新的版本，v0.10.21 版本中还未实现。\n   语法：ok, err = tcpsock:bind(address)\n  作用：像标准的 proxy_bind 指令一样，此 api 使到上游服务器的传出连接源自指定的本地 IP 地址。\n  注意：\n address 参数只能指定 IP 地址    tcpsock:connect   语法：ok, err = tcpsock:connect(host, port, options_table?)\n  参数：\n host：地址或者是 UNIX 域套接字文件。 port：端口 options_tables：  pool：内存池名称，如果不指定，则是 \u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; 或 \u0026lt;unix-socket-path\u0026gt;。 pool_size：  粒度是 worker 进程级别，不是程序级别，并且连接池创建后，大小就无法修改了。 如果没有指定此参数并且 backlog 参数也没有指定，则不会创建连接池。 如果没有指定此参数但指定 backlog，则连接池大小为 backlog。 如果连接池内连接数量超了，则会根据最近最少使用的方式关闭连接。   backlog：限制指定连接池打开的连接总数。  任何时候，打开的连接都不能超过 pool_size 指定的数量。 如果连接池满了，就会积压到 backlog 队列中，如果队列也满了，就会返回 nil 并报错。 如果等待时间超过 connect_timeout（可通过 settimeouts 指定），则会返回 nil 并报错。        返回值：\n ok：成功时返回 1，失败返回 nil。 err：失败时的错误信息。    作用：尝试在不阻塞的情况下将 TCP 套接字对象连接到远程服务器或 UNIX 域套接字文件。\n  注意：\n 在进行域名解析并连接到远端之前，这个接口始终在连接池中查找之前由此接口或 ngx.socket.connect 接口创建的空闲连接。 host 支持 IP 地址和域名，对于域名，将使用 Nginx 核心的动态解析器​​来无阻塞地解析域名。（Nginx 的解析器通过 resolver 指令来配置）。 如果域名解析返回多个 IP，将随机选择一个 IP 进行连接。 对已经连接 cosocket 对象再次调用此接口，将会首先关闭原始连接。    tcpsock:send   语法：bytes, err = tcpsock:send(data)\n  参数：\n data：需要发送的数据。字符串或者是一个字符串数组（table）。    返回值：\n bytes：发送了的字节数，失败返回 nil。 err：失败时的错误信息。    作用：在当前连接上发送数据。\n  注意：这是一个同步操作。直到所有数据发送到系统 socket 发送缓冲区或者出错才返回。\n  tcpsock:receive   语法：\n data, err, partial = tcpsock:receive(size) data, err, partial = tcpsock:receive(pattern?)    参数：\n size：接收指定字节的数据，支持数字或者字符串。 pattern：支持 *l 和 *a，默认是行模式 *l。  *l：从套接字中读取一行文本。该行以换行 (LF) 结束，前面可以选择回车 (CR)。返回行中不包含 CR 和 LF 字符。事实上，所有 CR 字符都被该模式忽略。 *a：从套接字读取直到连接关闭。      返回值：\n data：接收到的数据。出错时是 nil。 err：出错时的错误信息。 partial：出错时返回当前以接收到的数据。    作用：根据读取模式或大小从 socket 连接上接收数据。\n  注意：\n 可通过 settimeout 指定读取超时时间。（发送时，也可用此函数指定发送超时时间）。    tcpsock:settimeout   语法：tcpsock:settimeout(time)\n  参数：\n time：超时时间，单位是毫秒。    作用：为接下来的操作设置超时时间。\n 读取时，设置的是读取超时时间。 发送时，设置的是发送超时时间。 连接时，设置的是连接超时时间。    注意：设置 keepalive 超时需使用 setkeepalive 方法。\n  tcpsock:close   语法：ok, err = tcpsock:close()\n  返回值：\n ok：成功时返回 1，失败时返回 nil。 err：失败时的错误信息。    作用：关闭当前 socket 套接字。\n  注意：\n 调用过 setkeepalive 的 socket 对象，不用再调用 close，因为 socket 对象已经关闭并且连接已经被保存到内置连接池中。 没有调用 close 方法的 socket 对象（以及关联的连接）将在 Lua GC 释放 socket 对象或当前客户端 HTTP 请求处理完毕时关闭。    使用示例 local sock = ngx.socket.tcp() -- bind 接口在更新的版本才有 -- local ok, err = sock:bind(\u0026#34;172.22.49.3\u0026#34;) -- if not ok then -- ngx.say(\u0026#34;failed to bind\u0026#34;) -- return -- end local ok, err = sock:connect(\u0026#34;172.64.138.14\u0026#34;, 80) if not ok then ngx.say(\u0026#34;failed to connect server: \u0026#34;, err) return end ngx.say(\u0026#34;successfully connected!\u0026#34;) local req = \u0026#34;GET / HTTP/1.1\\r\\n\u0026#34; .. \u0026#34;Host: ifconfig.io\\r\\n\u0026#34; .. \u0026#34;User-Agent: curl/7.68.0\\r\\n\u0026#34; .. \u0026#34;Accept: */*\\r\\n\\r\\n\u0026#34; -- send sock:settimeout(3000) local bytes, err = sock:send(req) if not bytes then ngx.say(\u0026#34;failed to send data to server: \u0026#34;, err) return end ngx.say(\u0026#34;successfully sent, bytes: \u0026#34;, bytes) -- receive sock:settimeout(3000) local data, err, partial = sock:receive() if not data then ngx.say(\u0026#34;failed to read data from server: \u0026#34;, err) return end ngx.say(\u0026#34;successfully read: \u0026#34;, data) sock:close() 实现 Lua 接口注入 毫无疑问，还是类似的注入方式\n- main \\- ngx_init_cycle \\- ngx_conf_parse \\- ngx_conf_handler \\- ngx_http_block \\- ngx_http_lua_init \\- ngx_http_lua_init_vm \\- ngx_http_lua_new_state \\- ngx_http_lua_init_globals \\- ngx_http_lua_inject_ngx_api \\- ngx_http_lua_inject_socket_tcp_api  ngx_http_lua_inject_socket_tcp_api 的执行流程  - ngx_http_lua_inject_socket_tcp_api \\- lua_createtable: 创建 ngx.socket 表 \\- lua_setfield(L, -3, \u0026#34;tcp\u0026#34;)：注入 ngx.socket.tcp，以及 ngx.socket.stream, ngx.socket.connect 等 ngx.socket 系列接口 \\- lua_pushlightuserdata(L, ngx_http_lua_lightudata_mask(req_socket_metatable_key)) \\- lua_createtable(L, 0 /* narr */, 6 /* nrec */)：创建元表并注入通过 ngx.req.socket() 得到的对象的相关接口 \\- lua_pushlightuserdata(L, ngx_http_lua_lightudata_mask(raw_req_socket_metatable_key)) \\- lua_createtable(L, 0 /* narr */, 7 /* nrec */)：创建元表并注入通过 ngx.req.socket(raw) 得到的对象的相关接口 \\- lua_pushlightuserdata(L, ngx_http_lua_lightudata_mask(tcp_socket_metatable_key)) \\- lua_createtable(L, 0 /* narr */, 14 /* nrec */)：创建元表并注入 tcp 对象（通过 ngx.socket.tcp 创建）的接口 \\- upstream_udata_metatable_key：还有以下这些元表，不再赘述，如有必要，直接通过这些 key 在源码中搜索，即可知道如何使用。 \\- downstream_udata_metatable_key：例如这个在 ngx.req.socket 调用时使用 \\- pool_udata_metatable_key \\- pattern_udata_metatable_key \\- ssl_session_metatable_key 以 tcp 为例， 调用 ngx.socket.tcp() 函数创建 tcp 对象时，实际调用了 ngx_http_lua_socket_tcp 函数， 此函数中，会新建一个表，然后设置 ngx_http_lua_inject_socket_tcp_api 中创建的表（以 tcp_socket_metatable_key 标识）为元表。\n接下来，我们也以 tcp 为例，跟踪了解 cosocket 的实现方式。\n创建对象 创建对象的函数是 ngx_http_lua_socket_tcp，比较简单，主要完成以下操作：\n 获取请求 获取模块 ctx 检查 ctx 是否是可以 YIELD 的 创建新表 设置新表的元表为前面张杰中注入的元表， key：tcp_socket_metatable_key。 返回新表  创建连接 创建 TCP 连接的函数是 ngx_http_lua_socket_tcp_connect，我们来跟踪一下。\n注释版代码见 src/ngx_http_lua_socket_tcp.c\n- ngx_http_lua_socket_tcp_connect \\- if (lua_type(L, n) == LUA_TTABLE)：检查最后一个参数是不是 table 类型，是的话就是有选项参数（sock:connect 的最后一个参数）。 \\- lua_getfield(L, n, \u0026#34;pool_size\u0026#34;)：从选项参数表中取出 pool_size，并检查合法性，需要 大于 0 或者等于 nil。 \\- lua_getfield(L, n, \u0026#34;backlog\u0026#34;)：从选项参数表中取出 backlog，并检查合法性，需大于等于 0。如果只设置了 backlog，没有设置 pool_size，则把默认 pool_size 值设置成 pool_size。 \\- lua_getfield(L, n, \u0026#34;pool\u0026#34;)：从选项参数表中取值 pool，如果值是数字，就转成字符串，并继续按字符串处理；如果是字符串，就设置到 tcp 对象的指定的 key 下面（SOCKET_KEY_INDEX）；如果是 nil，就从堆栈弹出 pool 相关参数；其他值报错返回。 \\- if (n == 3 \u0026amp;\u0026amp; lua_isnumber(L, 3))：检查 port，不合法就退出，报错退出。 \\- lua_rawgeti(L, 1, SOCKET_CTX_INDEX)：取出 upstream_t， 如果没有就分配一个并设置到 tcp 对象的 SOCKET_CTX_INDEX；如果有了，就检查这个上游对象的有效性，有效就复用。 \\- ngx_memzero(u, sizeof(ngx_http_lua_socket_tcp_upstream_t))：把拿到的上游对象初始化一下：清空，设置相关字段。 \\- lua_rawgeti(L, 1, SOCKET_CONNECT_TIMEOUT_INDEX)：把超时参数从 TCP 对象中取出压入栈中，设置超时到上游对象的连接超时、发送超时、读取超时字段中。（TCP 对象中的超时参数是 settimeouts、settimeout 函数设置的） \\- lua_pushlightuserdata(L, ngx_http_lua_lightudata_mask(socket_pool_key))：根据 pool 参数或者 host:port 为 key 取出对应连接池，如果有就直接用；如果没有，就创建（ngx_http_lua_socket_tcp_create_socket_pool）这个连接池。 \\- ngx_http_lua_socket_tcp_connect_helper：进入包裹函数，继续处理 \\- if (spool != NULL)：检查是否指定了连接池；指定了，就从连接池中取出 keepalive 连接，取到了就直接返回。这里会限制连接池中总连接数不能超过 连接池大小 size + backlog。如果超过了 size，但小于 size + backlog，意味着是 backlog 连接，从 backlog 队列的从中取出或创建连接操作上下文（ngx_http_lua_socket_tcp_conn_op_ctx_t）放到队列中。 \\- host.data = ngx_palloc(r-\u0026gt;pool, host_len + 1)：分配内存存 host，用于通过 ngx_parse_url 创建 sockaddr。 \\- u-\u0026gt;resolved = ngx_pcalloc(r-\u0026gt;pool, sizeof(ngx_http_upstream_resolved_t))：分配内存存放域名解析相关内容，如果需要解析，就放到 u-\u0026gt;resolved-\u0026gt;host 字段；不用就把前面创建的 sockaddr 放到 u-\u0026gt;resolved-\u0026gt;sockaddr 中。 \\- if (u-\u0026gt;resolved-\u0026gt;sockaddr)：有地址了，直接进行连接，然后返回。 \\- ngx_http_lua_socket_resolve_retval_handler \\- rctx = ngx_resolve_start(clcf-\u0026gt;resolver, \u0026amp;temp)：进行域名解析。 \\- if (ngx_resolve_name(rctx) != NGX_OK)：正式开始。 \\- u-\u0026gt;write_prepare_retvals = ngx_http_lua_socket_resolve_retval_handler：设置解析完成后的回调函数。 - ngx_http_lua_socket_resolve_retval_handler：解析结果返回了，开始正式发起连接。 \\- if (u-\u0026gt;resolved-\u0026gt;sockaddr)：如果有就是解析成功了，没有就是解析失败了，报错返回。 \\- rc = ngx_event_connect_peer(pc)：发起连接 \\- if (rc == NGX_ERROR)：连接出错了 \\- ngx_http_lua_socket_conn_error_retval_handler：错误处理函数 \\- if (rc == NGX_BUSY)：没有存活连接 \\- if (rc == NGX_DECLINED)：socket 错误。 \\- ngx_http_lua_socket_conn_error_retval_handler：错误处理函数 \\- /* rc == NGX_OK || rc == NGX_AGAIN */；接下来就是连接中或者连接成功的情况了。 \\- NGX_AGAIN：connect 返回 -1，错误码是 NGX_EINPROGRESS，意思是正在连接中。 \\- c-\u0026gt;write-\u0026gt;handler = ngx_http_lua_socket_tcp_handler：添加读写事件的处理函数 \\- if (rc == NGX_OK)：如果是连接成功了，就去掉读写事件，免得浪费 CPU 周期。 \\- /* rc == NGX_AGAIN */：还没连接成功 \\- ngx_add_timer(c-\u0026gt;write, u-\u0026gt;connect_timeout)：增加增加连接超时 timer。 从 Lua 接口 connect 可以看到，该接口有 3 个参数，分别是 host、port、options_table。 （其实是 4 个参数，第一个是 tcpsock 自身：connect(tcpsock, host, port, options_table)）\n连接步骤大致总结如下：\n 检查选项参数（options_table） 如果没有连接池就创建连接池 从连接池中获取连接，没取到就直接进行连接；（后续可通过 setkeepalive 放回到连接池中） 通过 ngx_parse_url 解析 host，看是不是域名，不是域名会直接创建 sockaddr 如果是域名，就进行域名解析 解析完成调用 ngx_event_connect_peer 进行连接 如果返回 NGX_OK，就是连接成功了 如果返回 NGX_AGAIN，c 函数 connect 的错误码是 EINPROGRESS，表示正在连接中，设置读写事件，等待写事件即可。（连接成功后，套接字会变为可写状态，事件模块会调用写事件处理函数）  发送请求 接口注入：\n- ngx_http_lua_inject_socket_tcp_api \\- ngx_http_lua_socket_tcp_send 拿到注入的接口名称后，我们来跟踪一下：\n- ngx_http_lua_socket_tcp_send \\- if (u == NULL || u-\u0026gt;peer.connection == NULL || u-\u0026gt;write_closed)：先检查连接还在不在，不在就报错返回。 \\- if (u-\u0026gt;body_downstream)：检查是不是想要写请求对应的 socket（ngx.req.socket），是的话，报错返回，不允许写。 \\- type = lua_type(L, 2)：获取并检查第二个参数（也就是发送的数据）的类型；计算出最大发送长度。 \\- ngx_http_lua_chain_get_free_buf：看下还有没有空间能放得下这么长的数据；没有会返回 NULL。 \\- switch (type)：把要发送的数据写入获取到的 buffer 中。 \\- if (clcf-\u0026gt;tcp_nodelay \u0026amp;\u0026amp; c-\u0026gt;tcp_nodelay == NGX_TCP_NODELAY_UNSET)：看有没有选项需要设置。 \\- ngx_http_lua_socket_send：进行发送。 \\- b = u-\u0026gt;request_bufs-\u0026gt;buf：获取要发送的 buffer。 \\- n = c-\u0026gt;send(c, b-\u0026gt;pos, b-\u0026gt;last - b-\u0026gt;pos)：进行发送，如果发送失败或者阻塞了，就立即退出死循环；否则就一直发送到发送完为止。 \\- if (n == NGX_ERROR)：如果是出错，就进行错误处理，然后返回 NGX_ERROR \\- else：否则就是 n == NGX_AGAIN，还在发送中 \\- u-\u0026gt;write_event_handler = ngx_http_lua_socket_send_handler：设置写事件处理函数。 \\- ngx_add_timer(c-\u0026gt;write, u-\u0026gt;send_timeout)：增加定时器。 \\- ngx_handle_write_event(c-\u0026gt;write, u-\u0026gt;conf-\u0026gt;send_lowat)：监听写事件。 \\- if (rc == NGX_ERROR)：出错了就进行错误处理并返回 \\- ngx_http_lua_socket_write_error_retval_handler \\- if (rc == NGX_OK)：成功了直接返回 \\- /* rc == NGX_AGAIN */：还在发送中 \\- u-\u0026gt;write_prepare_retvals = ngx_http_lua_socket_tcp_send_retval_handler：设置好回调函数，yield 出去等待可写事件发生。 经过前面 connect 的整理，send 就简单了很多，都是一样的套路：返回 NGX_AGAIN 就 yield，继续加入到事件循环中，等待下次事件触发，继续处理，都完成以后，在 resume 回去 lua 代码。\n步骤大致总结如下：\n 计算发送的长度； 复制数据到指定的 buffer 中； 进行发送，如果一直发送成功，就一直发送；否则就退出循环。 如果是出错了，就进行错误处理，然后退出。 如果是阻塞了，就设置写处理函数并监听写事件，yield 出去等待下次可写。  接收响应 接口注入：\n- ngx_http_lua_inject_socket_tcp_api \\- ngx_http_lua_socket_tcp_receive 原理和前面发送类似，大致步骤如下：\n 处理参数，判断是数字还是字符串；数字表示要接收的字节数量，是字符串表示模式，是 *a 还是 *l。根据不同的模式设置不同的 input_filter。如果没有指定第二个参数，就是默认的行模式。 检查缓冲区有没有空间，没有就重新获取一个 开始读取，出错或者成功，就直接返回。 如果是 NGX_AGAIN，就设置好处理函数，yiele 了继续等待事件发生。  关闭连接 如果请求没有忙于读、写、连接，则调用 ngx_http_lua_socket_tcp_finalize 关闭连接。\n总结 1.Nginx 是如何进行域名解析的？ ngx_resolve_start、ngx_resolve_name，是异步的吗，会等待解析结果吗？ 答：详见 Nginx 是如何进行 DNS 解析的？。\n2.如何进行连接的？ 答：进行非阻塞连接，返回 rc == -1 \u0026amp;\u0026amp; err == NGX_EINPROGRESS 时，表示连接正在进行中。openresty 设置好读写事件，在 ngx_http_lua_socket_connected_handler 中检查连接实际是否成功。\n更多参考 I/O多路复用与非阻塞连接\n3.TCP 连接进行中（NGX_AGAIN）时，yield 出去后，会在哪里恢复？ 答：\n https://github.com/isshe/lua-nginx-module/blob/isshe/src/ngx_http_lua_socket_tcp.c#L840 此时 Lua 正在调用 connect。 yield 以后，继续返回到 ngx_http_lua_run_thread，最后回到事件循环中，等待事件发生，重新 resume。  // yield 后也就是 lua_resume 返回了 rv = lua_resume(orig_coctx-\u0026gt;co, nrets);  事件发生（c-\u0026gt;write 写事件）后，调用 ngx_http_lua_socket_tcp_handler。  连接成功后的调用栈：\n#0 ngx_http_lua_run_thread (L=0x55efffa60640 \u0026lt;cached_syslog_time+800\u0026gt;, r=0x55efff9d0280, ctx=0x55efff7be452 \u0026lt;ngx_sprintf+192\u0026gt;, nrets=32766) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:1112 #1 0x000055efff945315 in ngx_http_lua_socket_tcp_resume_helper (r=0x55f001716120, socket_op=0) at ../ngx_lua-0.10.21/src/ngx_http_lua_socket_tcp.c:5991 #2 0x000055efff945082 in ngx_http_lua_socket_tcp_conn_resume (r=0x55f001716120) at ../ngx_lua-0.10.21/src/ngx_http_lua_socket_tcp.c:5897 #3 0x000055efff92e8bf in ngx_http_lua_content_wev_handler (r=0x55f001716120) at ../ngx_lua-0.10.21/src/ngx_http_lua_contentby.c:152 #4 0x000055efff93f72a in ngx_http_lua_socket_handle_conn_success (r=0x55f001716120, u=0x7f868af3adc8) at ../ngx_lua-0.10.21/src/ngx_http_lua_socket_tcp.c:3451 #5 0x000055efff9401b6 in ngx_http_lua_socket_connected_handler (r=0x55f001716120, u=0x7f868af3adc8) at ../ngx_lua-0.10.21/src/ngx_http_lua_socket_tcp.c:3719 #6 0x000055efff93efd0 in ngx_http_lua_socket_tcp_handler (ev=0x55f0017a73b0) at ../ngx_lua-0.10.21/src/ngx_http_lua_socket_tcp.c:3239 ... 4.什么是 cosocket 呢？ cosocket 是如何实现的呢？ 答：cosocket 是一种基于协程的高性能、低延迟的 I/O 模型。cosocket 基于事件驱动和异步 I/O，使用 Nginx 事件驱动框架监听套接字事件，通过异步 I/O 读写套接字数据，实现面向协议编程（解析/处理协议）的目的。\n 协程：利用 yield、resume 对协程进行调度。 事件驱动：发生事件是，调用事先设置好的处理程序。 异步 IO：不进行阻塞调用，条件没就绪也立即返回。根据不同的返回值，进行处理。如果返回值是 NGX_AGAIN 意味着条件不满足，需要继续监听事件，并且 yield 当前的 Lua 调用，等待条件满足再返回。  ","date":"2023-05-04T06:00:05-03:00","image":"https://isshe.site/p/openresty-cosocket/image_hu791dd9063814c22195f4ea220a5b559d_225821_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-cosocket/","title":"OpenResty cosocket"},{"content":"Lua VM 初始化 上一篇关于 ngx.log 文章中，跟踪相关代码时思路几近断裂，因此赶紧来补补 Lua VM 初始化相关内容。\n目的：\n Lua VM 初始化的时机？（什么时候初始化） 了解 Lua VM 初始化做了哪些工作？为什么这么做（选）？ Lua 虚拟机是共用一个？还是每次调用 Lua 代码起一个？ 注入的接口和 _G 是什么关系？这些接口也在 _G 中吗？  Lua VM 初始化时机 从上一篇文章中，我们已经拿过一个 Lua VM 初始化相关的堆栈，这里截取一部分：\n#4 0x000055555570b955 in ngx_http_lua_init_vm (new_vm=0x555555891080, parent_vm=0x0, cycle=0x555555885740, pool=0x5555558856f0, lmcf=0x555555891080, log=0x55555583d280 \u0026lt;ngx_log\u0026gt;, pcln=0x0) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:3896 #5 0x00005555556fb450 in ngx_http_lua_init (cf=0x7fffffffd7e0) at ../ngx_lua-0.10.21/src/ngx_http_lua_module.c:865 #6 0x00005555555f4ddc in ngx_http_block (cf=0x7fffffffd7e0, cmd=0x55555581a200 \u0026lt;ngx_http_commands\u0026gt;, conf=0x555555886a20) at src/http/ngx_http.c:310 #7 0x00005555555b9ec7 in ngx_conf_handler (cf=0x7fffffffd7e0, last=1) at src/core/ngx_conf_file.c:463 #8 0x00005555555b99cc in ngx_conf_parse (cf=0x7fffffffd7e0, filename=0x555555885958) at src/core/ngx_conf_file.c:319 #9 0x00005555555b4f87 in ngx_init_cycle (old_cycle=0x7fffffffd9b0) at src/core/ngx_cycle.c:284 #10 0x0000555555592fe8 in main (argc=3, argv=0x7fffffffdd58) at src/core/nginx.c:295 从这个调用栈可以看到，是在解析 lua-nginx-module 配置阶段（准确来说是 postconfiguration 阶段）初始化的 Lua VM。\n#0 ngx_http_lua_init_vm (new_vm=0x1, parent_vm=0x0, cycle=0x0, pool=0x0, lmcf=0xffffffffffffffff, log=0x400002001, pcln=0x7ffe9ee23400) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:3882 #1 0x0000558146dea07f in ngx_http_lua_create_ctx (r=0x5581471b6120) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.h:305 #2 0x0000558146dea50d in ngx_http_lua_rewrite_handler (r=0x5581471b6120) at ../ngx_lua-0.10.21/src/ngx_http_lua_rewriteby.c:92 #3 0x0000558146cd558e in ngx_http_core_rewrite_phase (r=0x5581471b6120, ph=0x5581471bcf08) at src/http/ngx_http_core_module.c:939 #4 0x0000558146cd53de in ngx_http_core_run_phases (r=0x5581471b6120) ... 设置 lua_code_cache off 指令关闭缓存后，每次请求都会重新初始化 Lua VM。\nLua VM 初始化流程 - ngx_http_lua_init_vm \\- ngx_pool_cleanup_add：添加内存池清理函数——用于清理 Lua VM（ngx_http_lua_cleanup_vm） \\- ngx_http_lua_new_state：创建 Lua VM 实例 \\- luaL_newstate：新分配一个 lua_State 结构 \\- luaL_openlibs：打开所有标准 Lua 库到给定 state \\- lua_getglobal(L, \u0026quot;package\u0026quot;)：将全局 package 的值压入堆栈。返回该值的类型 \\- 返回值是代表类型，那为什么不直接用，而是下面进行 istable 判断？[1] \\- if (!lua_istable(L, -1))：检查栈顶值是否是 table（package 是一个 table），不是直接报错返回。 \\- if (parent_vm)：如果有父级 VM，则使用它的 path 和 cpath， \\- else：否则自行解析设置 path、cpath，从编译指定的默认路径和从 nginx 配置中得到相关路径 \\- ngx_http_lua_init_registry：初始化 Lua 注册表 [2] \\- 注册一个表以可靠地锚定 lua 协程，初始大小为 32 个 KV。 \\- 为 Lua 套接字连接池表注册一个表 \\- 注册一个表以缓存用户代码 \\- ngx_http_lua_init_globals：初始化 lua 全局变量 \\- ngx_http_lua_inject_ndk_api：注入 ngx devel kit 的 API（如果有定义 NDK 宏的话） \\- ngx_http_lua_inject_ngx_api：注入 ngx API，实际上就是创建 ngx 表和填充这个表。 \\- 例如：把 ngx.log 等于 ngx_http_lua_ngx_log \\- 例如：ngx.HTTP_GET = NGX_HTTP_GET \\- luaopen_ffi：加载 FFI 库，因为 cdata 需要 \\- if (lmcf-\u0026gt;preload_hooks)：检查是否有需要预加载的 hook \\- ngx_http_lua_probe_register_preload_package：注册第 3 方模块的预加载 hook \\- 示例：package=ngx.upstream，loader=ngx_http_lua_upstream_create_module \\- lua_pcall：调用 require(\u0026quot;resty.core\u0026quot;)，不知何意 \\- ngx_http_lua_inject_global_write_guard：注入全局写保护，使用全局变量时会得到告警提示 \\- 执行了一段 Lua 代码，设置了 _G 的元表，重载了 __newindex 可以看到，Lua VM 初始化主要做了以下事情：\n 新建 state 实例 打开标准库 设置搜索路径（path、cpath） 注册一些表 注入 Lua 接口、变量：重点关注，很多 Lua 接口都是在这里注入。 预加载第三方 hook 对 _G 进行写保护  那么，Lua 虚拟机是共用一个？还是每次调用 Lua 代码起一个？\n lua_code_cache 开启时，共用一个 lua_code_cache 关闭时，每个请求一个  总结  Lua VM 初始化的时机？（什么时候初始化）  答：lua_code_cache 开启时，在配置解析阶段（准确来说是 postconfiguration 阶段）；lua_code_cache 关闭时，每次请求都会重新初始化 Lua VM，在 rewrite 等实际设置了处理程序（handler）的阶段。\n Lua 虚拟机是共用一个？还是每次调用 Lua 代码起一个？  答：lua_code_cache 开启时，共用一个；lua_code_cache 关闭时，每个请求一个。\n 注入的接口和 _G 是什么关系？这些接口也在 _G 中吗？  答：是的，注入的接口就在 _G 或者 _G 的元表中。\n疑问  [1]：lua_getglobal 能直接返回类型，为什么不直接用而是用 istable 来判断？ [2]：注册的几个表的用途是什么？在哪里用了？（ngx_http_lua_init_registry）  ","date":"2023-05-04T06:00:05-03:00","image":"https://isshe.site/p/openresty-lua-vm-%E5%88%9D%E5%A7%8B%E5%8C%96/image_hu8b1a295022397cfd38b972b1dd920be7_248987_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-lua-vm-%E5%88%9D%E5%A7%8B%E5%8C%96/","title":"OpenResty Lua VM 初始化"},{"content":"轻线程信号量 和 Linux 系统或者 Nginx 中的信号量类似，都是用于进程/协程同步。当值小于 0 时，表示需要等待资源。 不过 Nginx 中的信号量是会导致进程在等待资源时休眠的，OpenResty 的信号量（后续简称信号量）是不是也是一样呢？我们来探究一番。\n目的：\n 如何使用信号量？ 信号量是如何实现的？ 信号量是否会导致如进程休眠之类的问题？ 不同进程的协程是否能使用信号量？  使用 Lua 接口的使用都比较简单，我们直接通过一个示例来说明。\n-- 引入 ngx.semaphore 模块 local semaphore = require \u0026#34;ngx.semaphore\u0026#34; -- 新建一个 semaphore 对象 -- 此时默认资源是 0 个 -- 也可以传递参数指定信号量初始有多少资源 local sema = semaphore.new() -- 获取资源数量 ngx.say(\u0026#34;main thread: count: \u0026#34;, sema:count()) -- count: 0 -- 新协程的处理函数 local function handler() ngx.say(\u0026#34;sub thread: waiting on sema...\u0026#34;) -- 等待 1 个资源；超时时间是 1 秒，如果资源数量 \u0026gt;= 0，立即返回，如果拿不到（数量 \u0026lt; 0），会 yield。 -- 相当于锁操作中的 加锁（lock）操作。 -- 参数中的 1 表示 1 秒；最小可以为 0.001 秒 local ok, err = sema:wait(1) -- wait for a second at most if not ok then ngx.say(\u0026#34;sub thread: failed to wait on sema: \u0026#34;, err) else ngx.say(\u0026#34;sub thread: waited successfully.\u0026#34;) end end -- 新建协程并立即跑 handler local co = ngx.thread.spawn(handler) ngx.say(\u0026#34;main thread: sleeping for a little while...\u0026#34;) ngx.sleep(0.1) -- wait a bit ngx.say(\u0026#34;main thread: posting to sema...\u0026#34;) ngx.say(\u0026#34;main thread: count: \u0026#34;, sema:count()) -- count: -1 -- 释放一个资源，这里的参数 1 表示释放的资源数量。 sema:post(1) ngx.say(\u0026#34;main thread: count: \u0026#34;, sema:count()) -- count: 0 ngx.say(\u0026#34;main thread: end.\u0026#34;) 示例输出如下：\nmain thread: count: 0 sub thread: waiting on sema... main thread: sleeping for a little while... main thread: posting to sema... main thread: count: -1 main thread: count: 0 main thread: end. sub thread: waited successfully. 实现 不像前面文章中的做法，这里用到的 Lua 接口不是通过接口注入的方式进行的，而是用的 Lua 模块，名称为 semaphore.lua。\n创建对象 - new \\- if n \u0026lt; 0 then：检查参数，如果小于 0，就报错退出。 \\- ngx_lua_ffi_sema_new(psem, n, errmsg)：调用 C 函数创建对象。 \\- ngx_http_lua_alloc_sema：分配内存，会一次分配一批，然后从中取 1 个，其他的放着后续能快速取，不用每次都分配。 \\- ffi_gc(sem, ngx_lua_ffi_sema_gc)：绑定 gc 函数，在 sem 被释放时，调用 gc 函数。 这个函数主要进行以下工作：\n 检查参数合法性 分配内存存储 sema 对象  ngx_lua_ffi_sema_new 在 http 子系统中对应 ngx_http_lua_ffi_sema_new，在 stream 子系统中对应 ngx_stream_lua_ffi_sema_new。   绑定清理函数  获取资源 - wait \\- if milliseconds \u0026lt; 0 then：检查参数，第二个参数是等待超时时间，单位是秒，最小支持 0.001 秒，也就是 1 毫秒。 \\- ngx_lua_ffi_sema_wait： \\- ngx_http_lua_ffi_check_context：检查上下文是否能 yield \\- ngx_queue_empty：如果等待队列为空并且还有资源直接返回成功 \\- if (wait_ms == 0)：如果要求不等待，也直接返回 \\- ngx_add_timer；接下来就是需要等待了，增加 timer，超时时间为调用接口时指定的时间。 \\- ngx_queue_insert_tail：把当前协程插入到信号量等待队列末尾。 \\- ok, err = co_yield()：不能在这里使用尾调用形式，因为可能需要当前函数调用的激活记录来保存对信号量对象的引用，以防止它过早地被 GC 处理。 这个调用主要进行以下工作：\n 检查参数合法性 获取资源，能获取到就直接返回，获取不到就看要不要等待，不等就直接返回超时；等就加入到等待队列中，然后 yield 出去，等待 post 操作唤醒。  释放资源 - post \\- if type(self) ~= \u0026#34;table\u0026#34; or type(self.sem) ~= \u0026#34;cdata\u0026#34; then：检查 self 对象 \\- if num \u0026lt; 1 then：检查参数是否是 \u0026gt;= 1 \\- ngx_lua_ffi_sema_post \\- sem-\u0026gt;resource_count += n：把资源加 n \\- ngx_post_event((\u0026amp;sem-\u0026gt;sem_event), \u0026amp;ngx_posted_events)：如果信号量中的等待队列不为空，就把事件加到全局的 ngx_posted_events 队列中，在后续的事件循环中进行唤醒新的协程。 这个函数也是非常简单，主要进行以下工作：\n 检查参数合法性 把资源数量增加 n 如果有等待队列，就把事件增加到 ngx_posted_events 中，后续处理。  总结  信号量是如何实现的？  答：还是依赖 Lua 的协程和 Nginx 定时器等。新建一个信号量对象，其中记录信号量的信息；然后使用 wait 和 post 来增减资源。\n 信号量是否会导致如进程休眠之类的问题？  答：不会。使用的 Lua 协程，在没有资源时，会 yiled 出去，给其他协程执行。\n 不同进程的协程是否能使用信号量？  答：不能。可以在不同上下文、请求中进行使用，但是要求是同一个 worker 进程。如需在不同进程间同步，可以使用：lua-resty-lock。\n","date":"2023-05-04T06:00:05-03:00","image":"https://isshe.site/p/openresty-%E4%BF%A1%E5%8F%B7%E9%87%8F/image_hud257672d761052d10876c00530251082_250335_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E4%BF%A1%E5%8F%B7%E9%87%8F/","title":"OpenResty 信号量"},{"content":"OpenResty shared dict 目的：\n 相关 Lua API 如 ngx.shared.DICT.get 是如何使用的？ 如何定义 lua_shared_dict 的，lua_shared_dict 做了哪些工作？ 详细跟踪各类 Lua 接口（set、get 每类一个）的实现，了解shared dict的设计/实现细节。 这些 Lua 接口是否是原子的？是否需要考虑竞争问题？原子性是如何保证的？ ngx_http_lua_shdict_shctx_t 等关键数据结构是什么作用？它们之间有什么联系？  使用 使用示例：\nhttp { lua_shared_dict dogs 10m; server { location / { content_by_lua_block { -- 设置 local dogs = ngx.shared.dogs dogs:set(\u0026#34;Jim\u0026#34;, 8) -- 获取 local jim_age = dogs:get(\u0026#34;Jim\u0026#34;) ngx.say(jim_age) -- 替换 dogs:replace(\u0026#34;Jim\u0026#34;, 9) -- 递增, value = 10 dogs:incr(\u0026#34;Jim\u0026#34;) -- 更新/设置超时 dogs:expire(\u0026#34;Jim\u0026#34;, 10) -- 获取 TTL dogs:ttl(\u0026#34;Jim\u0026#34;) -- 删除 dogs:delete(\u0026#34;Jim\u0026#34;) } } } } 以下是所有 Lua Api 的作用：\n 详细用法见 lua-nginx-module。\n  get: 获取指定 key 的 value。如果不存在，则返回 nil。 get_stale: 获取指定 key 的 value，即使已经过期，也正常返回。第三个返回值标识是否过期。 set: 增加或更新 shared dict 中的键值对。 safe_set: 如果 shared dict 满了，则返回 nil 和 \u0026ldquo;no memory\u0026rdquo;，不使用 LRU 算法自动淘汰项目。 add: 增加键值对到 shared dict 中。如果已经存在，则返回 nil 和 \u0026ldquo;exists\u0026rdquo; safe_add: 如果 shared dict 满了，则返回 nil 和 \u0026ldquo;no memory\u0026rdquo;，不使用 LRU 算法自动淘汰项目。 replace: 替换 shared dict 中指定键的值，如果键不存在，返回 \u0026ldquo;not found\u0026rdquo;。 delete: 删除 shared dict 中指定的键值对。 incr: 递增指定的数字型键值对的值，可以指定初始值，如果 shared dict 中没有对应的的键时，使用初识值进行初始化。 lpush: 把数字型或字符型的值插入到指定键的列表的左边（头部）。 rpush: 把数字型或字符型的值插入到指定键的列表的右边（尾部） lpop: 从指定键的列表的左边（头部）弹出一个值。 rpop: 从指定键的列表的右边（尾部）弹出一个值。 llen: 获取指定列表的长度。 ttl: 获取指定键值的 TTL。 expire: 设置指定键值的过期时间。 flush_all: 清空 shared dict 中所有键值对（设置为过期，不是立即释放内存） flush_expired: 释放过期的键值对的内存。 get_keys: 获取 shared dict 中所有的键。 capacity: 返回 shared dict 的容量（通过 lua_shared_dict 指令指定），单位为字节。 free_space: 返回 shared dict 的剩余空间，单位字节。  实现 怎么入手呢？先看看shared dict是怎么定义的吧。\n定义shared dict（lua_shared_dict） 指令定义：\n { ngx_string(\u0026quot;lua_shared_dict\u0026quot;), NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE2, ngx_http_lua_shared_dict, 0, 0, NULL }, 可以看到 ngx_http_lua_shared_dict 是这个处理函数。\n- ngx_http_lua_shared_dict \\- if (lmcf-\u0026gt;shdict_zones == NULL): 检查 main 配置，是否已经有这个存储所有 shared dict 的数组了，如果没有，就分配并初始化 \\- name = value[1]: 获取并检查 shared dict 名称 \\- size = ngx_parse_size(\u0026amp;value[2]): 获取并检查 shared dict 大小，单位字节 \\- ctx = ngx_pcalloc(cf-\u0026gt;pool, sizeof(ngx_http_lua_shdict_ctx_t)): 分配 shared dict 上下文结构，并设置好 shared dict 的名称、main 配置、log 配置等 \\- zone = ngx_http_lua_shared_memory_add(cf, \u0026amp;name, (size_t) size, \u0026amp;ngx_http_lua_module): 注册shared dict \\- if (lmcf-\u0026gt;shm_zones == NULL): 在 main 配置中维护的 ngx_shm_zone_t* 数组 \\- zone = ngx_shared_memory_add(cf, name, (size_t) size, tag): 调用 nginx 核心的接口来注册shared dict \\- ngx_memcpy(\u0026amp;ctx-\u0026gt;zone, zone, sizeof(ngx_shm_zone_t)): 复制 zone，两份 zone 分别设置不同的 data 和 init 字段。两个 zone 的关系是：zone2 = zone1-\u0026gt;data-\u0026gt;zone。 \\- zp = ngx_array_push(lmcf-\u0026gt;shm_zones): 加入到 shm_zones 数组中 \\- zone-\u0026gt;init = ngx_http_lua_shared_memory_init: 设置初始化函数 \\- if (zone-\u0026gt;init(zone, odata) != NGX_OK): 实际调用的是 ngx_http_lua_shdict_init_zone \\- if (lmcf-\u0026gt;shm_zones_inited == lmcf-\u0026gt;shm_zones-\u0026gt;nelts \u0026amp;\u0026amp; lmcf-\u0026gt;init_handler \u0026amp;\u0026amp; !ngx_test_config): 初始化完成，并且不是测试，就执行后续的 init_handler 操作 \\- rc = lmcf-\u0026gt;init_handler(ctx-\u0026gt;log, lmcf, lmcf-\u0026gt;lua) \\- zone-\u0026gt;data = ctx: 设置数据字段 \\- zp = ngx_array_push(lmcf-\u0026gt;shdict_zones): 加入到 shdict_zones 数组中 \\- zone-\u0026gt;init = ngx_http_lua_shdict_init_zone: 设置初始化函数 \\- ctx-\u0026gt;sh = ngx_slab_alloc(ctx-\u0026gt;shpool, sizeof(ngx_http_lua_shdict_shctx_t)) \\- ngx_rbtree_init(\u0026amp;ctx-\u0026gt;sh-\u0026gt;rbtree, \u0026amp;ctx-\u0026gt;sh-\u0026gt;sentinel, ngx_http_lua_shdict_rbtree_insert_value): 初始化红黑树，也就是 shared dict 中的键值对是通过红黑树来组织的，查找插入都会比较快。 \\- ngx_queue_init(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue): 初始化 lru 队列，同样是用来管理键值对的，空间不足时，就淘汰旧的键值对。 \\- ctx-\u0026gt;shpool-\u0026gt;log_ctx = ngx_slab_alloc(ctx-\u0026gt;shpool, len): 初始化日志消息 \\- zone-\u0026gt;data = ctx: 设置数据字段 这个函数主要做了以下事情：\n 获取并检查名称、大小参数 分配 shared dict 上下文结构 分配shared dict、设置相关初始化函数 加入到 main 配置的 shdict_zones 数组中  ngx_http_lua_shared_memory_add 只是注册一个新的 shared dict，不会立即分配对应大小的内存。\nngx.shared.DICT.get get 接口的实现，在 2019.8.1（commit ID: 947fa0088b7a0387f43eb016436a2e4462eb5746）中，把接口注入的方式改成了 FFI 的方式。这些 FFI C 接口在 lau-nginx-module 项目中，Lua 接口在 lua-resty-core 项目中。\n- shdict_get \\- check_zone: 检查 zone（shared dict）是否有效 \\- if key_len \u0026gt; 65535 then: 检查 key 的类型和长度。长度不能大于 65535 \\- local size = get_string_buf_size(): 获取一块空间来存储值，默认空间大小是 4096 字节 \\- ngx_http_lua_ffi_shdict_get: 获取值 \\- hash = ngx_crc32_short(key, key_len): 使用 CRC 算法生成一个 HASH 值 \\- ngx_shmtx_lock(\u0026amp;ctx-\u0026gt;shpool-\u0026gt;mutex): 加锁 \\- ngx_http_lua_shdict_expire(ctx, 1): 删除 1~2 个过期的数据条目，如果传值是 1，则不管过没过期，一定会删除 1 个数据条目。 \\- while (n \u0026lt; 3): 最多删除 3 个数据，n 是传进来的 \\- if (ngx_queue_empty(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue)): 队列空了，直接返回 \\- q = ngx_queue_last(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue): 获取队列中最旧的一个数据 \\- sd = ngx_queue_data(q, ngx_http_lua_shdict_node_t, queue): 获取数据 \\- if (n++ != 0): n 不等于 0，就需要检查过期时间，过期了才删除 \\- if (sd-\u0026gt;value_type == SHDICT_TLIST): 如果是列表，则遍历列表，然后一个一个删除。 \\- ngx_queue_remove(q): 从 LRU 队列中删除 \\- ngx_rbtree_delete(\u0026amp;ctx-\u0026gt;sh-\u0026gt;rbtree, node): 从红黑树中删除 \\- ngx_slab_free_locked(ctx-\u0026gt;shpool, node): 以加锁的方式从 slab 内存池中删除 \\- rc = ngx_http_lua_shdict_lookup(zone, hash, key, key_len, \u0026amp;sd): 进行检索 \\- while (node != sentinel): 在红黑树中进行查找，没到哨兵节点时，就一直找 \\- if (hash \u0026lt; node-\u0026gt;key): 先检查 hash (前面 ngx_crc32_short 生成的)，hash 相等，才有可能是要找的 key。 \\- if (hash \u0026gt; node-\u0026gt;key): 不是这个节点，往右找 \\- rc = ngx_memn2cmp(kdata, sd-\u0026gt;data, klen, (size_t) sd-\u0026gt;key_len): hash 值相等了，就比较 key 是否相同，相同证明就是要找的 \\- if (rc == 0): 找到了 \\- ngx_queue_remove(\u0026amp;sd-\u0026gt;queue) \\- ngx_queue_insert_head(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue, \u0026amp;sd-\u0026gt;queue): 刚访问过，放到队首去 \\- return NGX_DONE/NGX_OK: 过期返回 NGX_DONE，没过期返回 NGX_OK \\- *str_value_len = value.len: 根据不同的类型（字符串、数字、布尔），进行长度赋值 \\- ngx_memcpy(*str_value_buf, value.data, value.len): 根据不同的类型（字符串、数字、布尔），进行数据复制 \\- *user_flags = sd-\u0026gt;user_flags: 是否强制覆盖其他有效条目的标记 \\- ngx_shmtx_unlock(\u0026amp;ctx-\u0026gt;shpool-\u0026gt;mutex): 解锁 \\- *is_stale = (rc == NGX_DONE): 如果是获取 stale 的接口，则判断是否过期 \\- if typ == 4 then: 值的类型只能是字符串(4)、数字(3)、布尔值(1)，如果是字符串时，会检查返回的值的指针是否和传进去的一致，如果不一致，表示是值太大，动态分配的内存，复制成 Lua 字符串后，会调用 C.free() 进行释放。 这个接口主要进行了以下操作：\n 主要的参数检查，在 Lua 接口中进行 对内存池进行加锁（内存池级别） 尝试释放 1~2 个过期数据 然后在红黑树中进行搜索。如果找到，就把数据放到 LRU 队列首部，表示刚刚被访问过 最后把数据复制到传进来的内存中或者是另外申请一块内存（如果值太大），返回给 Lua 接口  ngx.shared.DICT.set - shdict_set \\- shdict_store \\- check_zone(zone): 检查shared dict是否有效 \\- if not exptime then: 检查 exptime、key 等参数是否合法 \\- if valtyp == \u0026quot;string\u0026quot; then: 检查值的类型，可以是 \u0026quot;string\u0026quot;, \u0026quot;number\u0026quot;, nil, \u0026quot;boolean\u0026quot;；如果不是这 4 种类型，就报错返回。 \\- ngx_lua_ffi_shdict_store \\- hash = ngx_crc32_short(key, key_len): 生成 hash 值 \\- switch (value_type): 统一把值转换到 1 对变量中（str_value_buf 和 str_value_len），\u0026quot;number\u0026quot;, nil, \u0026quot;boolean\u0026quot; 这三种类型才需要转换 \\- ngx_shmtx_lock(\u0026amp;ctx-\u0026gt;shpool-\u0026gt;mutex): 加锁 \\- ngx_http_lua_shdict_expire(ctx, 1): 释放 1~2 个过期数据条目 \\- rc = ngx_http_lua_shdict_lookup(zone, hash, key, key_len, \u0026amp;sd): 查找一下，看是否能找到 \\- if (op \u0026amp; NGX_HTTP_LUA_SHDICT_REPLACE): 如果是替换，并且没找到，就报错返回；否则就跳到替换的逻辑去执行 \\- if (op \u0026amp; NGX_HTTP_LUA_SHDICT_ADD): 如果是增加，但是找到并且没过期，就报错返回；找到但过期，就执行替换操作；没找到，就执行增加操作。 \\- else: 接下来是普通的 SET 操作 \\- if (rc == NGX_OK || rc == NGX_DONE): 找到并且没过期，或者是找到但过期 \\- if (value_type == LUA_TNIL): 如果是 nil，则表示是删除数据，跳到删除的逻辑去 \\- replace(goto 标记): 替换逻辑开始 \\- if (str_value_buf \u0026amp;\u0026amp; str_value_len == (size_t) sd-\u0026gt;value_len \u0026amp;\u0026amp; sd-\u0026gt;value_type != SHDICT_TLIST): 找到并且值的大小没变，就复用 \\- ngx_queue_remove(\u0026amp;sd-\u0026gt;queue) \\- ngx_queue_insert_head(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue, \u0026amp;sd-\u0026gt;queue): 插入到队首，表示刚访问过 \\- ngx_memcpy(sd-\u0026gt;data + key_len, str_value_buf, str_value_len): 把新值复制过去，然后解锁返回 \\- ngx_shmtx_unlock(\u0026amp;ctx-\u0026gt;shpool-\u0026gt;mutex) \\- else: 先删除，再插入 \\- remove(goto 标记): 删除逻辑开始 \\- if (sd-\u0026gt;value_type == SHDICT_TLIST): 如果是 list，则遍历删除列表内元素 \\- ngx_queue_remove(\u0026amp;sd-\u0026gt;queue): 从 LRU 队列中删除自身（不管是不是 list 类型） \\- ngx_rbtree_delete(\u0026amp;ctx-\u0026gt;sh-\u0026gt;rbtree, node): 从红黑树中删除自身 \\- ngx_slab_free_locked(ctx-\u0026gt;shpool, node): 从内存池中释放内存 \\- else: 数据没找到，直接新分配一个 \\- insert(goto 标记): 插入逻辑开始，数据不存在或者是新旧值的大小不匹配 \\- if (str_value_buf == NULL): 如果是 set(key, nil)，也就是删除操作，则直接解锁返回，因为前面已经删除了 \\- node = ngx_slab_alloc_locked(ctx-\u0026gt;shpool, n): 分配内存 \\- if (node == NULL): 没内存了 \\- if (op \u0026amp; NGX_HTTP_LUA_SHDICT_SAFE_STORE): 如果是 safe_set，直接报错返回 \\- for (i = 0; i \u0026lt; 30; i++): 否则尝试 30 次强制释放数据，如果还是没能释放掉并申请到想要的大小的内存，就也报错返回 \\- ngx_http_lua_shdict_expire \\- ngx_slab_alloc_locked \\- allocated(goto 标记): 分配逻辑开始 —— 其实内存已经分配好，现在是进行数据赋值等操作 \\- sd-\u0026gt;user_flags = user_flags: 设置超时时间，用户标记等 \\- p = ngx_copy(sd-\u0026gt;data, key, key_len): 复制 key \\- ngx_memcpy(p, str_value_buf, str_value_len): 复制 value \\- ngx_rbtree_insert(\u0026amp;ctx-\u0026gt;sh-\u0026gt;rbtree, node): 加入到红黑树中 \\- ngx_queue_insert_head(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue, \u0026amp;sd-\u0026gt;queue): 加入到 LRU 队列的队首 \\- ngx_shmtx_unlock(\u0026amp;ctx-\u0026gt;shpool-\u0026gt;mutex): 解锁返回 这个接口主要进行了以下操作：\n 在 Lua 接口中进行参数检查，key、flag、超时时间等 在 C 接口中进行参数检查，值的类型只能是 \u0026ldquo;string\u0026rdquo;, \u0026ldquo;number\u0026rdquo;, nil, \u0026ldquo;boolean\u0026rdquo; 这 4 种 对内存池进行加锁（内存池级别），开始执行变更操作 尝试释放 1~2 个过期数据 然后在红黑树中进行搜索  如果找到，并且  传进来的值是 nil，表示删除，跳到删除的逻辑 传进来的值不是 nil，旧的值也不是 list 类型，并且值的长度相等，说明可用复用，直接把新值复制过去即可 是 list 类型，则进行遍历删除 不是 list 类型，并且值的长度不相等，则删除旧的值，再分配新的空间存新的值     如果没找到，直接插入新的数据  ngx.shared.DICT.lpush 列表系列的接口则还是通过 C 接口注入的方式。\n- ngx_http_lua_inject_ngx_api \\- ngx_http_lua_inject_shdict_api \\- lua_pushcfunction(L, ngx_http_lua_shdict_lpush) \\- lua_setfield(L, -2, \u0026quot;lpush\u0026quot;) 接下来直接跟踪一下 ngx_http_lua_shdict_lpush：\n- ngx_http_lua_shdict_lpush \\- ngx_http_lua_shdict_push_helper \\- n = lua_gettop(L): 获取参数数量，进行参数检查。 \\- zone = ngx_http_lua_shdict_get_zone(L, 1): 获取shared dict，同时也是算是参数检查的一部分。 \\- if (lua_isnil(L, 2)): 检查第二个参数 key，key 不能为 nil，不能是空字符串，不能太长（多于 65535 字节） \\- hash = ngx_crc32_short(key.data, key.len): 计算 key 的 hash 值 \\- value_type = lua_type(L, 3): 获取要 push 的值的类型，只能是 string 和 number 类型 \\- ngx_shmtx_lock(\u0026amp;ctx-\u0026gt;shpool-\u0026gt;mutex): \\- ngx_http_lua_shdict_expire(ctx, 1): \\- rc = ngx_http_lua_shdict_lookup(zone, hash, key.data, key.len, \u0026amp;sd) \\- if (rc == NGX_DONE): key 存在但过期了 \\- if (sd-\u0026gt;value_type != SHDICT_TLIST): 如果旧的 key 对应的值不是 list 类型，则先删除旧的值，再插入新值 \\- ngx_queue_remove(\u0026amp;sd-\u0026gt;queue) \\- ngx_rbtree_delete(\u0026amp;ctx-\u0026gt;sh-\u0026gt;rbtree, node) \\- ngx_slab_free_locked(ctx-\u0026gt;shpool, node) \\- goto init_list: 跳到初始化 list 的部分 \\- else: 是 list 类型，但是过期了 \\- queue = ngx_http_lua_shdict_get_list_head(sd, key.len): 逐个释放所有的数据 \\- lnode = ngx_queue_data(q, ngx_http_lua_shdict_list_node_t, queue) \\- ngx_slab_free_locked(ctx-\u0026gt;shpool, lnode) \\- ngx_queue_init(queue): 重新初始化值队列（注意不是 LRU 队列） \\- ngx_queue_remove(\u0026amp;sd-\u0026gt;queue) \\- ngx_queue_insert_head(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue, \u0026amp;sd-\u0026gt;queue): 重新插入到 LRU 队列首部 \\- goto push_node: 跳到 push 数据的部分 \\- if (rc == NGX_OK): key 存在并且没过期 \\- if (sd-\u0026gt;value_type != SHDICT_TLIST): 如果久的值不是 list 类型，就报错退出 \\- queue = ngx_http_lua_shdict_get_list_head(sd, key.len): 获取值队列 \\- ngx_queue_remove(\u0026amp;sd-\u0026gt;queue): \\- ngx_queue_insert_head(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue, \u0026amp;sd-\u0026gt;queue): 老样子，刚访问过，放到 LRU 队首 \\- goto push_node: 跳到 push 数据的部分 \\- else: rc == NGX_DECLINED, key 没找到，或者从其他地方跳过来 \\- init_list(goto 标记) \\- n = offsetof(ngx_rbtree_node_t, color) + offsetof(ngx_http_lua_shdict_node_t, data) + key.len + sizeof(ngx_queue_t): 计算需要分配的空间大小，ngx_queue_t 这块即是值队列。 \\- n = (int) (uintptr_t) ngx_align_ptr(n, NGX_ALIGNMENT): 计算对齐后的大小 \\- node = ngx_slab_alloc_locked(ctx-\u0026gt;shpool, n): 加锁的方式分配内存 \\- ngx_memcpy(sd-\u0026gt;data, key.data, key.len): 然后就是把信息填充到分配的空间中，复制 key \\- ngx_queue_init(queue): 初始化值的队列 \\- ngx_rbtree_insert(\u0026amp;ctx-\u0026gt;sh-\u0026gt;rbtree, node): 把新的 key 插入到红黑树中 \\- ngx_queue_insert_head(\u0026amp;ctx-\u0026gt;sh-\u0026gt;lru_queue, \u0026amp;sd-\u0026gt;queue): 把新的 key 插入到 LRU 首部 \\- push_node(goto 标记) \\- n = offsetof(ngx_http_lua_shdict_list_node_t, data) + value.len: 计算要 push 的值的大小 \\- lnode = ngx_slab_alloc_locked(ctx-\u0026gt;shpool, n): 分配空间 \\- if (lnode == NULL): 分配出错了——没空间了 \\- if (sd-\u0026gt;value_len == 0): 如果列表中没有元素，就删除这个 key (LRU 队列和红黑树) \\- lua_pushliteral(L, \u0026quot;no memory\u0026quot;): 直接报错。 \\- else: 分配成功了 \\- ngx_memcpy(lnode-\u0026gt;data, value.data, value.len): 复制 value 到目标内存中 \\- if (flags == NGX_HTTP_LUA_SHDICT_LEFT): 如果是 lpush，就插入到列表头部 \\- ngx_queue_insert_head(queue, \u0026amp;lnode-\u0026gt;queue) \\- else: 否则，插入到列表尾部 \\- ngx_queue_insert_tail(queue, \u0026amp;lnode-\u0026gt;queue) 这个函数的主要逻辑是：\n 先找 key 是否存在于shared dict中 如果 key 存在，就检查过期了没有 过期了，如果是 list 类型，就直接复用，只是删除列表里面的所有值；如果不是 list 类型，直接删除这个 key。 没过期，如果是 list 类型，就表示是要找的那个 list，直接 push，如果不是 list 类型，就报错返回，说明不是要找的，用户操作错了。 如果 key 不存在，就直接初始化一个 list，然后把值 push 进去。  总结  如何定义 lua_shared_dict 的，lua_shared_dict 做了哪些工作？  答：主要是注册 shared dict、初始化 LRU 队列、初始化红黑树。\n 这些 Lua 接口是否是原子的？是否需要考虑竞争问题？原子性是如何保证的？  答：是原子的。首先每个进程只有是一个线程；另外通过锁来保证进程之间的数据同步。\n ngx_http_lua_shdict_shctx_t 等关键数据结构是什么作用？它们之间有什么联系？  答：主要涉及一下数据结构：\n ngx_http_lua_shm_zone_ctx_t: 用于维护共享内存本身，其中元素会只向实际的 ngx_shm_zone_t。 ngx_http_lua_shdict_ctx_t: 描述整个 shared dict。包括名称、slab 内存池、main 配置指针，同时也有一个元素指向 ngx_http_lua_shdict_shctx_t。 ngx_http_lua_shdict_shctx_t: 和 ngx_http_lua_shdict_ctx_t 一起表示整个 shared dict。这里主要是存储 lru 队列、红黑树相关内容。 ngx_http_lua_shdict_node_t: 用于表示一个 shared dict 键值对。  详细结构定义见 ngx_shared_dict.md\n内存分布：\n list 类型, - 表示减去  [ngx_rbtree_node_t-color-data|color|ngx_http_lua_shdict_node_t-data|key|ngx_queue_t] ngx_rbtree_node_t 和 ngx_http_lua_shdict_node_t 交接在一起了，公用了一些元素。 ngx_http_lua_shdict_node_t 的 data 就是 key 的开始，包含了 key 的首个字符。 ngx_queue_t 是双端队列，用于存储所有值。\n list 中每个值, - 表示减去  [ngx_http_lua_shdict_list_node_t-data|value] ngx_http_lua_shdict_list_node_t 的 data 是 value 的开始，存储了 value 的一个字符。\n 非 list 类型，- 表示减去  [ngx_rbtree_node_t-color-data|color|ngx_http_lua_shdict_node_t-data|key|value] 和 list 类型类似，只是最后在 key 后面存的是 value，而不再是队列。\n","date":"2023-05-03T06:00:05-03:00","image":"https://isshe.site/p/openresty-%E5%85%B1%E4%BA%AB%E5%AD%97%E5%85%B8%E5%86%85%E5%AD%98/image_hub58aa43631c748bc46260e35845799bd_220559_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E5%85%B1%E4%BA%AB%E5%AD%97%E5%85%B8%E5%86%85%E5%AD%98/","title":"OpenResty 共享字典（内存）"},{"content":"OpenResty 加载及缓存 Lua 代码 目的：\n 了解 OpenResty 是如何加载及缓存 Lua 代码的。  加载 Lua 代码之前的代码逻辑见 005-rewrite_by_lua.md，本文接着从 ngx_http_lua_cache_loadbuffer 开始深入。\nngx_http_lua_cache_loadbuffer - ngx_http_lua_cache_loadbuffer: 加载 Lua 代码 \\- ngx_http_lua_cache_load_code: 从缓存中加载，有直接返回，没有则继续。 \\- lua_pushlightuserdata(L, ngx_http_lua_lightudata_mask(code_cache_key)) \\- lua_rawget(L, LUA_REGISTRYINDEX): 把 Lua 代码缓存表加载到栈顶 \\- if (*ref == LUA_NOREF): 通过 ref 和 key 结合来获取缓存。如果有 ref，就用 ref，如果没有，就用 key。如果用 key 也没找到，就是没缓存，后续需要加载。 \\- lua_isfunction: 这是闭包工厂函数，通过此函数来生成闭包 \\- rc = lua_pcall(L, 0, 1, 0): 正式调用闭包工厂，生成闭包，返回值是 0 表示成功，否则就是失败了。 \\- ngx_http_lua_clfactory_loadbuffer: 加载闭包工厂 \\- lua_load(L, ngx_http_lua_clfactory_getS, \u0026amp;ls, name): 加载 Lua Chunk 成一个函数。这个函数其实是一个闭包 \u0026#34;return function() ... end\u0026#34;，其中 \u0026#34;return function\u0026#34; 和 \u0026#34;end\u0026#34; 是 ngx_http_lua_clfactory_getS 函数固定添加的 \\- ngx_http_lua_clfactory_getS: 这个 lua_load 的 reader 参数，用于读取 lua chunk。 \\- ngx_http_lua_cache_store_code: 把闭包工厂存到 cache 中，并返回一个闭包。 \\- lua_rawget(L, LUA_REGISTRYINDEX): 获取注册表 \\- lua_setfield(L, -2, key): 把 key 和闭包工厂设置到 cache 注册表中，或者是把 key、ref、闭包工厂设置到 cache 注册表中。 \\- rc = lua_pcall(L, 0, 1, 0): 生成一个闭包放到栈顶 最终结果：加载 Lua 代码到栈顶。\n此函数的主要过程：\n 查找缓存表中保存的闭包工厂，有就用这个闭包工厂生产一个闭包。 没有找到，则从代码块加载，固定加生成 \u0026ldquo;return function() \u0026hellip; end\u0026rdquo; 这样的代码块，加载成闭包工厂。 缓存得到的闭包工厂（不是具体的闭包），然后调用闭包工厂，返回一个闭包。（每次调用闭包工厂都会返回一个闭包）  这也就是 Lua 代码加载及缓存的过程。\n","date":"2023-04-22T06:00:02-03:00","image":"https://isshe.site/p/openresty-lua-%E4%BB%A3%E7%A0%81%E5%8A%A0%E8%BD%BD/image_hu413041019d95a132c5e6526329e5bb43_166854_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-lua-%E4%BB%A3%E7%A0%81%E5%8A%A0%E8%BD%BD/","title":"OpenResty Lua 代码加载"},{"content":"rewrite_by_lua* rewrite_by_lua* 充当一个 rewrite 阶段的处理程序，对每个请求执行指定的 Lua 代码，代码会在独立的全局环境（沙箱）中执行。\n用法  上下文: http, server, location, location if 阶段: rewrite tail  注意：执行阶段晚于标准 ngx_http_rewrite_module 模块。   语法：  与 init_by_lua* 类似，不再赘述。   注意：  如果 rewrite_by_lua* 指定的 Lua 代码中通过 ngx.exit(code) 退出，如果 code = ngx.OK（非 ngx.HTTP_OK），则会继续执行!    实现  以 rewrite_by_lua_block 为例\n 开始前，还是如以往一样，先明确此行的目的：\n 解析指令时，做了什么？猜测和前面两个没有太大差别。 在什么时候实际执行了 Lua 代码？如何执行的？每个请求都会执行这个，想必处理方法应该不同以往。 还提到“全局环境（沙箱）”，是什么呢？  指令定义 { ngx_string(\u0026#34;rewrite_by_lua_block\u0026#34;), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF |NGX_CONF_BLOCK|NGX_CONF_NOARGS, ngx_http_lua_rewrite_by_lua_block, NGX_HTTP_LOC_CONF_OFFSET, 0, (void *) ngx_http_lua_rewrite_handler_inline },  NGX_HTTP_LIF_CONF：location if 配置 ngx_http_lua_rewrite_by_lua_block：配置解析时执行的函数。 ngx_http_lua_rewrite_handler_inline：实际执行 Lua 代码的函数。  还是围绕 3 点展开：\n 指令解析函数 ngx_http_lua_rewrite_by_lua_block 做了什么？ 处理程序（cmd-\u0026gt;post, ngx_http_lua_rewrite_handler_inline）在什么时候执行的？ 处理程序（cmd-\u0026gt;post, ngx_http_lua_rewrite_handler_inline）做了什么？  ngx_http_lua_rewrite_by_lua_block 执行流程 - cf-\u0026gt;handler = ngx_http_lua_rewrite_by_lua;：直接设置处理程序，看起来是直接复用了，和 rewrite_by_lua 使用的同一个函数。 \\- ngx_http_lua_conf_lua_block_parse \\- if (cf-\u0026gt;conf_file-\u0026gt;file.fd != NGX_INVALID_FILE)：检查一下配置文件的文件描述符，有效，则认为是在配置文件中使用的指令。无效，则认为是通过 Nginx 参数(-g)调用的。 \\- ngx_http_lua_conf_read_lua_token：解析配置 \\- rv = (*cf-\u0026gt;handler)(cf, cmd, cf-\u0026gt;handler_conf)：调用 ngx_http_lua_rewrite_by_lua 设置 rewrite_handler \\- if (cmd-\u0026gt;post == NULL)：没有设置执行 Lua 代码的函数，则返回 \\- if (llcf-\u0026gt;rewrite_handler)：已经设置过处理程序了，也直接返回 \\- if (cmd-\u0026gt;post == ngx_http_lua_rewrite_handler_inline)：Lua 代码是在内存中，表示用的 rewrite_by_lua_block 或 rewrite_by_lua 指令 。 \\- ngx_http_lua_gen_chunk_name：生成代码块名称，示例：=rewrite_by_lua(nginx.conf:50) \\- ngx_http_lua_gen_chunk_cache_key：生成代码块缓存用的 key，示例：rewrite_by_lua_nhli_6f30fa99b87d7f63b59c913687f45f65 \\- else: Lua 代码在文件中，用的 rewrite_by_lua_file 指令（拓展一下） \\- ngx_http_compile_complex_value：文件名中可能有变量，场景：从请求 URL 中取一部分作为文件名。 \\- if (llcf-\u0026gt;rewrite_src.lengths == NULL)：文件名中没有变量 \\- ngx_http_lua_gen_file_cache_key：生成 cache key（注意文件名如果有变量，则不进行 cache） \\- llcf-\u0026gt;rewrite_handler = (ngx_http_handler_pt) cmd-\u0026gt;post：设置回调，也就是 ngx_http_lua_rewrite_handler_inline \\- ngx_http_conf_get_module_main_conf：获取配置 \\- lmcf-\u0026gt;requires_rewrite = 1：设置标记，表示需要注册 rewrite handler \\- lmcf-\u0026gt;requires_capture_filter = 1：设置标记，表示需要设置过滤器拦截请求的响应。 文件名中允许变量的示例：\n location ~ ^/app/([-_a-zA-Z0-9/]+) { set $path $1; rewrite_by_lua_file /path/to/lua/app/root/$path.lua; } ngx_http_lua_rewrite_handler_inline 的调用位置 根据前面的执行流程，我们知道处理程序是被设置在了 rewrite_handler 中，通过搜索，我们得到\n- ngx_http_lua_rewrite_handler \\- rewrite_handler 那么 ngx_http_lua_rewrite_handler 是通过在哪里调用了呢？ 通过搜索 ngx_http_lua_rewrite_handler，在 ngx_http_lua_init 函数中找到以下代码：\n ngx_http_lua_init 相关内容可见 001-module-init.md) 或 002-init_by_lua.md\n  if (lmcf-\u0026gt;requires_rewrite) { h = ngx_array_push(\u0026amp;cmcf-\u0026gt;phases[NGX_HTTP_REWRITE_PHASE].handlers); if (h == NULL) { return NGX_ERROR; } *h = ngx_http_lua_rewrite_handler; } 可见，ngx_http_lua_rewrite_handler 被添加到了 REWRITE 阶段的处理程序数组中。\n接下来我们直接使用 gdb 获取调用栈：\n $ gdb -p PID\n b ngx_http_lua_rewrite_handler bt\n  #0 ngx_http_lua_rewrite_handler (r=0x0) at ../ngx_lua-0.10.21/src/ngx_http_lua_rewriteby.c:26 #1 0x0000564c0906158e in ngx_http_core_rewrite_phase (r=0x564c09c74750, ph=0x564c09c9bea0) at src/http/ngx_http_core_module.c:939 #2 0x0000564c090613de in ngx_http_core_run_phases (r=0x564c09c74750) at src/http/ngx_http_core_module.c:885 #3 0x0000564c09061347 in ngx_http_handler (r=0x564c09c74750) at src/http/ngx_http_core_module.c:868 #4 0x0000564c09072044 in ngx_http_process_request (r=0x564c09c74750) at src/http/ngx_http_request.c:2120 #5 0x0000564c09070710 in ngx_http_process_request_headers (rev=0x564c09cb2f00) at src/http/ngx_http_request.c:1498 #6 0x0000564c0906fa6a in ngx_http_process_request_line (rev=0x564c09cb2f00) at src/http/ngx_http_request.c:1165 #7 0x0000564c0906e061 in ngx_http_wait_request_handler (rev=0x564c09cb2f00) at src/http/ngx_http_request.c:503 #8 0x0000564c0904a223 in ngx_epoll_process_events (cycle=0x564c09c70740, timer=60000, flags=1) at src/event/modules/ngx_epoll_module.c:901 #9 0x0000564c09035ee2 in ngx_process_events_and_timers (cycle=0x564c09c70740) at src/event/ngx_event.c:257 #10 0x0000564c09047402 in ngx_worker_process_cycle (cycle=0x564c09c70740, data=0x0) at src/os/unix/ngx_process_cycle.c:793 ... 读事件到达 worker 进程后，相应的事件处理模块（不同系统应当是使用了不同的事件模块，例如 Linux 使用 epoll，Unix 使用 kqueue ）调用读事件处理程序对请求进行读取并解析，然后调用各个阶段的处理程序。\n（请求的处理过程及阶段切换过程，在后续的 Nginx 系列文章中进行补充。）\nngx_http_lua_rewrite_handler 执行流程 - ngx_http_lua_rewrite_handler \\- if (r-\u0026gt;uri_changed)：URI 已经改变了，直接进行下一个模块 [1] \\- ngx_http_get_module_main_conf：获取模块配置 \\- if (!lmcf-\u0026gt;postponed_to_rewrite_phase_end)：是否作为 rewrite 阶段最后一个处理程序，默认为会放到最后。做法是交换当前处理程序和最后处理程序，然后 r-\u0026gt;phase_handler-- 来重跑当前位置的处理程序（交换成新的了），避免执行漏了交换过来的这个。 \\- ngx_http_get_module_loc_conf：获取模块的 location 配置 \\- if (llcf-\u0026gt;rewrite_handler == NULL)：如果处理程序没有设置，则不用继续了，直接下一个。 \\- ngx_http_get_module_ctx：获取模块上下文 \\- ngx_http_lua_create_ctx：没获取到模块上下文，则创建一个 \\- if (ctx-\u0026gt;entered_rewrite_phase)：如果已经进入过了，那么说明处理只是暂停了（等待更多资源之类的） \\- resume_handler：恢复 \\- if (ctx-\u0026gt;waiting_more_body)：需要更多请求体，返回等下次调用 \\- if (llcf-\u0026gt;force_read_body \u0026amp;\u0026amp; !ctx-\u0026gt;read_body_done)：如果需要读取请求体并且请求体没读完 \\- ngx_http_read_client_request_body：读取请求体，处理程序是 ngx_http_lua_generic_phase_post_read \\- rewrite_handler：调用 ngx_http_lua_rewrite_handler_inline，执行 Lua 代码 \\- ngx_http_get_module_loc_conf：获取 location 配置 \\- ngx_http_lua_get_lua_vm：获取 Lua VM \\- ngx_http_lua_cache_loadbuffer：加载 Lua 代码 \\- ngx_http_lua_cache_load_code：从缓存中加载，有直接返回，没则继续。 \\- ngx_http_lua_clfactory_loadbuffer：加载闭包工厂 \\- ngx_http_lua_cache_store_code：存到 cache 中 \\- ngx_http_lua_rewrite_by_chunk：执行 Lua 代码 \\- ngx_http_lua_new_thread：创建新协程 \\- ngx_http_lua_get_globals_table \\- lua_setfenv：把新协程的 global 表成闭包的 env 表。 \\- ngx_http_lua_run_thread：执行 Lua 代码  ngx_http_lua_cache_loadbuffer 相关函数见：018-load_cache_lua_code.md 执行代码前，把 Lua 代码闭包的 env 表设置成了新协程的 global 表了，因此相当于在“沙箱”中执行 Lua 代码。  （到此，我们前面提到的“目的”，就都知道答案了。）\n疑问 [1]：uri 变了为什么就不再执行 rewrite_by_lua* ？\n location / { rewrite ^/xyz\\.html$ /abc.html; # rewrite ^/xyz\\.html$ /abc.html last; # rewrite ^/xyz\\.html$ /abc.html break; rewrite_by_lua_block { return ngx.exec(\u0026quot;/after.html\u0026quot;) } }  无论是否使用 last/break，应该都是进了 ngx_http_lua_rewrite_handler 处理函数，只是 r-\u0026gt;uri_changed 控制了是否继续执行 Lua 处理程序。 大概还是需要了解 rewrite 指令如何实现才能解答这个问题。（与 last、break 搭配使用时等情况） 后续可参考文档：  http://chenzhenianqing.com/articles/576.html https://github.com/openresty/lua-nginx-module/blob/master/t/023-rewrite/sanity.t#L710   ngx_http_script.c 中有这么一段代码，其中 if (code-\u0026gt;break_cycle) 中设置 r-\u0026gt;uri_changed = 0 就是导致使用 rewrite x y break; 后，rewrite_by_lua* 还继续执行的原因。（实际其实 uri 是变了）   if (code-\u0026gt;uri) { r-\u0026gt;internal = 1; r-\u0026gt;valid_unparsed_uri = 0; if (code-\u0026gt;break_cycle) { r-\u0026gt;valid_location = 0; r-\u0026gt;uri_changed = 0; } else { r-\u0026gt;uri_changed = 1; } } ","date":"2023-04-18T06:00:02-03:00","image":"https://isshe.site/p/openresty-rewrite_by_lua/image_hu488b2f82ab20ee50f487200f2be764c2_242367_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-rewrite_by_lua/","title":"OpenResty rewrite_by_lua*"},{"content":"管道 目的：\n 有哪些使用场景？ 如何使用？在 OR 里面是如何使用的？ 由操作系统 shell 执行的字符串形式的命令行，会阻塞吗？ 如何实现的？ 在 proc_write 中 yield 出去后，是如何 resume 的？  使用 spawn —— 创建对象   语法：proc, err = pipe_module.spawn(args, opts?)\n  作用：创建并返回一个新的子流程实例。\n  参数：\n args：数组形式的命令或者是字符串形式的命令。  数组形式示例：{\u0026ldquo;ls\u0026rdquo;, \u0026ldquo;-l\u0026rdquo;} 字符串形式示例：\u0026ldquo;ls -l\u0026rdquo;。当使用此模式时，命令将由操作系统 shell 执行，就像 os.execute 一样。   opts：  merge_stderr：如果是 true，将合并 stderr 和 stdout 的输出，相当于 2\u0026gt;\u0026amp;1。 buffer_size：读取操作的缓冲区大小，默认是 4096 字节。 environ：环境变量。如果当前系统不支持环境变量，则返回 nil 和 \u0026ldquo;environ option not supported\u0026rdquo;。示例：{\u0026quot;PATH=/tmp/bin\u0026quot;, \u0026quot;CWD=/tmp/work\u0026quot;} write_timeout：写超时时间，单位是毫秒。默认是 10000，设置为 0 则永不超时。 stdout_read_timeout：标准输出读超时，单位是毫秒，默认是 10000，设置为 0 则永不超时。 stderr_read_timeout：标准错误读超时，单位是毫秒，默认是 10000，设置为 0 则永不超时。 wait_timeout：等待超时，单位是毫秒，默认是 10000，设置为 0 则永不超时。      返回值：\n 失败：返回 nil 和错误信息 成功：返回 pipe 对象    wait —— 等待当前子流程退出   语法： ok, reason, status = proc:wait()\n  作用：等待当前子流程退出，包括超时退出。\n  返回值：\n 成功：ok 值为 true 失败：ok 值为 false，reason 为一个字符串，如 \u0026ldquo;exit\u0026rdquo; 或 \u0026ldquo;signal\u0026rdquo;。  exit 时：status 将为 exit 的状态码。 signal 时，status 将为信号码。      kill —— 向子流程发送一个信号。   语法：ok, err = proc:kill(signum)\n  作用： 向子流程发送一个信号。\n  参数：\n signum：信号量数字。可以使用 lua-resty-signal 的 signum() 来获取信号量名称对应的信号量值。    返回值：\n 成功：true 失败：nil 和 错误字符串。如果是已经退出的子流程，则错误字符串为 \u0026ldquo;exited\u0026rdquo;。    shutdown —— 关闭当前子流程的 stderr、stderr 或 stdin   语法：ok, err = proc:shutdown(direction)\n  作用：关闭子流程的 stderr、 stderr 或 stdin。\n  参数：\n direction：stderr、stdout、stdin。    返回值：\n 成功：true  如果关闭一个轻线程正在等待的方向(stderr/stdout/stdin)，则返回 true。   失败：nil 和错误字符串。  如果指定了 merge_stderr，并且对 stderr 调用 shutdown，则返回 nil 和 \u0026ldquo;merged to stdout\u0026rdquo;。 如果子流程已经退出，则返回 nil 和 \u0026ldquo;closed\u0026rdquo;。      write —— 向子流程的 stdin 写入数据   语法：nbytes, err = proc:write(data)\n  作用：向子流程的 stdin 写入数据。\n  参数：\n data：需要写入的数据。    返回值：\n 成功：nbytes 表示成功写入的数据长度。 失败：nil 和错误字符串。  如果多个协程同时向当前子流程进行写入，则只有第一个成功，后续的调用都会返回 \u0026ldquo;pipe busy writing\u0026rdquo; 错误。 如果写操作被 shutdown 了，将返回 nil 和 \u0026ldquo;aborted\u0026rdquo;。 如果写已经退出的子流程，将返回 nil 和 \u0026ldquo;closed\u0026rdquo;。      stdout_read_、stderr_read_ —— 从 stderr 或 stdout 读取数据。  语法：  data, err, partial = proc:stderr_read_all() data, err, partial = proc:stdout_read_all() data, err, partial = proc:stderr_read_line() data, err, partial = proc:stdout_read_line() data, err, partial = proc:stderr_read_bytes(len) data, err, partial = proc:stdout_read_bytes(len) data, err = proc:stderr_read_any(max) proc:stdout_read_any(max) 比较简单，不再详细说明，可参考此文档：https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/pipe.md#stderr_read_all\n实现 相关 API 并不是通过 lua-nginx-module 注入的方式来实现。详见：\n pipe.lua  创建 pipe 对象 - pipe_spawn: 这部分是 Lua 代码，进行各种参数检查。 \\- ngx_http_lua_ffi_pipe_spawn: 创建 pipe 对象 \\- ngx_create_pool: 创建内存池 \\- pipe: 创建 3 个 pipe：对应 stdin、stdout、stderr；stderr 根据参数按需创建。 \\- fork: fork 进程 \\- 如果是子进程(fork 返回值是 0) \\- CPU_SET: 重新设置进程的 CPU 亲缘性 \\- sigaction: 重置已忽略信号的处理程序成 default(SIG_DFL) \\- sigprocmask(SIG_SETMASK, \u0026amp;set, NULL): 重置信号掩码 \\- ngx_close_socket(ls[i].fd): 关闭监听的套接字 \\- close(out[0]): 关闭不需要的管道套接字，如 stdin 的写（对子进程来说）；stdout 的读。 \\- dup2(in[0], STDIN_FILENO): 重定向标准输入、标准输入。 \\- close(in[0]): 关闭多余的套接字，如 stdin 的读。在 dup2 后，in[0] 会有 2 份，一份描述符是原来的 in[0]，另一份描述符是 STDIN_FILENO，因此关闭多余的 in[0]。 \\- execvpe/ngx_http_lua_execvpe/execvp：执行想要执行的命令(程序) \\- 如果是父进程（fork 返回值是子进程的 ID） \\- close: 关闭不需要的文件描述符，如标准输入的读，标准输出的写 \\- ngx_nonblocking: 把没关闭的文件描述符设置为非阻塞 \\- ngx_rbtree_insert: 设置好 pipe 对象，然后加入到红黑树中。 这个函数主要做了以下事情：\n 创建 2 或 3 个管道(pipe)，如果使用了 merge_stderr 则 2 个，否则 3 个。 然后 fork 进程 在子进程中关闭不要的 fd，并把标准输入和标准输出重定向到对应管道中 准备工作完成后，子进程执行执行命令 父进程也关闭不要的 fd，设置没关闭的 fd 成非阻塞，然后加入到红黑树中，进行管理。  向子流程的 stdin 写入数据 - proc_write: Lua 接口 \\- local rc = C.ngx_http_lua_ffi_pipe_proc_write: 进行写操作 \\- ngx_http_lua_pipe_init_ctx: 初始化 ctx。设置读写函数、初始化读写事件的处理函数。 \\- ngx_http_lua_chain_get_free_buf: 获取空间存放要写入的数据 \\- ngx_http_lua_pipe_write: 进行写操作 \\- c-\u0026gt;send: 实际的写入函数是 ngx_http_lua_pipe_fd_write \\- NGX_AGAIN: 返回值是 NGX_AGAIN 表示阻塞了 \\- pipe_ctx-\u0026gt;c-\u0026gt;data = ctx-\u0026gt;cur_co_ctx: 设置好 cur_co_ctx \\- ngx_handle_write_event: 添加写事件，事件处理函数是 ngx_http_lua_pipe_resume_write_handler。 \\- ngx_http_lua_pipe_resume_write_handler \\- ngx_http_lua_pipe_resume_helper \\- ngx_http_lua_pipe_clear_event: 把事件清理掉 \\- ctx-\u0026gt;cur_co_ctx = wait_co_ctx: 设置好 ctx \\- ngx_http_lua_pipe_resume: 已经进入 content 阶段，调用这个来环境 \\- ngx_http_core_run_phases: 否则，调用这个来唤醒 \\- ngx_http_run_posted_requests: 调用后续请求的处理 \\- ngx_add_timer(wev, timeout): 如果设置了超时时间，就添加到定时器中 \\- co_yield(): 如果前面调用的返回值是 FFI_AGAIN，则 yield 让出执行权 \\- rc = C.ngx_http_lua_ffi_pipe_get_write_result: 获取写结果 这个函数的主要实现思路是：\n 进行一次写入 如果没完成，就放到事件循环中 然后 yield 让出执行权 后续事件发生（可写或超时）在 resume 恢复后续执行  这个函数主要做了以下事情：\n 参数检查 把要写入的数据复制到 buffer 中 进行一次写入，根据写入结果进行后续操作 如果没写完，就监听写事件和设置定时器 然后让出执行权 后续 resume 回来后，调用 ngx_http_lua_ffi_pipe_get_write_result 来获取结果 如果还是没完成，就继续 yield 出去  从子流程的 stdout 读取数据 和写入数据是一样是思路，只是多了不同是读取模式，不再赘述。\n总结  有哪些使用场景？  答：用于执行系统命令。\n 由操作系统 shell 执行的字符串形式的命令行，会阻塞吗？  答：不会，当参数不是数组形式，会默认使用 /bin/sh 来执行命令。\n 在 proc_write 中 yield 出去后，是如何 resume 的？（如何实现的？）  答：进行读写操作时，如果一次完成不了，就设置好事件，然后 yiled 让出执行权；后续通过事件模块来进行 resume。\n","date":"2023-04-10T06:00:03-03:00","image":"https://isshe.site/p/openresty-%E7%AE%A1%E9%81%93pipe/image_hu85aaf5f0d41b0975ba4c41b921fc00cc_279865_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E7%AE%A1%E9%81%93pipe/","title":"OpenResty 管道（pipe）"},{"content":"OpenResty 中的 *_by_lua* 及阶段 目的：\n 了解都有哪些阶段：*_by_lua*。 了解各个阶段的执行时机，各阶段有什么限制：如是否可以 yield，原因是什么。  所有的 *_by_lua*：\n 执行阶段：指的是对应的 Nginx 的阶段\n   init_by_lua*：可用于加载配置、初始化全局变量等\n 上下文：无 执行阶段：初始化阶段是在 master 进程中 设置执行阶段的位置：无 是否可以 yield：否，初始化阶段，无需 yield。    init_worker_by_lua*：可用于加载 Lua 模块等\n 上下文：NGX_HTTP_LUA_CONTEXT_INIT_WORKER 执行阶段：初始化 worker 进程阶段 设置执行阶段的位置：无 是否可以 yield：否，初始化阶段，无需 yield。    ssl_client_hello_by_lua*：可以用于设置 TLS 算法，HTTP 协议版本(1.1/2/3)。\n 上下文：NGX_HTTP_LUA_CONTEXT_SSL_CLIENT_HELLO 执行阶段：客户端发来 Client Hello 时后，处理Client Hello 消息前 设置执行阶段的位置：SSL_CTX_set_client_hello_cb 是否可以 yield：是    ssl_session_fetch_by_lua*：根据客户端提供的 Session ID 查找并恢复会话。\n 上下文：NGX_HTTP_LUA_CONTEXT_SSL_SESS_FETCH 执行阶段：通常会在 ssl_certificate_by_lua* 前调用 设置执行阶段的位置：SSL_CTX_sess_set_get_cb 是否可以 yield：是 注意：使用 TLS session tickets 时，不会执行这个回调。    ssl_certificate_by_lua*：可用于动态设置服务器证书。\n 上下文：NGX_HTTP_LUA_CONTEXT_SSL_CERT 执行阶段：客户端发来 Client Hello 后，发送证书前 设置执行阶段的位置：SSL_CTX_set_cert_cb 是否可以 yield：是    ssl_session_store_by_lua*：可用于基于 Session ID 保存 SSL Session。\n 上下文：NGX_HTTP_LUA_CONTEXT_SSL_SESS_STORE 执行阶段：SSL/TLS 握手完成后 设置执行阶段的位置：SSL_CTX_sess_set_new_cb 是否可以 yield：否，该阶段的目的是将握手过程中得到的会话信息存储到共享存储区。不能 yield，但是仍然可以使用 ngx.timer.at 创建 0 延迟的计时器，以将 SSL 会话数据异步保存到外部服务（redis、memcached）。 注意：使用 TLS session tickets 时，不会执行这个回调。    set_by_lua*：可用于定义变量。\n 上下文：NGX_HTTP_LUA_CONTEXT_SET 执行阶段：rewrite 阶段 设置执行阶段的位置：通过 NDK 设置 是否可以 yield：否    rewrite_by_lua*： 可用于实现 URL 重写和参数修改等。\n 上下文：NGX_HTTP_LUA_CONTEXT_REWRITE 执行阶段：rewrite 阶段 设置执行阶段的位置：在 ngx_http_lua_init 中加入到 rewrite 阶段 handlers 中 是否可以 yield：是    access_by_lua*： 可用于访问控制，如 IP 黑白名单、权限鉴定等\n 上下文：NGX_HTTP_LUA_CONTEXT_ACCESS 执行阶段：access 阶段 设置执行阶段的位置：在 ngx_http_lua_init 中加入到 access 阶段 handlers 中 是否可以 yield：是    content_by_lua*： 可用于实现动态生成内容等\n 上下文：NGX_HTTP_LUA_CONTEXT_CONTENT 执行阶段：content 阶段 设置执行阶段的位置：在 ngx_http_lua_content_by_lua 配置解析函数中直接注册 location content handler 是否可以 yield：是    balancer_by_lua*： 可用于自定义负载均衡\n 上下文：NGX_HTTP_LUA_CONTEXT_BALANCER 执行阶段：content 阶段 设置执行阶段的位置：ngx_http_lua_balancer_by_lua 中重设 ngx_http_upstream_module 的 init_upstream 处理函数，进而重设 ngx_http_lua_balancer_get_peer，在里面会调用设置好的 cmd-\u0026gt;post 执行 Lua 代码 是否可以 yield：否    header_filter_by_lua*： 可用于增删改响应头部\n 上下文：NGX_HTTP_LUA_CONTEXT_HEADER_FILTER 执行阶段：output-header-filter（响应头过滤） 设置执行阶段的位置：在 ngx_http_lua_init 中加入到相关 filter 链中 是否可以 yield：否。需要进行异步操作使用 ngx.timer.at。以下 API 都被禁用了：  Output API functions (e.g., ngx.say and ngx.send_headers) Control API functions (e.g., ngx.redirect and ngx.exec) Subrequest API functions (e.g., ngx.location.capture and ngx. location.capture_multi) Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket).      body_filter_by_lua*： 可用于修改响应体\n 上下文：NGX_HTTP_LUA_CONTEXT_BODY_FILTER 执行阶段：output-body-filter（响应体过滤） 设置执行阶段的位置：在 ngx_http_lua_init 中加入到相关 filter 链中 是否可以 yield：否。禁用的 API 情况与 header_filter_by_lua* 一样。需要进行异步操作使用 ngx.timer.at。    log_by_lua*： 可用于记录日志到文件或发送到 redis 等服务器中\n 上下文：NGX_HTTP_LUA_CONTEXT_LOG 执行阶段：log 阶段 设置执行阶段的位置：在 ngx_http_lua_init 中加入到 Log 阶段 handlers 中 是否可以 yield：否。禁用的 API 情况与 header_filter_by_lua* 一样。需要进行异步操作使用 ngx.timer.at。    exit_worker_by_lua*： 可用于 worker 进程退出清理，worker 进程退出前执行\n 上下文：NGX_HTTP_LUA_CONTEXT_EXIT_WORKER 执行阶段：无 设置执行阶段的位置：无 是否可以 yield：否    ngx.timer\n 上下文：NGX_HTTP_LUA_CONTEXT_TIMER 是否可以 yield：是    ","date":"2023-04-02T06:00:02-03:00","image":"https://isshe.site/p/openresty-_by_lua-%E5%8F%8A%E9%98%B6%E6%AE%B5/image_huab6d4bf2fac89bf04d136b1532e709da_268856_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-_by_lua-%E5%8F%8A%E9%98%B6%E6%AE%B5/","title":"OpenResty *_by_lua* 及阶段"},{"content":"ngx.sleep 在 OpenResty 中，我们可以通过 ngx.sleep() 让出执行权进行“睡眠/挂起”，让当前请求暂停一段时间（单位为秒）后醒来。\n目的：\n 了解 ngx.sleep 的使用。 了解 ngx.sleep 的实现。 ngx.sleep()及其他 cosocket 相关的函数不能用在 init_by_lua/init_worker_by_lua/set_by_lua/header_filter_by_lua/body_filter_by_lua/log_by_lua 的原因是什么?  使用 ngx.sleep 的使用非常简单：\nngx.sleep(0.001) 睡眠时间的精度是毫秒（0.001 秒）。\n上下文：rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer., ssl_certificate_by_lua, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*\n实现 ngx.sleep 也是通过 C 代码注入的方式，对应的处理函数是：ngx_http_lua_ngx_sleep，我们直接来跟踪这个函数的实现。\n- ngx_http_lua_ngx_sleep \\- delay = (ngx_int_t) (luaL_checknumber(L, 1) * 1000)：将参数转换成毫秒 \\- coctx-\u0026gt;sleep.handler = ngx_http_lua_sleep_handler：填充 coctx-\u0026gt;sleep 事件 \\- ngx_add_timer(\u0026amp;coctx-\u0026gt;sleep, (ngx_msec_t) delay)：添加定时器 \\- return lua_yield(L, 0)：让出执行权 可以看到，时间到了以后，会调用 ngx_http_lua_sleep_handler：\n- ngx_http_lua_sleep_handler \\- ctx-\u0026gt;cur_co_ctx = coctx：设置当前协程 \\- if (ctx-\u0026gt;entered_content_phase)：如果不是 access、rewrite 阶段 \\- ngx_http_lua_sleep_resume：直接 resume \\- vm = ngx_http_lua_get_lua_vm(r, ctx)：获取 Lua 虚拟机 \\- rc = ngx_http_lua_run_thread(vm, r, ctx, 0)：继续跑协程 \\- else：否则如果是 access、rewrite 阶段，就设置回调，直接进入核心处理流程 \\- ctx-\u0026gt;resume_handler = ngx_http_lua_sleep_resume：设置 resume 回调 \\- ngx_http_core_run_phases(r)：然后继续回到核心处理逻辑 \\- ngx_http_run_posted_requests：执行后续的请求 在这个函数中，会恢复被暂停的 Lua 协程。\n总结 ngx.sleep 的实现比较简单，一句话总结： 设置好处理函数和定时器，然后让出执行权，时间到了触发事件调用设置好的处理函数来恢复执行。\n问题：\n1.ngx.sleep()及其他 cosocket 相关的函数不能用在 init_by_lua/init_worker_by_lua/set_by_lua/header_filter_by_lua/body_filter_by_lua/log_by_lua 的原因是什么?\n 答：这些阶段都不能 yield，需要是可以 yield 的阶段（NGX_HTTP_LUA_CONTEXT_YIELDABLE）。详见 OpenResty 中的 *_by_lua* 及阶段  ","date":"2023-04-02T06:00:02-03:00","image":"https://isshe.site/p/openresty-ngx.sleep/image_hufcdb8a4692f8ada50966e20cd23479ea_226817_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-ngx.sleep/","title":"OpenResty ngx.sleep"},{"content":"lua-nginx-module 模块的定义及初始化 lua_nginx_module 其实就是一个 Nginx 模块，定义及实现都需要按照 Nginx 模块的要求。\n这篇文章的目的是什么呢？\n 了解 lua-nginx-module 模块相关数据结构的定义。 了解 lua-nginx-module 模块大致的初始化流程，对 lua-nginx-module 模块有一个总体的概念，然后我们在后续的文章中，去细化追究相关指令的细节。  总分结构    定义  定义个全局的模块变量：   ngx_http_lua_module.c 此结构的详细解释可见 Nginx 数据结构 ngx_module_t\n ngx_module_t ngx_http_lua_module = { NGX_MODULE_V1, \u0026amp;ngx_http_lua_module_ctx, /* module context */ ngx_http_lua_cmds, /* module directives */ NGX_HTTP_MODULE, /* module type */ NULL, /* init master */ NULL, /* init module */ ngx_http_lua_init_worker, /* init process */ NULL, /* init thread */ NULL, /* exit thread */ ngx_http_lua_exit_worker, /* exit process */ NULL, /* exit master */ NGX_MODULE_V1_PADDING };  定义一个模块上下文  static ngx_http_module_t ngx_http_lua_module_ctx = { NULL, /* preconfiguration */ ngx_http_lua_init, /* postconfiguration */ ngx_http_lua_create_main_conf, /* create main configuration */ ngx_http_lua_init_main_conf, /* init main configuration */ ngx_http_lua_create_srv_conf, /* create server configuration */ ngx_http_lua_merge_srv_conf, /* merge server configuration */ ngx_http_lua_create_loc_conf, /* create location configuration */ ngx_http_lua_merge_loc_conf /* merge location configuration */ }; 可以看到被定义成了一个 HTTP 模块（NGX_HTTP_MODULE, ngx_http_module_t）。\nmain conf 见：ngx_http_lua_main_conf_t srv_conf 见：ngx_http_lua_srv_conf_t loc_conf 见：ngx_http_lua_loc_conf_t\n 定义指令  static ngx_command_t ngx_http_lua_cmds[] = { { ngx_string(\u0026quot;lua_load_resty_core\u0026quot;), NGX_HTTP_MAIN_CONF|NGX_CONF_FLAG, ngx_http_lua_load_resty_core, NGX_HTTP_MAIN_CONF_OFFSET, 0, NULL }, ... } 初始化 接下来，我们粗略地了解一下 模块初始化 和 进程初始化。\n模块初始化 Nginx 模块的初始化流程见：Nginx 模块初始化\n简而言之就是：\n 解析到相关配置指令（ngx_http_lua_cmds 数组中定义，如 init_by_lua），就执行指令的处理函数。  xxx_by_lua 指令的具体处理见后续的文章。   调用 ngx_http_lua_init 这个 postconfiguration 函数（详见上文的 “模块上下文 ngx_http_lua_module_ctx”）  init_by_lua 设置的 handler 在 postconfiguration 。    我们来看下 ngx_http_lua_init 这个函数做了什么。\nngx_http_lua_init 执行流程 - ngx_http_lua_init \\- if (lmcf-\u0026gt;requires_rewrite)：判断是否需要介入 rewrite 阶段的处理 \\- if (lmcf-\u0026gt;requires_access)：判断是否需要介入 access 阶段的处理 \\- if (lmcf-\u0026gt;requires_log)：判断是否需要介入 log 阶段的处理 \\- ngx_array_push：如果需要，就设置对应的 handler。 \\- 如：ngx_array_push(\u0026amp;cmcf-\u0026gt;phases[NGX_HTTP_REWRITE_PHASE].handlers); \\- if (multi_http_blocks || lmcf-\u0026gt;requires_header_filter)：判断是否需要接入 header_fitler 阶段 \\- ngx_http_lua_header_filter_init：如果需要介入，则会调用此函数把相关处理函数设置到调用链中。 \\= if (multi_http_blocks || lmcf-\u0026gt;requires_body_filter)：判断是否需要接入 body_fitler 阶段 \\- ngx_http_lua_body_filter_init：如果需要介入，则会调用此函数把相关处理函数设置到调用链中。 \\- ngx_pool_cleanup_add：添加内存池清理函数 \\- ngx_http_lua_pipe_init：初始化一颗红黑树，用于管道处理，见 [pipe](015-pipe.md)。 \\- ngx_http_lua_init_vm：如果没有初始化 Lua VM，则初始化。lua_State 设置在 lmcf-\u0026gt;lua 中。 \\- init_handler(ngx_http_lua_init_by_inline)：执行 Lua 代码 可以看到，配置解析完后（postconfiguration）， 立即初始化 Lua VM ，然后调用了 ngx_http_lua_init_by_inline。 注意：上面并没有类似于 lmcf-\u0026gt;requires_content 相关的判断，那么是 content 阶段不需要相关标记么？\n进程初始化 从前面的模块定义可以看到 OpenResty 只指定了 ngx_http_lua_init_worker 和 ngx_http_lua_exit_worker 两个 worker 进程的处理函数。 配置解析完成后，会 fork 出子进程，然后调用 ngx_http_lua_init_worker 函数，我们来具体看看。\n- ngx_http_lua_init_worker \\- ngx_http_cycle_get_module_main_conf：获取主配置 \\- ngx_http_lua_pipe_add_signal_handler：添加信号处理函数，pipe 见 [pipe](015-pipe.md) \\- init_worker_handler：执行对应的 Lua 代码 init_worker_handler 从哪里来的呢？是 init_worker_by_lua 指令设置的，这个我们在后续的文章中再去验证一下。\n","date":"2023-03-05T06:00:05-04:00","image":"https://isshe.site/p/openresty-%E6%A8%A1%E5%9D%97%E5%88%9D%E5%A7%8B%E5%8C%96/image_hudab9f7e78110512db634a199699a7696_211640_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E6%A8%A1%E5%9D%97%E5%88%9D%E5%A7%8B%E5%8C%96/","title":"OpenResty 模块初始化"},{"content":"Postgresql 慢查询语句记录与分析 1. 记录  postgresql 以 12 版本为例\n 我们需要先打开 postgresql 的慢查询日志，此为前置条件，先记录下我们时间较长的查询。\n 编辑配置文件：/var/postgres12/data/postgresql.conf  #log_min_duration_statement = -1 # -1 is disabled, 0 logs all statements # and their durations, \u0026gt; 0 logs only # statements running at least this number # of milliseconds 修改 -1 为 200，表示大于等于 200 毫秒的操作将被记录到日志。\n 重载配置  /path/to/pg_ctl reload -D /path/to/pgdata 2. 获取慢查询语句 2.1 切 postgresql 超户 sudo su - postgres 2.2 获取慢查询语句  打开日志文件  less /path/to/pg_log/postgresql.log  跳到文件末尾  Shift + G  查询关键字 duration  因为被记录的日志格式形如：\nduration xxx ms select …. 3. 分析  连接 postgresql 服务器  path/to/psql -U postgres -d \u0026lt;database\u0026gt;  打开计时  \\timing  语句分析  explain select max(id) as max_id from test_table where created \u0026lt; now() - interval '24 hours'; QUERY PLAN ------------------------------------------------------------------------------------------------------------------------------ Finalize Aggregate (cost=12673.45..12673.46 rows=1 width=8) -\u0026gt; Gather (cost=12673.24..12673.45 rows=2 width=8) Workers Planned: 2 -\u0026gt; Partial Aggregate (cost=11673.24..11673.25 rows=1 width=8) -\u0026gt; Parallel Seq Scan on test_table (cost=0.00..10631.80 rows=416575 width=8) Filter: (created \u0026lt; (now() - '24:00:00'::interval)) (6 rows) explain 是显示查询计划，不会真正执行，所以甚至 update 也可以放在 explain 后面。 但是要注意，不能是 explain analyze ，带了 analyze 就真跑了，所以这个不能用于 DML 。\n DQL: SELECT DML: UPDATE/DELETE/INSERT DDL: CREATE TABLE/VIEW/INDEX/SYN/CLUSTER DCL: GRANT/ROLLBACK/COMMIT\n 另外可以看到结果中显示的是 Seq Scan，顺序扫描，所以可以为它创建一个索引，变成 Index Scan。\ncreate index test_index on test_table (created); 然后再次分析，如果时间没有明显减少，可以再去掉此索引。 重复以上步骤，即可逐步减少系统中的慢查询。\n 运行 ANALYZE 命令更新系统中表的统计信息  ANALYZElarge_table;","date":"2023-02-01T06:00:04-04:00","image":"https://isshe.site/p/%E6%95%B0%E6%8D%AE%E5%BA%93-postgresql-%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90/image_huab6d4bf2fac89bf04d136b1532e709da_268856_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%95%B0%E6%8D%AE%E5%BA%93-postgresql-%E6%85%A2%E6%9F%A5%E8%AF%A2%E5%88%86%E6%9E%90/","title":"数据库 —— Postgresql 慢查询分析"},{"content":"轻量级线程 与前一个文档中介绍的协程不同，轻量级线程不需要自行 resume、yield 来调度协程，因此使用起来更方便，有并行操作时，通常会使用此方式。\n 看是否和此函数强关联：ngx_http_lua_run_thread； 如果此文章无法完成对 ngx_http_lua_run_thread 的理解，则另外文章。\n 目的：\n 轻线程如何使用？ 轻线程的使用场景？ 什么是轻线程？ OpenResty 的协程与 Luajit 的协程是什么关系？有什么区别？  介绍 轻线程是一种由 lua-nginx-module 调度的特殊的 Lua 协程。rewrite/access/content_by_lua* 的 Lua 代码块就是在 lua-nginx-module 自动创建的**样板“轻线程”**中执行，这种样板“轻线程”也称为“入口线程（entry thread）”。\n默认情况下，rewrite_by_lua 等 Nginx 处理程序只有在遇到以下情况时才会中止：\n 入口线程和所有用户轻线程都中止了。 任意一个轻线程调用了 ngx.exit、ngx.exec、ngx.redirect、ngx.req.set_uri(uri, true)。 入口线程触发了 Lua 错误。  不过，用户的轻线程触发了 Lua 错误而中止，并不会导致其他轻线程也中止。\n由于 Nginx 子请求模型的限制，一般不允许中止一个正在运行的 Nginx 子请求，因此也不允许中止一个正等待一个或多个子请求终止的正在运行的轻线程，而必须使用 ngx.thread.wait 来等待这些轻线程终止。 一个值得注意的例外是，可以使用状态码 ngx.ERROR(-1), 408, 444 或 499 调用 ngx.exit 来中止挂起的子请求。\n轻线程不是以抢的方式进行调度的，也就是不会自动执行时间分片。轻线程会一直运行，知道遇到以下情况：\n 一个 I/O 操作无法在一次执行中完成。 调用了 coroutine.yield 主动让出执行权。 被 Lua 错误中断了，或者调用了 ngx.exit, ngx.exec, ngx.redirect, 或 ngx.req.set_uri(uri, true)。  前 2 种情况中，轻线程通常很快就会被 lua-nginx-module 的调度器重新唤醒。\n在轻线程中可以创建轻线程；在 coroutine.create 创建的协程中也可以创建轻线程，创建轻线程的协程/轻线程被称为父协程/轻线。父协程可以调用 ngx.thread.wait 来等待轻线程终止。\n此外，在轻线程中，也可以调用 coroutine.status 和 coroutine.yield。 轻线程将成为“僵尸”轻线程，当轻线程已经终止，父协程未终止并且父协程没有调用 ngx.thread.wait 来等待已终止的轻线程。\n轻线程最适用于在单个 Nginx 请求处理程序中并发请求上游。（分别发送不同请求到不同的服务器）\n使用 ngx.thread.spawn   上下文：rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer., ssl_certificate_by_lua, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*\n  语法：co = ngx.thread.spawn(func, arg1, arg2, ...)\n 参数：  func: 是启动协程后需要执行的函数。 arg1/arg2\u0026hellip;: 是 func 的参数。   返回值：  co: 一个 Lua 协程对象      作用：创建一个协程，并使用指定参数立即执行 func，直到 func 函数返回或出错或遇到 I/O 参数被 yield 了。ngx.thread.spawn 返回后，新创建的“轻线程”通常会在各种 I/O 事件中保持异步运行。\n  ngx.thread.wait   上下文：rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer., ssl_certificate_by_lua, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*\n  语法：ok, res1, res2, ... = ngx.thread.wait(thread1, thread2, ...)\n 参数：  thread1/thread2/\u0026hellip;：需要等待的轻线程，由 ngx.thread.spawn 创建。   返回值：  ok：一个布尔值，表示轻线程是否成功终止。 res1/res2/\u0026hellip;：用户 Lua 函数的返回结果，或者是错误对象。      作用：等待一个或多个轻线程，并返回第一个终止（成功或错误）的轻线程的结果（ok 的值）。\n  ngx.thread.kill   上下文：rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer., ssl_certificate_by_lua, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*\n  语法：ok, err = ngx.thread.kill(thread)\n 参数：  thread：要杀死的轻线程对象。   返回值：  ok：杀死轻线程否成功，成功则是 true，否则是 nil。 err：杀死轻线程失败时的错误描述字符串。      作用：杀死一个正在运行的轻线程。\n  实现 可以预想到，相关 Lua 接口还是通过注入的方式注册到 lua-nginx-module 中，我们来追踪一下。\nLua 接口注入  调用栈  - main \\- ngx_init_cycle \\- ngx_conf_parse \\- ngx_conf_handler \\- ngx_http_block \\- ngx_http_lua_init \\- ngx_http_lua_init_vm \\- ngx_http_lua_new_state \\- ngx_http_lua_init_globals \\- ngx_http_lua_inject_ngx_api \\- ngx_http_lua_inject_uthread_api 调用栈和之前在 010-lua-vm-init.md 中拿到的一样，没什么特殊的地方。\nngx_http_lua_inject_uthread_api  void ngx_http_lua_inject_uthread_api(ngx_log_t *log, lua_State *L) { /* new thread table */ lua_createtable(L, 0 /* narr */, 3 /* nrec */); lua_pushcfunction(L, ngx_http_lua_uthread_spawn); lua_setfield(L, -2, \u0026#34;spawn\u0026#34;); lua_pushcfunction(L, ngx_http_lua_uthread_wait); lua_setfield(L, -2, \u0026#34;wait\u0026#34;); lua_pushcfunction(L, ngx_http_lua_uthread_kill); lua_setfield(L, -2, \u0026#34;kill\u0026#34;); lua_setfield(L, -2, \u0026#34;thread\u0026#34;); } 在这个函数中，拿到了 “spawn” 等操作实际调用的 C 函数，我们后续从这些函数着手进行探索。\nngx.thread.spawn: ngx_http_lua_uthread_spawn - ngx_http_lua_uthread_spawn \\- lua_gettop：获取栈中元素数量。 \\- ngx_http_lua_get_req：获取请求。 \\- ngx_http_get_module_ctx：获取模块上下文。 \\- ngx_http_lua_coroutine_create_helper：创建协程，和 [011-corountine.md](011-corountine.md) 用的同一个函数，co 栈中只有一个 entry_func —— 入口函数。 \\- if (n \u0026gt; 1)：如果入口函数有参数。 \\- lua_replace(L, 1)：用 co 掉栈底元素，此时 L 的栈：co arg1 ... argn co。 \\- lua_xmove(L, coctx-\u0026gt;co, n - 1)：从 L 移动 n - 1 个元素到 coctx-\u0026gt;co 栈中，此市场 coctx-\u0026gt;co 的栈：entry_func arg1 ... argn co。 \\- ngx_http_lua_post_thread：加入到 post thread 链表中。 \\- ctx-\u0026gt;cur_co_ctx = coctx：设置当前协程上下文成新的协程，下次调度时，会 resume 此协程。 \\- ngx_http_lua_attach_co_ctx_to_L(coctx-\u0026gt;co, coctx)：关联 coctx 和 co。 \\- lua_yield：让出当前协程的执行权限。 主要做了以下事情：\n 创建新协程 配置好堆栈（设置好参数） yield 当前协程以开始调度新的协程  ngx.thread.wait: ngx_http_lua_uthread_wait - ngx_http_lua_uthread_wait \\- ngx_http_lua_get_req \\- ngx_http_get_module_ctx \\- ngx_http_lua_check_context：检查上下文是否是可以 yield 的 \\- nargs = lua_gettop(L)：获取参数数量，参数是协程对象 \\- for (i = 1; i \u0026lt;= nargs; i++)：逐个遍历检查要 wait 的协程 \\- sub_co = lua_tothread(L, i)：获取协程对象 \\- ngx_http_lua_get_co_ctx：后协程上下文 \\- switch (sub_coctx-\u0026gt;co_status)：检查协程状态 \\- case NGX_HTTP_LUA_CO_ZOMBIE：是僵尸协程 \\- nrets = lua_gettop(sub_coctx-\u0026gt;co)：获取返回值 \\- lua_xmove(sub_coctx-\u0026gt;co, L, nrets：设置成当前协程的返回值，作为 wait 方法的返回值 \\- ngx_http_lua_del_thread：从协程列表中删除协程 \\- case NGX_HTTP_LUA_CO_DEAD：已经是终止的协程了 \\- if (i \u0026lt; nargs)：如果还有其他协程需要检查，则继续 \\- else：否则就返回错误 \\- lua_pushnil \\- lua_pushliteral(L, \u0026quot;already waited or killed\u0026quot;) \\- default：协程还活着，则继续等待 \\- lua_yield(L, 0)：让出执行权限，让子协程继续执行 此函数做了以下事情：\n 遍历传入的参数，逐个检查是否是僵尸协程，返回第一个僵尸协程； 当前检查的协程如果已经终止，则继续检查其他协程；如果是最后一个，则报错返回。 如果没有协程终止或是僵尸协程，则让出执行权限，让子协程继续被调度。  yield 前并没有设置 ctx-\u0026gt;cur_co_ctx，那么是如何进行后续的调度的呢？  说明是子协程让出了执行权限（因为 IO 或其他原因），后续依赖于 Nginx 的事件模型进行调度。      ngx.thread.kill: ngx_http_lua_uthread_kill - ngx_http_lua_uthread_kill \\- ngx_http_lua_get_req \\- ngx_http_get_module_ctx \\- ngx_http_lua_check_context \\- sub_co = lua_tothread(L, 1)：获取参数 \\- luaL_argcheck：检查参数是否是协程 \\- ngx_http_lua_get_co_ctx：获取协程的上下文 \\- if (sub_coctx-\u0026gt;parent_co_ctx != coctx)：检查当前协程是否是要 kill 协程的父协程，不是不能 kill \\- if (sub_coctx-\u0026gt;pending_subreqs \u0026gt; 0)：检查协程是否还有未处理的请求 \\- switch (sub_coctx-\u0026gt;co_status)：检查协程状态 \\- NGX_HTTP_LUA_CO_ZOMBIE：删除协程并返回错误 \\- ngx_http_lua_del_thread \\- lua_pushnil \\- lua_pushliteral \\- NGX_HTTP_LUA_CO_DEAD：直接返回错误 \\- lua_pushnil \\- lua_pushliteral \\- default：执行清理函数并删除协程 \\- ngx_http_lua_cleanup_pending_operation \\- ngx_http_lua_del_thread \\- lua_pushinteger：设置返回值 从这个流程中，我们可以知道，只有父协程能 kill 子协程。\n总结  轻线程的使用场景？  答：主要用于并行操作，如并行发送请求到上游服务器。\n OpenResty 的协程与 Luajit 的协程是什么关系？有什么区别？  答：底层用的就是 Luajit 的协程，只是调度是 lua-nginx-module 进行。\n参考  https://github.com/openresty/lua-nginx-module#ngxthreadspawn  ","date":"2023-01-08T06:00:04-04:00","image":"https://isshe.site/p/openresty-%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BA%BF%E7%A8%8B/image_hu85aaf5f0d41b0975ba4c41b921fc00cc_279865_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BA%BF%E7%A8%8B/","title":"OpenResty 轻量级线程"},{"content":"协程 lua-nginx-module 提供了 coroutine 系列 Lua 接口，用于操作协程。\n这个与 ngx_http_lua_new_thread 相关的 lua-nginx-module 内部使用的协程不同，切勿搞混了。\n这系列函数较为少用，需要并行操作时通常使用轻量级线程（light thread）。\n目的：\n coroutine Lua 接口的使用？主要使用场景？  如前面提到，这个较为少用。lua-nginx-module 支持，主要应该是为了兼容第三方 Lua 模块。   coroutine 是如何实现的？ 与 Luajit 的协程是什么关系？  使用  coroutine.create(f)：创建一个协程并返回此协程，类型为“thread”，f 必须是一个函数。 coroutine.resume (co [, val1, ···])：开始或继续执行协程 co。如果协程执行出错，则返回 false 和错误信息，如果协程执行正常，返回 true。  首次调用会开始调用 f 函数，val1 等作为参数传递给 f。 后续调用会用 yield 的地方继续，val1 等作为 yield 的结果传递给 f。   coroutine.yield (···)：暂停正在执行的协程的执行。传递给 yield 的参数，将作为 resume 额外的结果返回。 coroutine.running ()：返回正在运行的协程，主协程正在运行，则返回 nil。 coroutine.status (co)：返回协程 co 的状态。  running：协程正在执行 suspended：调用了 yield，或者还没开始运行。 normal：激活但没有在运行，意味着它正在 resume 其他协程。 dead：执行完 f 函数，或者出错了。   coroutine.wrap (f)：create 和 resume 的包裹函数。创建一个协程，参数 f 必须是一个 Lua 函数，结果也是一个 Lua 函数（假设为 g）。g 的后续每次调用都会 resume 协程，传递给 g 的参数，会作为 resume 的参数（val1 等），resume 返回的结果即是 g 的返回结果。  示例：\nlocal function f() local cnt = 0 for i = 1, 20 do ngx.say(\u0026#34;Hello, \u0026#34;, cnt) coroutine.yield() cnt = cnt + 1 end end local c = coroutine.create(f) for i = 1, 3 do coroutine.resume(c) ngx.say(\u0026#34;***\u0026#34;) end 实现 在前一篇文章中，我们了解到 lua-nginx-module 主要是通过注入的方式把 Lua 接口注册到 Lua VM 中，coroutine 当然也不例外，我们来看下。\n- ngx_http_lua_init_vm \\- ngx_pool_cleanup_add \\- ngx_http_lua_new_state \\- ngx_http_lua_init_globals \\- ngx_http_lua_inject_ngx_api：注入 ngx API，实际上就是创建 ngx 表和填充这个表。 \\- ngx_http_lua_inject_coroutine_api ngx_http_lua_inject_coroutine_api 的执行流程 ngx_http_lua_inject_coroutine_api 又做了什么哪些呢？我们继续来看下\n- ngx_http_lua_inject_coroutine_api \\- lua_createtable(L, 0 /* narr */, 16 /* nrec */)：新建一个 coroutine 表 \\- lua_getglobal(L, \u0026#34;coroutine\u0026#34;)：把旧的 coroutine 表放到栈顶 \\- lua_getfield(L, -1, \u0026#34;running\u0026#34;)：把旧 coroutine[\u0026#34;running\u0026#34;] 放到栈顶 \\- lua_setfield(L, -3, \u0026#34;running\u0026#34;)：把旧 coroutine[\u0026#34;running\u0026#34;] 赋值给 新 coroutine[\u0026#34;running\u0026#34;]，并出栈 旧 coroutine[\u0026#34;running\u0026#34;]。 \\- 其他函数类似：create -\u0026gt; _create，wrap -\u0026gt; _wrap，resume -\u0026gt; _resume，yield -\u0026gt; _yield，status -\u0026gt; _status \\- lua_pop(L, 1)：不在需要操作旧的 coroutine 表了，弹出栈。 \\- lua_pushcfunction(L, ngx_http_lua_coroutine_create)：把函数压入栈中 \\- lua_setfield(L, -2, \u0026#34;__create\u0026#34;)：设置新 coroutine[\u0026#34;__create\u0026#34;] = ngx_http_lua_coroutine_create \\- 其他函数类似：[\u0026#34;wrap\u0026#34;] = ngx_http_lua_coroutine_wrap，[\u0026#34;resume\u0026#34;] = ngx_http_lua_coroutine_resume, ... \\- lua_setglobal(L, \u0026#34;coroutine\u0026#34;)：把新 coroutine 设置到全局表中替换旧的 \\- luaL_loadbuffer \\- lua_pcall：加载并执行一段 Lua 代码（下面贴出），设置新 coroutine 表的 \u0026#34;create\u0026#34;，\u0026#34;resume\u0026#34; 等（不用设置 running，running 没变化） Lua 注入 coroutine create 等接口的 Lua 代码：\nlocal keys = {\u0026#39;create\u0026#39;, \u0026#39;yield\u0026#39;, \u0026#39;resume\u0026#39;, \u0026#39;status\u0026#39;, \u0026#39;wrap\u0026#39;} -- ifdef OPENRESTY_LUAJIT local get_req = require \u0026#39;thread.exdata\u0026#39; -- #else local getfenv = getfenv -- #endif for _, key in ipairs(keys) do local std = coroutine[\u0026#39;_\u0026#39; .. key] local ours = coroutine[\u0026#39;__\u0026#39; .. key] local raw_ctx = ngx._phase_ctx coroutine[key] = function (...) -- #ifdef OPENRESTY_LUAJIT local r = get_req() -- #else local r = getfenv(0).__ngx_req -- #endif if r ~= nil then -- #ifdef OPENRESTY_LUAJIT local ctx = raw_ctx() -- #else local ctx = raw_ctx(r) -- #endif -- /* ignore header and body filters */ if ctx ~= 0x020 and ctx ~= 0x040 then return ours(...) end end return std(...) end end package.loaded.coroutine = coroutine 可以看到，在 ngx_http_lua_inject_coroutine_api 中，主要是替换了旧的 coroutine 表成新的 routine 表；新旧的 coroutine 函数（新：__xxx，旧：_xxx），按需调用。 同时，新的 coroutine 函数依赖 request 和 ctx。 也就是说，ngx.* 相关函数可以在使用新 coroutine 函数创建的 coroutine 中使用。而 header filter 和 body filter 以及其他没有 request 的调用，则使用的是标准库的 coroutine 函数，没法使用这些函数。\n新的 coroutine 函数是怎样的呢？有什么特殊的吗？我们继续看。\nngx_http_lua_coroutine_create VS lj_cf_coroutine_create   ngx_http_lua_coroutine_create\n- ngx_http_lua_coroutine_create \\- ngx_http_lua_get_req(L)：获取请求。 \\- ngx_http_get_module_ctx(r, ngx_http_lua_module)：获取 ctx。 \\- ngx_http_lua_coroutine_create_helper：在 wrap 中也用了，因此封装了个 helper 函数。 \\- luaL_argcheck：参数检查。首先检查 coroutine.create 的传参是否是函数。 \\- ngx_http_lua_check_context：检查这个接口是否能在当前上下文中被调用。这是一个宏，实际上就是对相关标记位进行\u0026#34;按位与\u0026#34;。 \\- ngx_http_lua_get_lua_vm(r, ctx)：获取 Lua VM。 \\- lua_newthread：如果不需要 co_ref 就直接创建线程。在根 Lua State 创建新线程，使之总是 yield 到主线程。 \\- ngx_http_lua_new_cached_thread：如果需要 co_ref（一个整数，用于查找线程，速度快），则调用此函数来创建。在根 Lua State 创建新线程，使之总是 yield 到主线程。 \\- ngx_http_lua_probe_user_coroutine_create：一个 dtrace 挂载点，没有定义 NGX_DTRACE 时，此宏为空。 \\- ngx_http_lua_get_co_ctx：从模块 ctx 中获取协程 ctx，如果没获取到，就创建；获取到就初始化一下。 \\- ngx_http_lua_create_co_ctx：创建协程 ctx。 \\- ngx_http_lua_set_req：把协程和请求关联起来。 \\- ngx_http_lua_attach_co_ctx_to_L：把协程 ctx 关联到协程。 \\- lua_xmove(vm, L, 1)：把协程从主线程移到 L。lua_xmove：从 vm 栈中弹出 1 个元素压到 L 栈中。 \\- lua_pushvalue(L, 1)：把入口函数复制到 L 的栈顶。 \\- lua_xmove(L, co, 1)：把入口函数从 L 移动到协程 co。   可以看到，与前面一致，新的 coroutine 函数需要 request 和 ngx_http_lua_module 的 ctx。 为了更清晰整个原理，我们完整地跟踪一下栈变化：（无关代码已经省去）\nint ngx_http_lua_coroutine_create_helper(lua_State *L, ngx_http_request_t *r, ngx_http_lua_ctx_t *ctx, ngx_http_lua_co_ctx_t **pcoctx, int *co_ref) { // L: entry_func  luaL_argcheck(L, lua_isfunction(L, 1) \u0026amp;\u0026amp; !lua_iscfunction(L, 1), 1, \u0026#34;Lua function expected\u0026#34;); if (co_ref == NULL) { // vm: co  co = lua_newthread(vm); } else { // vm: coroutines_key registry co co  lmcf = ngx_http_get_module_main_conf(r, ngx_http_lua_module); *co_ref = ngx_http_lua_new_cached_thread(vm, \u0026amp;co, lmcf, 0); } // co(extdata) = r  // co(extdata2) = coctx  ngx_http_lua_set_req(co, r); ngx_http_lua_attach_co_ctx_to_L(co, coctx); // vm: coroutines_key registry co  // L: entry_func arg1 ... argn co  lua_xmove(vm, L, 1); /* move coroutine from main thread to L */ if (co_ref) { // vm: coroutines_key registry  lua_pop(vm, 1); /* pop coroutines */ } // L: entry_func arg1 ... argn co entry_func  lua_pushvalue(L, 1); /* copy entry function to top of L*/ // L: entry_func arg1 ... argn co  // co: entry_func  lua_xmove(L, co, 1); /* move entry function from L to co */ } 可以看到，co 栈中只有一个 entry_func（此时 coroutine.create 接口也没有传髯口函数的参数）。\n  lj_cf_coroutine_create:\n// static int lj_cf_coroutine_create(lua_State *L) LJLIB_CF(coroutine_create) { lua_State *L1; if (!(L-\u0026gt;base \u0026lt; L-\u0026gt;top \u0026amp;\u0026amp; tvisfunc(L-\u0026gt;base))) lj_err_argt(L, 1, LUA_TFUNCTION); L1 = lua_newthread(L); setfuncV(L, L1-\u0026gt;top++, funcV(L-\u0026gt;base)); return 1; }   主要差别是 ngx_http_lua_coroutine_create 依赖 ctx 和 r，并且可能从 cache 中取协程；lj_cf_coroutine_create 直接 lua_newthread 了一个协程。\nngx_http_lua_coroutine_resume VS lj_ffh_coroutine_resume   ngx_http_lua_coroutine_resume\n- ngx_http_lua_coroutine_resume \\- co = lua_tothread(L, 1)：从栈中 index = 1 的地方取出值，转换成 Lua 线程。不是线程会返回 NULL。 \\- luaL_argcheck：检查 co 是否有效。 \\- ngx_http_lua_get_req：获取请求。 \\- ngx_http_get_module_ctx：获取模块 ctx。 \\- ngx_http_lua_check_context：检查这个接口是否能在当前上下文中被调用。 \\- p_coctx = ctx-\u0026gt;cur_co_ctx：获取当前 ctx 作为父 ctx。 \\- ngx_http_lua_get_co_ctx：从 co 中获取协程 ctx。 \\- ngx_http_lua_probe_user_coroutine_resume：dtrace 钩子。 \\- if (coctx-\u0026gt;co_status != NGX_HTTP_LUA_CO_SUSPENDED)：检查进程状态，如果不是 NGX_HTTP_LUA_CO_SUSPENDED 则不能进行 resume，直接返回错误。 \\- p_coctx-\u0026gt;co_status = NGX_HTTP_LUA_CO_NORMAL：设置父协程 ctx 的状态。 \\- coctx-\u0026gt;parent_co_ctx = p_coctx：设置协程的父协程 ctx。 \\- coctx-\u0026gt;co_status = NGX_HTTP_LUA_CO_RUNNING：设置协程的状态。 \\- ctx-\u0026gt;co_op = NGX_HTTP_LUA_USER_CORO_RESUME：设置协程操作是用户进行 RESUME。 \\- ctx-\u0026gt;cur_co_ctx = coctx：设置 ctx 的 cur_co_ctx 为即将 resume 的 coctx，当前协程 yield 后，将执行此协程。 \\- lua_yield：yeild 回主线程，然后让主线程来 resume。   不是应该 resume 吗？这里为什么调用的 lua_yield 呢？看到这里或许会有这样的疑惑。 其实 review、access 等阶段的 Lua 代码，都是通过 ngx_http_lua_run_thread 来执行的，ngx_http_lua_coroutine_resume 这里执行完 lua_yield 后，会回到 ngx_http_lua_run_thread 中，由于状态是 LUA_YIELD 和操作是 NGX_HTTP_LUA_USER_CORO_RESUME，会继续(continue) ngx_http_lua_run_thread 的死循环，进而执行到刚刚要 resume 的协程。\n lj_ffh_coroutine_resume  在 header filter 或 body filter 阶段，都是调用的 Luajit 的 coroutine 接口，都是在 ngx_http_lua_header_filter_by_chunk 中调用 lua_pcall 来执行的，与 lua-nginx-module 的接口不同。 不过 Luajit 的 coroutine.resume 是如何实现的，还没搞清楚，跟踪 lj_ffh_coroutine_resume 并没有发现有被调用，最终调用的 lj_vm_resume 这个汇编接口。后续学习 Luajit 时，再继续探究。 Luajit 的 coroutine.resume 及 coroutine.yield 底层接口看起来都是汇编的（使用 LJLIB_ASM 修饰）。\n总结 回到我们前面提出的问题，\n  coroutine Lua 接口的使用？主要使用场景？ 答：这个较为少用。lua-nginx-module 支持，主要应该是为了兼容第三方 Lua 模块。\n  coroutine 是如何实现的？ 答：不同阶段使用不同的底层函数，access 等阶段时候的是 lua-nginx-module 实现的函数，相关调度也是 lua-nginx-module 接管。header filter 等阶段则是使用 Luajit 实现的函数，相关调度由 Luajit 接管。\n  与 Luajit 的协程是什么关系？ 答：最终都是用了 Luajit 的 lua_resume、lua_yield 等函数。\n  疑问  如何判断一个 Lua State 是 root Lua State？ Luajit 中栈是如何分布的呢？1,-1 等索引的值代表什么？  后续见此文档：1-luajit-stack.md   Luajit 的 coroutine.resume 是如何实现的？  ","date":"2023-01-01T06:00:04-04:00","image":"https://isshe.site/p/openresty-%E5%8D%8F%E7%A8%8B/image_hu689d4fb24de3faf3d6ece04efc963d1d_254728_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E5%8D%8F%E7%A8%8B/","title":"OpenResty 协程"},{"content":"Lua Nginx Module 的源码结构  常常提醒自己使用总分思想，这不，发现缺少了一些更为全局的内容，现补充如下。 以 0.10.21 版本为例\n 目的\n 大致了解 openresty 是个什么、实现了哪些功能。  ngx_lua-0.10.21 ├── README.markdown ├── src │ ├── api │ │ └── ngx_http_lua_api.h │ ├── ddebug.h：用于调试的头文件 - 各个阶段是处理程序，用于支持 `*_by_lua*` 系列指令 │ ├── ngx_http_lua_initby.c │ ├── ngx_http_lua_initby.h │ ├── ngx_http_lua_initworkerby.c │ ├── ngx_http_lua_initworkerby.h │ ├── ngx_http_lua_ssl_certby.c │ ├── ngx_http_lua_ssl_certby.h │ ├── ngx_http_lua_ssl_client_helloby.c │ ├── ngx_http_lua_ssl_client_helloby.h │ ├── ngx_http_lua_setby.c │ ├── ngx_http_lua_setby.h │ ├── ngx_http_lua_ssl_session_fetchby.c │ ├── ngx_http_lua_ssl_session_fetchby.h │ ├── ngx_http_lua_ssl_session_storeby.c │ ├── ngx_http_lua_ssl_session_storeby.h │ ├── ngx_http_lua_rewriteby.c │ ├── ngx_http_lua_rewriteby.h │ ├── ngx_http_lua_accessby.c │ ├── ngx_http_lua_accessby.h │ ├── ngx_http_lua_contentby.c │ ├── ngx_http_lua_contentby.h │ ├── ngx_http_lua_bodyfilterby.c │ ├── ngx_http_lua_bodyfilterby.h │ ├── ngx_http_lua_exitworkerby.c │ ├── ngx_http_lua_exitworkerby.h │ ├── ngx_http_lua_headerfilterby.c │ ├── ngx_http_lua_headerfilterby.h │ ├── ngx_http_lua_logby.c │ ├── ngx_http_lua_logby.h - 进程间通讯 │ ├── ngx_http_lua_pipe.c │ ├── ngx_http_lua_pipe.h │ ├── ngx_http_lua_semaphore.c │ ├── ngx_http_lua_semaphore.h │ ├── ngx_http_lua_shdict.c │ ├── ngx_http_lua_shdict.h - socket 套接字：网络编程 │ ├── ngx_http_lua_socket_tcp.c │ ├── ngx_http_lua_socket_tcp.h │ ├── ngx_http_lua_socket_udp.c │ ├── ngx_http_lua_socket_udp.h - 其他待分类 │ ├── ngx_http_lua_api.c │ ├── ngx_http_lua_args.c │ ├── ngx_http_lua_args.h │ ├── ngx_http_lua_balancer.c │ ├── ngx_http_lua_balancer.h │ ├── ngx_http_lua_cache.c │ ├── ngx_http_lua_cache.h │ ├── ngx_http_lua_capturefilter.c │ ├── ngx_http_lua_capturefilter.h │ ├── ngx_http_lua_clfactory.c │ ├── ngx_http_lua_clfactory.h │ ├── ngx_http_lua_common.h │ ├── ngx_http_lua_config.c │ ├── ngx_http_lua_config.h │ ├── ngx_http_lua_consts.c │ ├── ngx_http_lua_consts.h │ ├── ngx_http_lua_control.c │ ├── ngx_http_lua_control.h │ ├── ngx_http_lua_coroutine.c │ ├── ngx_http_lua_coroutine.h │ ├── ngx_http_lua_ctx.c │ ├── ngx_http_lua_ctx.h │ ├── ngx_http_lua_directive.c │ ├── ngx_http_lua_directive.h │ ├── ngx_http_lua_exception.c │ ├── ngx_http_lua_exception.h │ ├── ngx_http_lua_headers.c │ ├── ngx_http_lua_headers.h │ ├── ngx_http_lua_headers_in.c │ ├── ngx_http_lua_headers_in.h │ ├── ngx_http_lua_headers_out.c │ ├── ngx_http_lua_headers_out.h │ ├── ngx_http_lua_input_filters.c │ ├── ngx_http_lua_input_filters.h │ ├── ngx_http_lua_lex.c │ ├── ngx_http_lua_lex.h │ ├── ngx_http_lua_log.c │ ├── ngx_http_lua_log.h │ ├── ngx_http_lua_log_ringbuf.c │ ├── ngx_http_lua_log_ringbuf.h │ ├── ngx_http_lua_misc.c │ ├── ngx_http_lua_misc.h │ ├── ngx_http_lua_module.c │ ├── ngx_http_lua_ndk.c │ ├── ngx_http_lua_ndk.h │ ├── ngx_http_lua_output.c │ ├── ngx_http_lua_output.h │ ├── ngx_http_lua_pcrefix.c │ ├── ngx_http_lua_pcrefix.h │ ├── ngx_http_lua_phase.c │ ├── ngx_http_lua_probe.h │ ├── ngx_http_lua_regex.c │ ├── ngx_http_lua_req_body.c │ ├── ngx_http_lua_req_body.h │ ├── ngx_http_lua_req_method.c │ ├── ngx_http_lua_script.c │ ├── ngx_http_lua_script.h │ ├── ngx_http_lua_sleep.c │ ├── ngx_http_lua_sleep.h │ ├── ngx_http_lua_ssl.c │ ├── ngx_http_lua_ssl.h │ ├── ngx_http_lua_ssl_ocsp.c │ ├── ngx_http_lua_string.c │ ├── ngx_http_lua_string.h │ ├── ngx_http_lua_subrequest.c │ ├── ngx_http_lua_subrequest.h │ ├── ngx_http_lua_time.c │ ├── ngx_http_lua_timer.c │ ├── ngx_http_lua_timer.h │ ├── ngx_http_lua_uri.c │ ├── ngx_http_lua_uri.h │ ├── ngx_http_lua_uthread.c │ ├── ngx_http_lua_uthread.h │ ├── ngx_http_lua_util.c │ ├── ngx_http_lua_util.h │ ├── ngx_http_lua_variable.c │ ├── ngx_http_lua_worker.c │ ├── ngx_http_lua_worker_thread.c │ └── ngx_http_lua_worker_thread.h ├── t：测试用例 ├── util：小工具 └── valgrind.suppress ","date":"2022-12-06T06:00:05-04:00","image":"https://isshe.site/p/openresty-%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/image_hud37660a567da8df0403875e6c802b8b7_242254_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/","title":"OpenResty 代码结构"},{"content":"ngx.log 我们都知道，这个接口的功能是打印错误日志，那么它是如何工作的呢？我们来探究一下。\n注意，是接口 ngx.log 不是指令 log_by_lua 。*\n目的：\n 它是如何工作的呢？  ngx.log 是如何被定义的？ ngx.log 执行时，做了什么？    使用   上下文：context: init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer., balancer_by_lua, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*\n  语法：ngx.log(log_level, ...)\n  注意：\n Lua nil 会被输出为字符串 \u0026ldquo;nil\u0026rdquo;；Lua 的布尔类型会输出为 \u0026ldquo;true\u0026rdquo; or \u0026ldquo;false\u0026rdquo;；ngx.null 被输出为 \u0026ldquo;null\u0026rdquo; 字符串；Lua table 将会调用其元表的 __tostring 函数，调用失败则抛出异常，异常也被输出到错误日志中；如果是 userdata，则输出字符串 \u0026ldquo;null\u0026rdquo;；其他类型一律抛出异常。 Nginx 内核中的错误消息长度有一个硬编码的 2048 字节限制。此限制包括尾部换行符和前置时间戳。如果消息大小超过此限制，Nginx 将相应地截断消息。可以通过编辑 Nginx 源代码树中 src/core/ngx_log.h 文件中的 NGX_MAX_ERROR_STR 宏定义来手动修改此限制。    实现   我的第一想法还是从使用入手，我们使用的是 Lua 接口 ngx.log。 根据此接口，找到 lib/ngx/errlog.lua 文件，不过很遗憾，这个并不是我们要找的文件。接下来怎么继续呢？\n  考虑到最终会调用 write 接口来写文件，我们可以尝试使用 GDB 来跟踪 Nginx write 相关的接口。不过也有可能调用 ngx.log 时，并不会立即写文件。不确定，但是可以试试。 （Nginx 处理 access log 时，通常会进行缓存；并且写文件是一个耗时的操作，每个请求都写一下也不合理） 通过使用 GDB 对 ngx_write_file 进行跟踪，发现并没有被调用。\n  想到 ngx.log 最终是调用了 nginx 核心的写日志函数，因此我们可以跟一下 nginx 记录日志相关的函数，从 ngx_log.c 中 找到 ngx_log_error_core，进行跟踪，得到：\n  #0 ngx_log_error_core (level=4, log=0x0, err=0, fmt=0x56030bc04f83 \u0026#34;%s%*s\u0026#34;) at src/core/ngx_log.c:106 #1 0x000056030bb20886 in log_wrapper (log=0x56030bd759f0, ident=0x56030bc04ed9 \u0026#34;[lua] \u0026#34;, level=4, L=0x7f4f86397f50) at ../ngx_lua-0.10.21/src/ngx_http_lua_log.c:273 #2 0x000056030bb1ff37 in ngx_http_lua_ngx_log (L=0x7f4f86397f50) at ../ngx_lua-0.10.21/src/ngx_http_lua_log.c:60 #3 0x00007f4f86b81b83 in lj_BC_FUNCC () from /root/persional/openresty-bin/luajit/lib/libluajit-5.1.so.2 #4 0x000056030bb3e35b in ngx_http_lua_run_thread (L=0x7f4f86387380, r=0x56030bdfb300, ctx=0x56030bdfc048, nrets=0) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:1185 #5 0x000056030bb46b92 in ngx_http_lua_rewrite_by_chunk (L=0x7f4f86387380, r=0x56030bdfb300) at ../ngx_lua-0.10.21/src/ngx_http_lua_rewriteby.c:337 #6 0x000056030bb467ae in ngx_http_lua_rewrite_handler_inline (r=0x56030bdfb300) at ../ngx_lua-0.10.21/src/ngx_http_lua_rewriteby.c:190 #7 0x000056030bb466e7 in ngx_http_lua_rewrite_handler (r=0x56030bdfb300) at ../ngx_lua-0.10.21/src/ngx_http_lua_rewriteby.c:162 ... 在 rewrite_by_lua 指令中使用的 ngx.log，因此调用栈下面部分是关于此指令的。 这就是 ngx.log 写日志的过程，不过 ngx.log 是如何与 ngx_http_lua_ngx_log 对应起来的呢？也就是使用 ngx.log 时，是如何知道要去调用 ngx_http_lua_ngx_log 的呢？通过搜索源码，得到：\nvoid ngx_http_lua_inject_log_api(lua_State *L) { ngx_http_lua_inject_log_consts(L); lua_pushcfunction(L, ngx_http_lua_ngx_log); lua_setfield(L, -2, \u0026#34;log\u0026#34;); lua_pushcfunction(L, ngx_http_lua_print); lua_setglobal(L, \u0026#34;print\u0026#34;); } 看起来是在这里进行了关联，使用 GDB 跟踪一下 ngx_http_lua_inject_log_api， 在 worker 进程进行跟踪，发现并没有被调用，跟踪 master 进程得到：\n#0 ngx_http_lua_inject_log_api (L=0x7ffff7717380) at ../ngx_lua-0.10.21/src/ngx_http_lua_log.c:281 #1 0x0000555555705855 in ngx_http_lua_inject_ngx_api (L=0x7ffff7717380, lmcf=0x555555891080, log=0x55555583d280 \u0026lt;ngx_log\u0026gt;) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:840 #2 0x00005555557057c4 in ngx_http_lua_init_globals (L=0x7ffff7717380, cycle=0x555555885740, lmcf=0x555555891080, log=0x55555583d280 \u0026lt;ngx_log\u0026gt;) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:822 #3 0x0000555555704647 in ngx_http_lua_new_state (parent_vm=0x0, cycle=0x555555885740, lmcf=0x555555891080, log=0x55555583d280 \u0026lt;ngx_log\u0026gt;) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:326 #4 0x000055555570b955 in ngx_http_lua_init_vm (new_vm=0x555555891080, parent_vm=0x0, cycle=0x555555885740, pool=0x5555558856f0, lmcf=0x555555891080, log=0x55555583d280 \u0026lt;ngx_log\u0026gt;, pcln=0x0) at ../ngx_lua-0.10.21/src/ngx_http_lua_util.c:3896 #5 0x00005555556fb450 in ngx_http_lua_init (cf=0x7fffffffd7e0) at ../ngx_lua-0.10.21/src/ngx_http_lua_module.c:865 #6 0x00005555555f4ddc in ngx_http_block (cf=0x7fffffffd7e0, cmd=0x55555581a200 \u0026lt;ngx_http_commands\u0026gt;, conf=0x555555886a20) at src/http/ngx_http.c:310 #7 0x00005555555b9ec7 in ngx_conf_handler (cf=0x7fffffffd7e0, last=1) at src/core/ngx_conf_file.c:463 #8 0x00005555555b99cc in ngx_conf_parse (cf=0x7fffffffd7e0, filename=0x555555885958) at src/core/ngx_conf_file.c:319 #9 0x00005555555b4f87 in ngx_init_cycle (old_cycle=0x7fffffffd9b0) at src/core/ngx_cycle.c:284 #10 0x0000555555592fe8 in main (argc=3, argv=0x7fffffffdd58) at src/core/nginx.c:295 得到了调用栈，接下来了解一下栈中各个函数的作用。 从前面的文章中，我们了解到 ngx_http_block 是进行 HTTP 块的配置解析，因此我们从这里开始跟踪。\nstatic char * ngx_http_block(ngx_conf_t *cf, ngx_command_t *cmd, void *conf) { ... if (module-\u0026gt;postconfiguration) { if (module-\u0026gt;postconfiguration(cf) != NGX_OK) { return NGX_CONF_ERROR; } } ... } src/http/ngx_http.c:310 对应的是 postconfiguration 这个语句，也就是在进行 lua-nginx-module postconfiguration 时（见001-module-init），进行的日志相关内容的绑定/初始化——注入日志 API。postconfiguration 进行了哪些操作我们后续在 010-lua-vm-init 进行探究，现在先只关注 Log 相关的内容：\nvoid ngx_http_lua_inject_log_api(lua_State *L) { ngx_http_lua_inject_log_consts(L); lua_pushcfunction(L, ngx_http_lua_ngx_log); lua_setfield(L, -2, \u0026#34;log\u0026#34;); lua_pushcfunction(L, ngx_http_lua_print); lua_setglobal(L, \u0026#34;print\u0026#34;); } 这部分代码便是注入：ngx.log 以及 ngx.print。 那么 ngx_http_lua_inject_log_consts 是什么呢？\nstatic void ngx_http_lua_inject_log_consts(lua_State *L) { /* {{{ nginx log level constants */ lua_pushinteger(L, NGX_LOG_STDERR); lua_setfield(L, -2, \u0026quot;STDERR\u0026quot;); lua_pushinteger(L, NGX_LOG_EMERG); lua_setfield(L, -2, \u0026quot;EMERG\u0026quot;); ... lua_pushinteger(L, NGX_LOG_DEBUG); lua_setfield(L, -2, \u0026quot;DEBUG\u0026quot;); /* }}} */ } ngx_http_lua_inject_log_consts 注册了一些日志等级的常量。 ngx.log 的定义流程我们了解了，接下来继续看下 ngx.log 执行时做了什么。\nngx.log(ngx_http_lua_ngx_log) 的执行流程 - ngx_http_lua_ngx_log：nginx 日志功能的包裹函数。 \\- ngx_http_lua_get_req：从 lua_State 中获取请求 \\- luaL_checkint：获取 log level 的值 \\- lua_remove： 从栈中删除 log level \\- log_wrapper \\- if (level \u0026gt; log-\u0026gt;log_level)：检查日志级别，级别不够则直接返回 \\- nargs = lua_gettop(L)：获取参数数量 \\- type = lua_type(L, i)：获取每个参数的类型，计算格式化参数需要的大小，格式化参数。（不同类型的处理见上文“使用”章节的注意部分） \\- ngx_log_error：调用 nginx 核心提供的日志打印函数 至此，我们算是捋通了整个流程：Lua 接口 ngx.log 是通过 API 注入把 c 函数注册到 Lua VM 中，然后被 Lua 代码调用调用时，通过 lj_BC_FUNCC 调用对应的 c 函数。\n 如果前面的方法行不通，接下来打算通过源码搜索相关关键字或者是通过搜索引擎搜索介绍相关内容的文章。\n ","date":"2022-11-15T06:00:05-04:00","image":"https://isshe.site/p/openresty-ngx.log/image_hud65e514ff14931b6d473072786819b50_270380_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-ngx.log/","title":"OpenResty ngx.log"},{"content":"log_by_lua* 在日志处理阶段执行 Lua 源代码，不会替换当前的访问日志，并在打印日志之前运行。\n用法  上下文: http, server, location, location if 阶段: log 语法：  与 init_by_lua* 类似，不再赘述。   注意：  以下 API 无法在此指令中使用：  Output API functions (e.g., ngx.say and ngx.send_headers) Control API functions (e.g., ngx.exit) Subrequest API functions (e.g., ngx.location.capture and ngx.location.capture_multi) Cosocket API functions (e.g., ngx.socket.tcp and ngx.req.socket).      实现  与 005-rewrite_by_lua 类似，不再赘述。\n  header_filter_by_lua*、 body_filter_by_lua* 等都是一样的套路，就不再赘述了。\n ","date":"2022-11-13T06:00:04-04:00","image":"https://isshe.site/p/openresty-log_by_lua/image_huab6d4bf2fac89bf04d136b1532e709da_268856_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-log_by_lua/","title":"OpenResty log_by_lua*"},{"content":"content_by_lua* content_by_lua* 充当一个 content 阶段的处理程序，对每个请求执行指定的 Lua 代码，代码会在独立的全局环境（沙箱）中执行。\n用法  上下文: location, location if  注意，不能定义在 http、server 块内了。   阶段: content 语法：  与 init_by_lua* 类似，不再赘述。   注意：这个指令不要和其他 content handler 指令（如 proxy_pass）在同一个 location 同时使用。  实现 在《模块初始化》 的 “ngx_http_lua_init 执行流程” 中， 我们了解到 content handler 并没有像 rewrite handler 一样在函数 ngx_http_lua_init 中被放到 cmcf-\u0026gt;phases 数组中，所以接下来我们来探究一下为什么。 因此，我们此行的目的：\n 了解指令是如何被解析的。（猜测与前面的阶段没有什么差异） 了解 content handler 是被如何设置的，为何于其他阶段的 handler 不同。 了解是何时执行了 Lua 代码，如何执行的。（猜测与前面的阶段没有什么差异）  指令定义 /* content_by_lua \u0026#34;\u0026lt;inline script\u0026gt;\u0026#34; */ { ngx_string(\u0026#34;content_by_lua\u0026#34;), NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1, ngx_http_lua_content_by_lua, NGX_HTTP_LOC_CONF_OFFSET, 0, (void *) ngx_http_lua_content_handler_inline }, ngx_http_lua_content_by_lua 执行过程 - ngx_http_lua_content_by_lua \\- if (cmd-\u0026gt;post == NULL)：检查是否有指定处理程序，没有直接报错返回。 \\- if (llcf-\u0026gt;content_handler)：检查是否已经设置了处理程序，设置了报错返回。 \\- if (value[1].len == 0)：检查配置块的大小，为 0 表示无效的 Lua 代码块，直接报错返回。 \\- if (cmd-\u0026gt;post == ngx_http_lua_content_handler_inline)：检查 Lua 代码是文件还是其他 \\- ngx_http_lua_gen_chunk_name：不是文件，生成 chunkname 和 cache key \\- ngx_http_lua_gen_chunk_cache_key \\- else：是文件 \\- ngx_http_compile_complex_value：解析文件路径，是否包含变量之类的（不建议使用变量，容易有安全问题） \\- ngx_http_lua_gen_file_cache_key：生成 cache key \\- llcf-\u0026gt;content_handler = (ngx_http_handler_pt) cmd-\u0026gt;post：设置处理函数——执行 Lua 代码的函数 \\- lmcf-\u0026gt;requires_capture_filter = 1 \\- clcf-\u0026gt;handler = ngx_http_lua_content_handler 可以看到，流程与其他阶段的指令没有太多区别，只是：\n clcf-\u0026gt;handler：这个是什么呢？有什么作用呢？什么时候执行的呢？  根据之前的经验，看 ngx_http_lua_content_handler 名字就能猜到，此函数中毫无疑问会调用 ngx_http_lua_content_handler_inline，也就是 cmd-\u0026gt;post。 也就是，content handler 的设置，不是像 access handler 那样直接放到一个数组（cmcf-\u0026gt;phases）中。 解释了 clcf-\u0026gt;handler 是什么，那么它是什么时候执行的呢？\nngx_http_lua_content_handler_inline 被调用位置 我们再来用 gdb 看下 ngx_http_lua_content_handler_inline（ngx_http_lua_content_handler）是如何被调用的。\n命令：\n$ gdb -p PID \u0026gt; b ngx_http_lua_content_handler_inline $ curl localhost # 其他 shell \u0026gt; c \u0026gt; bt 得到：\n#0 ngx_http_lua_content_handler_inline (r=0x0) at ../ngx_lua-0.10.21/src/ngx_http_lua_contentby.c:291 #1 0x000056030bb45ae0 in ngx_http_lua_content_handler (r=0x56030bd7b7e0) at ../ngx_lua-0.10.21/src/ngx_http_lua_contentby.c:222 #2 0x000056030ba324f5 in ngx_http_core_content_phase (r=0x56030bd7b7e0, ph=0x56030bdbc100) at src/http/ngx_http_core_module.c:1269 #3 0x000056030ba313de in ngx_http_core_run_phases (r=0x56030bd7b7e0) at src/http/ngx_http_core_module.c:885 #4 0x000056030ba31347 in ngx_http_handler (r=0x56030bd7b7e0) at src/http/ngx_http_core_module.c:868 #5 0x000056030ba42044 in ngx_http_process_request (r=0x56030bd7b7e0) at src/http/ngx_http_request.c:2120 #6 0x000056030ba40710 in ngx_http_process_request_headers (rev=0x56030bdc54c0) at src/http/ngx_http_request.c:1498 #7 0x000056030ba3fa6a in ngx_http_process_request_line (rev=0x56030bdc54c0) at src/http/ngx_http_request.c:1165 #8 0x000056030ba3e061 in ngx_http_wait_request_handler (rev=0x56030bdc54c0) at src/http/ngx_http_request.c:503 #9 0x000056030ba1a223 in ngx_epoll_process_events (cycle=0x56030bd77740, timer=60000, flags=1) at src/event/modules/ngx_epoll_module.c:901 #10 0x000056030ba05ee2 in ngx_process_events_and_timers (cycle=0x56030bd77740) at src/event/ngx_event.c:257 #11 0x000056030ba17402 in ngx_worker_process_cycle (cycle=0x56030bd77740, data=0x0) at src/os/unix/ngx_process_cycle.c:793 #12 0x000056030ba1361a in ngx_spawn_process (cycle=0x56030bd77740, proc=0x56030ba17311 \u0026lt;ngx_worker_process_cycle\u0026gt;, data=0x0, name=0x56030bbeaf7c \u0026#34;worker process\u0026#34;, respawn=-3) at src/os/unix/ngx_process.c:199 #13 0x000056030ba1606a in ngx_start_worker_processes (cycle=0x56030bd77740, n=1, type=-3) at src/os/unix/ngx_process_cycle.c:382 #14 0x000056030ba15511 in ngx_master_process_cycle (cycle=0x56030bd77740) at src/os/unix/ngx_process_cycle.c:135 #15 0x000056030b9cb3b9 in main (argc=3, argv=0x7ffce805c458) at src/core/nginx.c:386 与 005-rewrite_by_lua.md 中获取到的调用栈对比，发现并没有什么差别。\n 什么时候执行的问题也解答了：和 rewrite/access 阶段的处理程序一样，都是在相同的地方执行。（都是通过 phase 索引进行控制）\n 都是在以下代码中进行调用：\nvoid ngx_http_core_run_phases(ngx_http_request_t *r) { ngx_int_t rc; ngx_http_phase_handler_t *ph; ngx_http_core_main_conf_t *cmcf; cmcf = ngx_http_get_module_main_conf(r, ngx_http_core_module); ph = cmcf-\u0026gt;phase_engine.handlers; while (ph[r-\u0026gt;phase_handler].checker) { rc = ph[r-\u0026gt;phase_handler].checker(r, \u0026amp;ph[r-\u0026gt;phase_handler]); if (rc == NGX_OK) { return; } } } 也就是\n rc = ph[r-\u0026gt;phase_handler].checker(r, \u0026amp;ph[r-\u0026gt;phase_handler]);\n 这一句。可以看出调用方式和其他阶段的 handler 都是一样的。 那么就有疑问了，clcf-\u0026gt;handler 是怎么被设置到这里（ph[r-\u0026gt;phase_handler].checker）来的呢？ 通过搜索跟踪 clcf-\u0026gt;handler，我们得到：\n\\- ngx_http_core_find_config_phase \\- ngx_http_update_location_config \\- r-\u0026gt;content_handler = clcf-\u0026gt;handler; 再结合前面的“ngx_http_lua_content_by_lua 执行过程”，得到调用流程 —— 和 GDB 获取的一致：\n- ngx_http_core_content_phase \\- r-\u0026gt;content_handler：ngx_http_lua_content_handler（clcf-\u0026gt;handler） \\- llcf-\u0026gt;content_handler：ngx_http_lua_content_handler_inline 更多关于 Nginx 阶段的内容，我们在 Nginx 系列文章《6-nginx-phase.md》中进行探索。\nngx_http_lua_content_handler_inline 执行过程 - ngx_http_lua_content_handler_inline \\- ngx_http_get_module_loc_conf：获取 location 配置 \\- ngx_http_lua_get_lua_vm：获取 Lua VM \\- ngx_http_lua_cache_loadbuffer：加载 Lua 代码 \\- ngx_http_lua_content_by_chunk：执行 Lua 代码 与 ngx_http_lua_access_handler_inline、ngx_http_lua_rewrite_handler_inline 没差别。\n","date":"2022-11-12T06:00:04-04:00","image":"https://isshe.site/p/openresty-content_by_lua/image_hud65e514ff14931b6d473072786819b50_270380_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-content_by_lua/","title":"OpenResty content_by_lua*"},{"content":"access_by_lua* access_by_lua* 充当一个 access 阶段的处理程序，对每个请求执行指定的 Lua 代码，代码会在独立的全局环境（沙箱）中执行。\n用法  上下文: http, server, location, location if 阶段: access tail  注意：执行阶段晚于标准 ngx_http_access_module 模块。   语法：  与 init_by_lua* 类似，不再赘述。    实现 实现逻辑与 rewrite_by_lua* 别无二致，不再赘述。\n","date":"2022-11-06T06:00:05-04:00","image":"https://isshe.site/p/openresty-access_by_lua/image_hua2c3de042391b06a6fd250468293caa8_267334_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-access_by_lua/","title":"OpenResty access_by_lua*"},{"content":"init_by_lua*  相关代码逻辑出自 lua-nginx-module v0.10.21 版本\n 当 Nginx 收到 HUP 信号并开始重新加载配置文件时，Lua VM 会被重新创建，并且 init_by_lua* 会在新的 Lua VM 上再次运行。 如果关闭 lua_code_cache 指令（默认打开），init_by_lua* 处理程序（Lua 代码）将在每个请求上运行，因为在这种特殊模式下，需要为每个请求创建一个独立的 Lua VM。\n用法  init_by_lua 已不建议使用，使用 init_by_lua_block 和 init_by_lua_file 代替。\n   使用场景：\n 在 init_by_lua* 中，加载 Lua 模块，如 require \u0026quot;cjson\u0026quot;，再在其他阶段（如 content_by_lua*）使用：再次 require，这次 require 会很快，直接从 package.loaded 中获取返回。    执行阶段：loading-config，配置加载阶段\n  上下文：http\n  语法：\n  init_by_lua \u0026#39;lua-script-str\u0026#39; init_by_lua_block { lua-script } init_by_lua_file \u0026lt;path-to-lua-script-file\u0026gt;  示例：  init_by_lua 'print(\u0026quot;Hello World\u0026quot;)' init_by_lua_block { print(\u0026quot;Hello World\u0026quot;) } init_by_lua_file /usr/local/openresty/lua/init.lua 实现  以 init_by_lua 为例\n 指令定义 { ngx_string(\u0026#34;init_by_lua\u0026#34;), NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1, ngx_http_lua_init_by_lua, NGX_HTTP_MAIN_CONF_OFFSET, 0, (void *) ngx_http_lua_init_by_inline }, 可以看到，在解析到 init_by_lua 指令时，会调用 ngx_http_lua_init_by_lua 函数进行处理，那么\n ngx_http_lua_init_by_lua 这个函数中会执行 Lua 代码吗？ ngx_http_lua_init_by_inline 函数又是做什么用？  ngx_http_lua_init_by_lua 执行流程 - ngx_http_lua_init_by_lua \\- if (cmd-\u0026gt;post == NULL)：检查是否有 handler，没有直接报错。 \\- if (lmcf-\u0026gt;init_handler)：检查是否已经配置过 init_handler 了，配置过直接返回。 \\- lmcf-\u0026gt;init_handler = (ngx_http_lua_main_conf_handler_pt) cmd-\u0026gt;post：设置 init_handler，也就是把 init_handler 设置为 ngx_http_lua_init_by_inline。 \\- ngx_http_lua_rebase_path：Lua 代码在文件中，则调用此函数获取 Lua 文件的绝对路径。 \\- ngx_http_lua_gen_chunk_name：是 Lua 代码块，则调用此函数生成 chunk name。 \\- lmcf-\u0026gt;init_src：设置 Lua 文件路径或 Lua 代码到此变量中 可以看到，此函数中只是设置了 init_handler，并没有执行对应的 Lua 代码，那么 Lua 代码应该是在 ngx_http_lua_init_by_inline 中执行了。\nngx_http_lua_init_by_inline 执行流程  ngx_http_lua_init_by_inline 如何被调用？  详见上篇文章《模块初始化》 的 “ngx_http_lua_init 执行流程”\n ngx_http_lua_init_by_inline 的执行流程  - ngx_http_lua_init_by_inline \\- luaL_loadbuffer：加载 Lua 代码，这是 luajit 的接口 \\- luaL_loadbufferx：这部分后续放到 Luajit 目录下 \\- lua_loadx \\- lj_buf_init \\- lj_vm_cpcall \\- lj_lex_cleanup \\- lj_gc_check \\- ngx_http_lua_do_call：执行代码 \\- lua_gettop：获取函数在堆栈的索引/位置[?] \\- lua_insert：索引压栈 \\- lua_pushcfunction： traceback 压栈函数/异常处理函数（值：ngx_http_lua_traceback），出错时调用。 \\- ngx_http_lua_pcre_malloc_init：PCRE 内存分配函数及内存池修改，改为使用 cycle 的内存池（ngx_cycle-\u0026gt;pool） \\- lua_pcall：执行 Lua 代码 \\- ngx_http_lua_pcre_malloc_done：代码执行完了，还原回去 \\- lua_remove：索引出栈 \\- ngx_http_lua_report： \\- if (status \u0026amp;\u0026amp; !lua_isnil(L, -1))：状态不为 0（出错了）并且 Lua 类型不是 nil \\- lua_tostring：把错误消息取出来 \\- ngx_log_error：打印到 nginx log 中 \\- lua_gc：强制执行一次完整的垃圾收集 这个函数主要做了以下事情：\n 调用 luaL_loadbuffer 函数从缓冲区加载 Lua 代码 调用 ngx_http_lua_do_call 设置处理函数，并执行 Lua 代码 调用 ngx_http_lua_report 检查执行状态，出错则打印错误日志，并进行垃圾回收  到目前为止，我们得到了一个比较上层的 Lua 代码执行流程。 更详细的 Lua 代码执行细节（如 lua_loadx、lua_pcall 等函数的行为），后续再来探索。\nTODO  学习执行 Lua 代码相关的内容。  ","date":"2022-11-06T06:00:05-04:00","image":"https://isshe.site/p/openresty-init_by_lua/image_hu70840ac7263b3ebb6d16250de0b46ff4_264462_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-init_by_lua/","title":"OpenResty init_by_lua*"},{"content":"init_worker_by_lua* 如果没有启用 master 进程则此指令的 Lua 代码将在 init_by_lua* 指令的 Lua 代码之后运行。\n 启用 master 进程：表示非 master-worker 的模式  用法   使用场景\n 通常用于启动定时器执行每 worker 相关的内容，或者后端健康检查等。    执行阶段：starting-worker，工作进程启动阶段\n  上下文：http\n  语法：\n  与 init_by_lua* 类似，不再赘述。\n实现  以 init_worker_by_lua_file 为例\n 通过前面的探索，我们已经知道指令的解析会在配置解析阶段，而对应的 Lua 代码会在后续才执行。 因此，我们接下来目的很明确：\n 解析 init_worker_by_lua_file 指令时，做了什么？ 在什么时候实际执行了 Lua 代码？如何执行的？  我们以 init_worker_by_lua_file 指令为例。\n指令定义 { ngx_string(\u0026#34;init_worker_by_lua_file\u0026#34;), NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1, ngx_http_lua_init_worker_by_lua, NGX_HTTP_MAIN_CONF_OFFSET, 0, (void *) ngx_http_lua_init_worker_by_file },  ngx_http_lua_init_worker_by_lua：指令解析时调用的函数。 ngx_http_lua_init_worker_by_file：指令结构的 post 字段的值。  解析指令时，会调用 ngx_http_lua_init_worker_by_lua，我们来跟踪一下。\nngx_http_lua_init_worker_by_lua 执行流程 - ngx_http_lua_init_worker_by_lua \\- if (cmd-\u0026gt;post == NULL)：如果缺少回调函数，就直接报错返回。 \\- if (lmcf-\u0026gt;init_worker_handler)：如果已经设置过回调了，就直接返回。 \\- lmcf-\u0026gt;init_worker_handler = (ngx_http_lua_main_conf_handler_pt) cmd-\u0026gt;post;：把回调设置到 init_worker_handler 上。 \\- if (cmd-\u0026gt;post == ngx_http_lua_init_worker_by_file)：如果是文件，init_worker_src 中则填入绝对路径。否则填入配置里面的代码。 \\- ngx_http_lua_rebase_path：获取文件绝对路径 这个函数做的事情很简单，就 2 件：\n 设置好回调函数。 设置好 Lua 代码或代码路径。  ngx_http_lua_init_worker_by_file 的调用位置 根据上面我们知道会调用 init_worker_handler，因此可以反向跟踪代码来得到调用栈。 不过这里我直接使用 bpftrace 来获取：（bpftrace 相关内容见：M.方法论/阅读源码的方法.md）\n 命令  sudo bpftrace -e \u0026#39;uprobe:/opt/openresty/nginx/sbin/nginx:ngx_http_lua_init_worker_by_file {printf(\u0026#34;%s\\n\u0026#34;, ustack());}\u0026#39; 然后配置好 nginx.conf 并启动 openresty，即可得到调用栈。\n 调用栈  ngx_http_lua_init_worker_by_file+0 ngx_worker_process_init+2009 ngx_worker_process_cycle+69 ngx_spawn_process+1860 ngx_start_worker_processes+126 ngx_master_process_cycle+756 main+1538 __libc_start_main+243 有点奇怪，这里为什么会显示 ngx_worker_process_init 直接调用了 ngx_http_lua_init_worker_by_file 呢？ ngx_worker_process_init 是 nginx 框架里面的函数，而 ngx_http_lua_init_worker_by_file 是 lua-nginx-module 模块里面的函数。\n前面是把 ngx_http_lua_init_worker_by_file 赋值给了 ngx_http_lua_main_conf_t 结构（变量 lmcf）的 init_worker_handler 字段， 而 ngx_http_lua_main_conf_t 看起来是 lua-nginx-module 的结构，nginx 框架怎么会知道呢？\n跟踪代码发现\n- ngx_worker_process_init \\- init_process(ngx_http_lua_init_worker)：这是我们在定义模块时候，给 init_process 字段赋值了 ngx_http_lua_init_worker。 \\- init_worker_handler(ngx_http_lua_init_worker_by_file) 实际是这样。\n但是为什么少了呢？我们后续有机会再来探究。\n到这里我们了解到 Lua 代码是在产生 worker 进程后，对 worker 进程进行初始化时被调用了。\nngx_http_lua_init_worker_by_file 执行流程 - ngx_http_lua_init_worker_by_file \\- luaL_loadfile \\- ngx_http_lua_do_call \\- ngx_http_lua_report 和 init_by_lua 指令的区别在于 luaL_loadbuffer 换成了 luaL_loadfile。 luaL_loadfile 也就是读文件，然后加载代码。\nTODO  探究 “为什么调用栈少了一帧”。  参考  https://github.com/openresty/lua-nginx-module#init_worker_by_lua https://github.com/openresty/lua-nginx-module#init_worker_by_lua_block https://github.com/openresty/lua-nginx-module#init_worker_by_lua  ","date":"2022-11-06T06:00:05-04:00","image":"https://isshe.site/p/openresty-init_worker_by_lua/image_hu85aaf5f0d41b0975ba4c41b921fc00cc_279865_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-init_worker_by_lua/","title":"OpenResty init_worker_by_lua*"},{"content":"Lua 代码执行实例跟踪  实际跟踪 Lua 代码的执行情况（主要是出错情况）。\n 异常情况 由于使用 bpftrace 得到的堆栈不符合预期，直接用 gdb 来获取：\n指令：\n # index a nil value init_by_lua 'return a.b'; 对 nil 值进行索引。\n错误输出：\nnginx: [error] init_by_lua error: init_by_lua:1: attempt to index global 'a' (a nil value) stack traceback: init_by_lua:1: in main chunk 命令：\n$ gdb sbin/nginx \u0026gt; set args -p /NGINX/CONFIG/PATH \u0026gt; b ngx_http_lua_traceback \u0026gt; run \u0026gt; bt 从 init_by_lua 的文章中，已经知道了 ngx_http_lua_traceback 是错误处理函数，因此我们直接追踪它。\n结果：\n#0 ngx_http_lua_traceback (L=0x7ffff76f02e8) at ngx_lua-0.10.21/src/ngx_http_lua_util.c:3071 #1 0x00007ffff7eb1b83 in lj_BC_FUNCC () from luajit/lib/libluajit-5.1.so.2 #2 0x00007ffff7eb7098 in lj_err_run (L=L@entry=0x7ffff7717380) at lj_err.c:856 #3 0x00007ffff7eb72ed in err_msgv (L=L@entry=0x7ffff7717380, em=em@entry=LJ_ERR_BADOPRT) at lj_err.c:881 #4 0x00007ffff7eb7474 in lj_err_optype (L=L@entry=0x7ffff7717380, o=o@entry=0x7ffff770f380, opm=opm@entry=LJ_ERR_OPINDEX) at lj_err.c:915 #5 0x00007ffff7ebb967 in lj_meta_tget (L=0x7ffff7717380, o=0x7ffff770f380, k=0x7fffffffd2d0) at lj_meta.c:147 #6 0x00007ffff7eb2089 in lj_vmeta_tgetv () from luajit/lib/libluajit-5.1.so.2 #7 0x00007ffff7ecc1cd in lua_pcall (L=0x7ffff7717380, nargs=0, nresults=0, errfunc=\u0026lt;optimized out\u0026gt;) at lj_api.c:1145 #8 0x000055555570c0fb in ngx_http_lua_do_call (log=0x55555583d280 \u0026lt;ngx_log\u0026gt;, L=0x7ffff7717380) at ngx_lua-0.10.21/src/ngx_http_lua_util.c:4192 #9 0x000055555572bda3 in ngx_http_lua_init_by_inline (log=0x55555583d280 \u0026lt;ngx_log\u0026gt;, lmcf=0x555555890e80, L=0x7ffff7717380) at ngx_lua-0.10.21/src/ngx_http_lua_initby.c:24 #10 0x00005555556fb594 in ngx_http_lua_init (cf=0x7fffffffd7e0) at ngx_lua-0.10.21/src/ngx_http_lua_module.c:896 #11 0x00005555555f4ddc in ngx_http_block (cf=0x7fffffffd7e0, cmd=0x55555581a200 \u0026lt;ngx_http_commands\u0026gt;, conf=0x555555886a20) at src/http/ngx_http.c:310 #12 0x00005555555b9ec7 in ngx_conf_handler (cf=0x7fffffffd7e0, last=1) at src/core/ngx_conf_file.c:463 #13 0x00005555555b99cc in ngx_conf_parse (cf=0x7fffffffd7e0, filename=0x555555885958) at src/core/ngx_conf_file.c:319 #14 0x00005555555b4f87 in ngx_init_cycle (old_cycle=0x7fffffffd9b0) at src/core/ngx_cycle.c:284 #15 0x0000555555592fe8 in main (argc=3, argv=0x7fffffffdd58) at src/core/nginx.c:295 可以看到最终 ngx_http_lua_traceback 是被 Luajit 调用了，这是在 ngx_http_lua_do_call 中设置的。\n ngx_http_lua_traceback 函数源码：  int ngx_http_lua_traceback(lua_State *L) { if (!lua_isstring(L, 1)) { /* 'message' not a string? */ return 1; /* keep it intact */ } lua_getglobal(L, \u0026quot;debug\u0026quot;); if (!lua_istable(L, -1)) { lua_pop(L, 1); return 1; } lua_getfield(L, -1, \u0026quot;traceback\u0026quot;); if (!lua_isfunction(L, -1)) { lua_pop(L, 2); return 1; } lua_pushvalue(L, 1); /* pass error message */ lua_pushinteger(L, 2); /* skip this function and traceback */ lua_call(L, 2, 1); /* call debug.traceback */ return 1; } 根据注释可以看到，主要做了：\n 设置错误信息 跳过 2 个栈帧：当前 Lua 函数和栈帧 [?, 猜测] 调用 debug.traceback  因此，此函数看起来是获取调用栈，然后在后续打印到日志中（由 ngx_http_lua_report 调用 ngx_log_error）。\n由于缺乏对 lua_* 相关函数的了解，还是没法继续深入，先作罢，后续再读下 luajit 源码去了解。\n","date":"2022-10-30T06:00:04-03:00","image":"https://isshe.site/p/openresty-lua-%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E5%AE%9E%E4%BE%8B%E8%B7%9F%E8%B8%AA/image_hue5dc0d3f3cdfdc2db7e9f7df6176631d_248590_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/openresty-lua-%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E5%AE%9E%E4%BE%8B%E8%B7%9F%E8%B8%AA/","title":"OpenResty Lua 代码执行实例跟踪"},{"content":"gdb gdb - GNU调试器。\n调试器(如GDB)的目的是允许你查看其他程序在执行时的\u0026quot;内部\u0026quot;的内容，或者程序奔溃的时候正在做什么。 GDB可以做4种主要的事情来帮助你捕捉bug：\n 启动你的程序，指定任何可能影响程序行为的内容。 使程序在指定条件下停止。 检查你程序停止时，正在发生的事情。 更改程序中的内容，以便你可以尝试纠正一个错误的影响并继续了解另一个错误。  你可以用GDB来调试C、C++、Fortran、Modula-2编写的程序。 使用gdb命令来调用GDB。一旦启动，它会从中断读取命令，直到你用GDB命令\u0026quot;exit\u0026quot;告诉它退出。你可以用GDB命令help来查看帮助（不用退出gdb）。 你可以运行没有参数或选项的gdb ; 但是最常用的启动GDB的方法是使用一个或两个参数，将可执行程序指定为参数：\n gdb program\n 您还可以从可执行程序和指定的core文件开始：\n gdb program core\n 如果要调试正在运行的进程，则可以将进程ID指定为第二个参数：\n gdb program 1234 gdb -p 1234\n 将GDB附加(attach)到1234进程（除非你由一个名字为1234的core文件，gdb会先查找core文件）。 以下是一些常用的GDB命令:\nbreak [file:]function 在函数(文件)中设置断点。 缩写：b。 用法： b \u0026lt;行号\u0026gt;，如：b 8 b \u0026lt;函数名称\u0026gt;，如：b main b *\u0026lt;函数名称\u0026gt;，如：b *main（在函数名称前面加“*”符号表示将断点设置在“由编译器生成的prolog代码处”） b *\u0026lt;代码地址\u0026gt;，如：b *0x804835c。 d [breakpoint number] 删除断点 run [arglist] 开始你的程序（arglist是参数列表） 缩写：r bt 回溯(backtrace)：显示程序堆栈。 print expr 显示表达式expr的值。 缩写：p c 继续运行你的程序（在停止后，例如断电）。continue的缩写。 next 继续下一行(在停止后)；不进入函数的单步调试。 缩写：n edit [file:]function 查看程序当前停止的行。 list [file:]function 在当前停止的位置附近键入程序的文本。 step 继续下一行(在停止后)；进入函数的单步调试。 缩写：s i 显示各类信息。如：i r，显示寄存器的信息 help [name] 显示GDB命令name的信息，或有关使用GDB的一般信息。 quit 退出GDB。 缩写：q 有关GDB的完整详细信息，请参阅：A Guide to the GNU Source-Level Debugger\n用法 gdb [-help] [-nh] [-nx] [-q] [-batch] [-cd=dir] [-f] [-b bps] [-tty=dev] [-s symfile] [-e prog] [-se prog] [-c core] [-p procID] [-x cmds] [-d dir] [prog|prog procID|prog core] 选项 选项之外的任何参数都需要指定可执行文件和核心文件（或进程ID）。 所有选项和命令行参数都按顺序处理。使用' -x \u0026lsquo;选项时，顺序会有所不同。\n-help -h 列出所有选项，并提供简要说明。 -symbols=file -s file 从file文件中读取符号表（symbol table）。 -write 允许写入可执行文件和core文件。 -exec=file -e file 使用file文件作为可执行文件在适当时执行，并与核心转储一起检查纯数据。 -se=file 从file文件中读取符号表并将file用作可执行文件。 -core=file -c file 指定core文件。 -command=file -x file 执行file文件中的GDB命令。（自动化？） -ex command 执行给定的GDB命令。 -directory=directory -d directory 将目录添加到路径(path)以搜索源文件。 -nh 不要执行~/.gdbinit中的命令。 -nx -n 不要执行任何\u0026#39;.gdbinit\u0026#39;初始化文件中的命令。 -quiet -q \u0026#34;Quiet\u0026#34;. 不要打印介绍性和版权信息。这些消息也在批处理模式下被抑制。 -batch 以批处理模式运行。 在执行完用-x选项指定的所有命令文件(如果不禁止，则为.gdbinit)后，以0退出。 如果在运行命令文件中的GDB命令时发生错误，则以非0退出。 批处理模式可用于将GDB作为过滤器运行，例如在另一台计算机上下载并运行程序; 为了使这个更有用，消息程序正常退出。【？？？】 -cd=directory 使用directory作用GDB的工作目录（而不是用当前目录） -fullname -f Emacs在将GDB作为子进程运行时设置此选项。 它告诉GDB每次显示堆栈帧时都以标准的，可识别的方式输出完整的文件名和行号（包括每次程序停止时）。 这种可识别的格式看起来像两个\u0026#39;\\032\u0026#39;字符，后跟文件名，行号和以冒号分隔的字符位置，以及换行符。 Emacs-to-GDB接口程序使用两个\u0026#39;\\032\u0026#39;字符作为信号来显示帧的源代码。 -b bps 设置GDB用于远程调试的任何串行接口的线性速度（波特率或每秒位数）。 -tty=device 使用device运行程序的标准输入和输出。 示例 编译并跟踪 gcc test.c -o test -g gdb test \u0026lt;gdb命令\u0026gt; \u0026lt;b main\u0026gt;: 断点 \u0026lt;b 10\u0026gt;: 第10行设置断点 \u0026lt;d 10\u0026gt;: 删除第10行的断点 \u0026lt;info b\u0026gt;: 查看断点信息 \u0026lt;c\u0026gt;: 继续 \u0026lt;n\u0026gt;: 下一行 \u0026lt;s\u0026gt;: 下一行，进入函数。 \u0026lt;r\u0026gt;: 执行 \u0026lt;c\u0026gt;: 继续执行 \u0026lt;i r\u0026gt;: 显示寄存器的信息 \u0026lt;bt\u0026gt;: 显示堆栈 \u0026lt;list 10\u0026gt;: 从第10行开始显示代码 跟踪实例 gdb sbin/nginx # 设置程序的相关参数 \u0026gt; set args -p /root/nginx/test # 主要想跟踪 nginx 的 worker 进程，因此设置跟踪 fork \u0026gt; set follow-fork-mode child # 必要的地方打上断点 \u0026gt; b ngx_http_log_module.c:294 \u0026gt; b ngx_http_log_module.c:309 # 执行 \u0026gt; run # 另一个 shell，发送请求 curl localhost:xxx # 此时 gdb 这边到达断点 # 查看调用栈 \u0026gt; bt # 打印想看的变量 \u0026gt; p values[0] \u0026gt; p values[1] \u0026gt; p n \u0026gt; p log-\u0026gt;script # 有分叉，单步调试看看 \u0026gt; list \u0026gt; n \u0026gt; n # 重复上面的步骤，逐渐找到问题 拓展  shell命令：info gdb gdb在线文档  A Guide to the GNU Source-Level Debugger    参考  https://man.linuxde.net/gdb  ","date":"2022-10-17T06:00:04-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-gdb/image_hu9a6e15c100f49a1259729f1a9f46ad7a_252829_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-gdb/","title":"Linux 命令 —— gdb"},{"content":"中断 1. 硬件中断注册 #include \u0026lt;linux/interrupt.h\u0026gt; static inline int __must_check request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev)  作用：申请一个中断线。 参数：  irq: 中断线号 handler: 中断处理函数 flags: name: dev:    2. 硬件中断释放 #include \u0026lt;linux/interrupt.h\u0026gt; const void *free_irq(unsigned int irq, void *dev_id);  作用：释放一个中断线。如果没有其他设备注册该IRQ线，就关闭该IRQ。 参数：  irq: 中断线号。 dev_id: 设备标识。    3. 中断类型 网络设备常见的中断事件类型：\n 接收一帧：最常见、标准的情况。 传输失败； DMA传输已成功完成；  drivers/net/3c59x.c有相关范例。   设备有足够内存处理新传输；  4. 中断共享 IRQ线是有限的资源；允许系统能容纳设备数目的简单方式就是：允许多台设备共享一个IRQ线。 一组设备共享一条IRQ线时，所有这些设备的设备驱动程序都必须有能力处理共享的IRQ。换言之，设备注册IRQ时，需要说明其是否支持中断共享。\n5. IRQ处理函数映射（中断向量表） 相关结构：详见\u0026lt;include/linux/interrupt.h\u0026gt;\n struct irq_desc struct irqaction  irq_desc ----\u0026gt;+---------+ | | | +---------+ | | *action | --------------------\u0026gt; +---------------+ +---------+ | *next | | | | | | | | +---------------+ | +---------+ struct irqaction NR_IRQS | *action | --------------------\u0026gt; +---------------+ ------\u0026gt; +---------------+ | +---------+ | *next | | *next | | | | SA_SHIRQ | | | | | | +---------------+ +---------------+ +---------+ -- struct irqaction struct irqaction | | | | -\u0026gt; struct irq_desc -----+---------+ -- ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%86%85%E6%A0%B8-%E4%B8%AD%E6%96%AD/image_hu3beecb1316a348fa5f605548c01c17ba_220606_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%86%85%E6%A0%B8-%E4%B8%AD%E6%96%AD/","title":"Linux 内核 —— 中断"},{"content":"设备驱动 NIC可用之前，相关联的net_device数据结构必须先初始化，添加至内核网络设备数据库、配置并开启。 注册/注销/开启/关闭是四个不同的操作，不要混淆。 相关讨论，主要以网络设备为主。\n设备注册 触发网络设备注册的情况：\n 加载NIC设备驱动程序：内建在内核，则引导期间初始化；模块形式，则在运行期间初始化。  例如，注册PCI设备驱动程序时，会导致pci_driver-\u0026gt;probe被调用。   插入可热插拔网络设备：内核通知其驱动程序，驱动程序注册该设备。 注册流程：以ethernet设备为例，流程都是一样，只是细节不同。   示例可见：drivers/net/ethernet/intel/e100.c\n xxx_probe/module_init | |---\u0026gt;dev = alloc_etherdev(sizeof(driver_private_structure)) | | | +---\u0026gt; alloc_etherdev(sizeof_priv, \u0026#34;eth%d\u0026#34;, ether_setup) | | | |---\u0026gt; dev = kmalloc(sizeof(net_device)) + sizeof_prive + padding) | |---\u0026gt; ether_setup(dev) | |---\u0026gt; strcpy(dev-\u0026gt;name, \u0026#34;eth%d\u0026#34;) | +---\u0026gt; return(dev) | ... ... ... |---\u0026gt; netdev_boot_setup_check(dev) | ... ... ... +---\u0026gt; register_netdev(dev) | +---\u0026gt; register_netdevice(dev) 注销 触发网络设备注销的情况：\n 卸载NIC去而被驱动程序：模块形式的设备驱动程序被卸载，相关联的NIC都需要被注销。  例如，卸载PCI设备驱动程序时，会导致pci_driver-\u0026gt;remove被调用。   删除可热拔插网络设备。 注销流程：  xxx_remove(_one)/module_exit | |---\u0026gt; unregister_netdev(dev) | | | +---\u0026gt; unregister_netdevice(dev) |---\u0026gt; ... ... ... | +---\u0026gt; free_netdev(dev)  注销总是会调用unregister_netdevice和free_netdev。  有时显式调用free_netdev，有时则通过dev-\u0026gt;destructor间接调用。  只有少数虚拟设备的设备驱动程序采用这种方法，如，net/8021q/vlan.c      更多示例信息 见net_device\nA.问题  设备是何时以及如何在内核注册的？ 网络设备如何利用网络设备数据库注册，并指派一个net_device结构的实例？ net_device结构如何组织到hash表和列表，以便各种查询？ net_device实例如何初始化？   一部分由内核核心完成，一部分由其设备驱动完成。\n  就注册而言，虚拟设备和真实设备有何差别？  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%86%85%E6%A0%B8-%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/image_hu70675371b4d01d0ec6d16ae0abb1373c_296698_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%86%85%E6%A0%B8-%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/","title":"Linux 内核 —— 设备驱动"},{"content":"git submodule 添加submodule： git submodule add \u0026lt;subproject URL\u0026gt; \u0026gt; git submodule add https://github.com/isshe/gitsubproject 查看subproject的commit： git diff --cached \u0026lt;subproject dir\u0026gt; \u0026gt; git diff --cached gitsubproject/ 查看subproject的.gitmodules： git diff --cached --submodule 自动clone每个submodule： git clone --recursive \u0026lt;your repository url\u0026gt; \u0026gt; git clone --recursive https://github.com/isshe/gitproject 拉取子模块： git submodule init git submodule update \u0026gt; 更常用的是：递归更新 git submodule update --init --recursive 子模块的后续更新：\ngit submodule update --remote 调整submodule的commit： git pull origin xxx 切submodule的分支： git config -f .gitmodules submodule.\u0026lt;submodule dir\u0026gt;.branch \u0026lt;submodule target branch name\u0026gt; \u0026gt; git config -f .gitmodules submodule.DbConnector.branch stable 更新到相应的分支：\ngit checkout -b \u0026lt;branch name\u0026gt; --track origin/\u0026lt;branch name\u0026gt; \u0026gt; git checkout -b chudai --track origin/chudai 删除一个submodule：  Delete the relevant section from the .gitmodules file. Stage the .gitmodules changes git add .gitmodules Delete the relevant section from .git/config. Run git rm --cached path_to_submodule (no trailing slash). Run rm -rf .git/modules/path_to_submodule Commit git commit -m \u0026quot;Removed submodule \u0026lt;name\u0026gt;\u0026quot; Delete the now untracked submodule filesrm -rf path_to_submodule  使用示例 显示某次提交修改的文件 git show --name-only HEAD git merge squash git checkout \u0026lt;your-dev-branch\u0026gt; # -i 后跟 commit id，要合并的提交的前一个，如果你要合并两次提交，那个出来的编辑器里应该有两条记录 git rebase -i HEAD~2 # 编辑框出来后，可以把后面的提交的 pick 改为 squash git pull --rebase origin master git push -f origin \u0026lt;your-dev-branch\u0026gt; # git checkout master git pull origin master git merge \u0026lt;your-dev-branch\u0026gt; git push origin master git tag  打 tag  git tag -a {tag name} {commit id}  推送 tag 到远端  git push origin {tag name} ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-git/image_hu9a230336efb1ccd23b21d20aba4c6df2_292131_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-git/","title":"Linux 命令 —— git"},{"content":"ip 显示/操纵路由、设备、策略路由、隧道。\n概要 ip [ OPTIONS ] OBJECT { COMMAND | help } ip [ -force ] -batch filename OBJECT := { link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | tcp_metrics } OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] | -r[esolve] | -f[amily] { inet | inet6 | ipx | dnet | link } | -o[neline] | -n[etns] name | -a[ll] | -c[olor] } OBJECT:\n address - 一个设备的IPv4/IPv6地址。（缩写：a 或 addr） addrlabel - 协议地址选择的标签配置。 （缩写：addrl） l2tp - IP隧道以太网(L2TPv3). link - 网络设备。如eth0。 （ 缩写：l） maddress - 多播地址。 （缩写：m 或 maddr） monitor - 监测netlink消息 mroute - 组播路由缓存条目。 （缩写：mr） mrule - 组播路由策略数据库中的规则。 neighbour - 管理 ARP 或 NDISC 缓存条目。（缩写：n or neigh） netns - 管理网络命名空间。 ntable - 管理邻居缓存的操作。 route - 路由表中的路由规则。 （缩写：r） rule - 路由策略数据库中的规则。 （缩写：ru tcp_metrics/tcpmetrics - 管理 TCP Metrics。 tunnel - IP隧道。 （缩写：t） tuntap - 管理 TUN/TAP 设备。 xfrm - 管理 IPSec 策略。 （缩写：x）  选项 -V, -Version 打印ip实用工具/iproute2的版本。 -h, -human, -human-readable 输出具有人类可读值的后跟后缀的统计信息。 -b, -batch \u0026lt;FILENAME\u0026gt; 从提供的文件或标准输入中读取命令并调用它们。首次失败将导致ip终止。 -force 不在批处理模式出错时终止ip。如果在执行命令期间出现任何错误，则应用程序返回代码将不为零。 -s, -stats, -statistics 输出更多信息。如果选项出现两次或更多次，则信息量会增加。通常，信息是统计信息或某些时间值。 -d, -details 输出更多细节信息。 -l, -loops \u0026lt;COUNT\u0026gt; 指定\u0026#39;ip address flush\u0026#39;逻辑在放弃之前将尝试的最大循环次数。默认值为10。零(0)表示一直循环到删除所有地址。 -f, -family \u0026lt;FAMILY\u0026gt; 指定要使用的协议族。 协议族标识符可以是inet，inet6，bridge，ipx，dnet，mpls或link之一。 如果此选项不存在，则从其他参数中猜出协议族。 如果命令行的其余部分没有提供足够的信息来猜测，则ip会使用一个默认值，通常是inet或any。 link是一个特殊的系列标识符，表示不涉及任何网络协议。 -4 -family inet 的简写. -6 -family inet6 的简写. -B -family bridge 的简写. -D -family decnet 的简写. -I -family ipx 的简写. -M -family mpls 的简写. -0 -family link 的简写. -o, -oneline 将每条记录输出到单一的行，用\u0026#39;\\\u0026#39;字符替换换行符。 当您想要使用wc或grep输出计数记录时，这很方便。 -r, -resolve 使用系统的名称解析程序来打印DNS名称而不是主机地址。 -n, -netns \u0026lt;NETNS\u0026gt; 将ip切换到指定的网络命名空间NETNS。 实际上它只是简化执行： ip netns exec NETNS ip [ OPTIONS ] OBJECT { COMMAND | help } 到 ip -n[etns] NETNS [ OPTIONS ] OBJECT { COMMAND | help } -a, -all 对所有对象执行指定的命令，它取决于命令是否支持此选项。 -c, -color 使用颜色输出。 -t, -timestamp 使用monitor选项时显示当前时间。 示例 查看详细的接口信息  ip -c -d -s -s link show ip -c -d -s -s link show ens33\n 查看接口地址  ip addr shwo ens33 ip -4 addr show ens33 ip -6 addr show ens33\n 为接口添加地址  ip addr add \u0026lt;IP 地址/前缀长度\u0026gt; [broadcast \u0026lt;广播地址\u0026gt;] dev \u0026lt;接口名\u0026gt; ip addr add 192.168.2.102/24 dev ens33 IPv6地址加-6即可。\n 删除接口地址  sudo ip addr del 192.168.2.102/24 dev ens33\n 启用接口  ip link set ens33 up\n 禁用接口  ip link set ens33 down\n 设置接口MAC地址 设置前需要先禁用接口\n ip link set ens33 address 00:0c:29:a5:ce:35\n 设置接口MTU  ip link set ens33 mtu 1500\n 添加802.1Q VLAN接口  ip link add link \u0026lt;接口名\u0026gt; name \u0026lt;子接口名\u0026gt; type vlan id sudo ip link add link ens33 name ens33.1 type vlan id 10\n 删除一个接口  sudo ip link del ens33.1\n 查看路由表  sudo ip route show\n 查看指定目标地址用的那条路由规则  ip route get 192.168.2.103\n 添加默认路由  ip route add default via \u0026lt;默认网关\u0026gt; [dev \u0026lt;出接口\u0026gt;]\n 添加路由表项  ip route add \u0026lt;目标 IP 地址/前缀长度\u0026gt; via \u0026lt;下一跳\u0026gt; [dev \u0026lt;出接口\u0026gt;] sudo ip route add 192.168.2.0/24 via 192.168.2.1 dev ens33\n 删除路由表项  sudo ip route del 192.168.3.0/24 dev ens33\n 查看ARP表  ip neigh show dev ens33\n 添加永久ARP条目  ip neigh add \u0026lt;IP 地址\u0026gt; lladdr \u0026lt;以冒号分割的 MAC 地址\u0026gt; dev \u0026lt;接口名\u0026gt; nud permanent ip neigh add 192.168.2.149 lladdr e0:d5:5e:a1:d0:d1 dev ens33 nud permanent\n 把动态ARP条目转换为永久ARP条目  ip neigh change \u0026lt;IP 地址\u0026gt; dev \u0026lt;接口名\u0026gt; nud permanent\n 删除ARP条目  ip neigh del \u0026lt;IP 地址\u0026gt; dev \u0026lt;接口名\u0026gt; ip neigh del 192.168.2.149 dev ens33\n 清空ARP表（不影响永久条目）  ip neigh flush all\n 参考  https://zhuanlan.zhihu.com/p/28155886 https://ss64.com/bash/ip.html linux man page  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-ip/image_hu9a230336efb1ccd23b21d20aba4c6df2_292131_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-ip/","title":"Linux 命令 —— ip"},{"content":"modprobe modprobe - 向Linux内核添加或从内核移除模块。\nmodprobe智能地从Linux内核添加或删除模块：\n 注意，模块名称中-和_没有区别（自动执行下划线转换）。 modprobe在模块目录/lib/modules/'uname -r'(符号冲突了，用'代替)中查找所有模块和其他文件。  除了/etc/modprobe.d目录是的可选配置文件。详见modprobe.d   modprobe还将以\u0026lt;module\u0026gt;.\u0026lt;option\u0026gt;的形式使用内核命令行上指定的模块选项。  modprobe.blacklist=\u0026lt;module\u0026gt;的形式使用黑名单。   如果在modulename之后给出了任何参数，它们将被传递给内核。  除了配置文件中列出的选项。    用法 modprobe [-v] [-V] [-C config-file] [-n] [-i] [-q] [-b] [modulename] [module parameters...] modprobe [-r] [-v] [-n] [-i] [modulename...] modprobe [-c] modprobe [--dump-modversions] [filename] 选项 -a, --all 加载命令行中指定的所有模块。 -b, --use-blacklist 此选项使modprobe将配置文件（如果有）中的黑名单命令也应用于模块名称。 它通常由udev(7)使用。 -C, --config 此选项会覆盖缺省配置目录（/etc/modprobe.d） 此选项通过安装或删除命令传递给 MODPROBE_OPTIONS环境变量中 的其他modprobe命令。 -c, --showconfig 输出config目录中的有效配置并退出。 --dump-modversions 打印出模块所需的模块版本信息列表。 分发版通常使用此选项，以便使用模块版本控制deps(依赖？)打包Linux内核模块。 -d, --dirname 模块的根目录，默认是`/`。 --first-time 通常，如果告知插入已存在的模块或删除不存在的模块，modprobe将成功（并且不执行任何操作）。 这是简单脚本的理想选择; 然而，更复杂的脚本通常想知道modprobe是否真的做了一些事情： 这个选项使modprobe失败，因为它实际上没有做任何事情。 --force-vermagic 每个模块都包含一个包含重要信息的小字符串，例如内核和编译器版本。 如果模块无法加载并且内核抱怨`version magic`不匹配，则可以使用此选项将其删除(抱怨)。 当然，这个检查是为了保护你的，所以这个使用选项是危险的，除非你知道你在做什么。 这适用于插入的任何模块：命令行上的模块（或别名）以及它所依赖的任何模块。 --force-modversion 当使用CONFIG_MODVERSIONS集编译模块时，会创建模块使用（或由模块提供）的每个接口的版本的详细说明。 如果模块无法加载并且内核抱怨模块不同意某个接口的版本，则可以使用“--force-modversion”来完全删除版本信息。 当然，这项检查是为了保护您的，所以使用此选项是危险的，除非您知道自己在做什么。 这适用于插入的任何模块：命令行上的模块（或别名）以及它所依赖的任何模块。 -f, --force 尝试从模块中删除任何可能阻止加载的版本信息：这与使用--force-vermagic和--force-modversion相同。 当然，这些检查是为了您的保护，所以使用此选项是危险的，除非您知道自己在做什么。 这适用于插入的任何模块：命令行上的模块（或别名）以及它所依赖的任何模块。 -i, --ignore-install, --ignore-remove 此选项使modprobe忽略命令行中，指定的模块的配置文件（如果有）中的安装和删除命令（任何相关模块仍然受配置文件中为它们设置的命令的限制）。 当使用此选项时，无论是否仅使用--ignore-install或--ignore-remove中的一个或其他（而不是两个）更具体地进行请求，将忽略安装和删除命令。 详见modprobe.d(5)。 -n, --dry-run, --show 除了实际插入或删除模块（或运行安装或删除命令）之外，此选项可以执行所有操作。 与-v结合使用，可用于调试问题。 由于历史原因，--dry-run和--show实际上意味着相同的事情并且可以互换。 -q, --quiet 使用此标志，如果您尝试删除或插入无法找到的模块（并且不是别名或安装/删除命令），modprobe将不会打印错误消息。 但是，它仍将以非零退出状态返回。 内核使用它来机会性地探测可能存在的正在使用request_module的模块。 -R, --resolve-alias 打印与别名匹配的所有模块名称。这对于调试模块别名问题很有用。 -r, --remove 这个选项使modprobe删除而不是插入一个模块。 如果它依赖的模块也没有使用，modprobe讲尝试移除它们。 不像插入可以在命令行上指定多个模块。（意思是-r指定移除一个？） （在删除模块时指定模块参数没有意义） 通常没有理由删除模块，但有些错误的(buggy)模块需要它。 您的发行版内核可能尚未构建为支持删除模块。 -S, --set-version 设置内核版本，而不是使用uname(2)来决定内核版本（它决定了在哪里找到模块）。 --show-depends 显示模块的依赖，包括模块它自己。 列出模块（或别名）的依赖关系，包括模块本身。 这会生成一组(可能为空)模块文件名，每行一个，每个以“insmod”开头，通常由发行版使用，以确定生成initrd/initramfs映像时要包含哪些模块。 应用的安装命令以“install”为前缀。 它不运行任何安装命令。 请注意，modinfo(8) 可用于从模块本身提取模块的依赖关系，但不知道别名或安装命令。 -s, --syslog 此选项会导致错误消息通过syslog机制（如级别为LOG_NOTICE的LOG_DAEMON）而不是标准错误。 当stderr不可用时，也会自动启用此功能。 此选项通过安装或删除命令传递给MODPROBE_OPTIONS环境变量中的其他modprobe命令。 -V, --version 显示此程序的版本并退出。 -v, --verbose 打印程序正在做什么的信息。 通常modprobe只打印出错的信息。 此选项通过安装或删除命令传递给MODPROBE_OPTIONS环境变量中的其他modprobe命令。 示例 加载模块  modprobe vfat\n 卸载模块  modprobe -r vfat\n 查看模块的配置文件  modprobe -r\n 输出类似：\nalias ip6t_conntrack xt_conntrack alias ip_conntrack nf_conntrack_ipv4 alias symbol:__nf_conntrack_confirm nf_conntrack alias symbol:ct_sip_parse_request nf_conntrack_sip  symbol：应该是说这个是nf_conntrack中的符号（也就是函数）。【？？？】  疑问  modprobe -r输出的含义？  相关  modprobe.d insmod rmmod lsmod modinfo  参考 ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-modprobe/image_hu59cc54696cb592a00ff642a6eb2b1685_283782_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-modprobe/","title":"Linux 命令 —— modprobe"},{"content":"netstat 显示当前的连接情况。（UDP、TCP、UNIX、ICMP等） 显示路由表、网络接口列表、网络统计信息、多播信息、伪装连接等。\n1. 介绍 1.1 用法 netstat [-vWeenNcCF] [\u0026lt;Af\u0026gt;] -r netstat {-V|--version|-h|--help} netstat [-vWnNcaeol] [\u0026lt;Socket\u0026gt; ...] netstat { [-vWeenNac] -i | [-cWnNe] -M | -s } 1.2 选项 -r, --route 显示路由表 -i, --interfaces 显示接口列表 -g, --groups 显示多播组成员 -s, --statistics 显示网络统计信息 -M, --masquerade display masqueraded connections【？？？】 -v, --verbose 详细 -W, --wide 不要截断IP地址 -n, --numeric 不要解析IP成域名（直接使用IP，不经过域名服务器） --numeric-hosts 不要解析主机名 --numeric-ports 不要解析端口名 --numeric-users 不要解析用户名 -N, --symbolic 解析硬件名 【？？？】 -e, --extend 显示更多信息 -p, --programs 显示进程ID和进程名 -c, --continuous 持续列出网络状态 -l, --listening 显示LISTENING状态的连接 -a, --all, --listening 显示所有连接(默认: 显示CONNECTED的连接) -o, --timers 显示计时器 【netstat -to】 -F, --fib 显示转发信息库（Forwarding Information Base），默认显示 -C, --cache 显示路由缓存(routing cache)而不是FIB -t, --tcp 显示TCP信息 -u, --udp 显示UDP信息 -w, --raw 实现raw信息 -x, --unix 显示unix信息 --ax25 显示AMPR AX.25信息 --ipx 显示Novell IPX信息 --ddp 显示Appletalk DDP信息 \u0026lt;Socket\u0026gt;={-t|--tcp} {-u|--udp} {-w|--raw} {-x|--unix} --ax25 --ipx --netrom \u0026lt;AF\u0026gt;=Use \u0026#39;-6|-4\u0026#39; or \u0026#39;-A \u0026lt;af\u0026gt;\u0026#39; or \u0026#39;--\u0026lt;af\u0026gt;\u0026#39;; default: inet 可能的地址系列列表（支持路由）: inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25) netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP) x25 (CCITT X.25) 2. 示例 查看端口是否被占用 netstat -tuanp | grep 53 获取进程ID/进程名 netstat -ap 显示网络统计数据 netstat -s 显示路由表 netstat -r 显示网络接口 netstat -i netstat -ie 显示LISTENING(监听)状态的连接 netstat -l 3. 疑问 masqueraded connections是什么？ ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-netstat/image_hu0d592102e033b96588ada77308d430a0_228400_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-netstat/","title":"Linux 命令 —— netstat"},{"content":"strace strace - 跟踪系统调用和信号。\n在最简单的情况下，strace运行指定的命令直到它退出。 它拦截并记录由进程调用的系统调用和进程接收的信号。 每个系统调用的名称，其参数和返回值都打印在标准错误或使用-o选项指定的文件上。 strace是一种有用的诊断，指导和调试工具。 跟踪中的每一行都包含系统调用名称，后跟括号中的参数及其返回值。如：\nopen(\u0026#34;/dev/null\u0026#34;, O_RDONLY) = 3 系统调用错误，如：(返回 -1，并打印出错原因)\nopen(\u0026#34;/foo/bar\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) 信号，如：\nsigsuspend([] \u0026lt;unfinished ...\u0026gt; --- SIGINT (Interrupt) --- +++ killed by SIGINT +++ 正在执行系统调用的同时，另一个线程/进程调用另一个系统调用，则strace将尝试保留这些事件的顺序并将正在进行的调用标记为未完成。 当调用返回时，它将被标记为已恢复：\n[pid 28772] select(4, [3], NULL, NULL, NULL \u0026lt;unfinished ...\u0026gt; [pid 28779] clock_gettime(CLOCK_REALTIME, {1130322148, 939977000}) = 0 [pid 28772] \u0026lt;... select resumed\u0026gt; ) = 1 (in [3]) 系统调用被中断后重启，如：\nread(0, 0x7ffff72cf5cf, 1) = ? ERESTARTSYS (To be restarted) --- SIGALRM (Alarm clock) @ 0 (0) --- rt_sigreturn(0xe) = 0 read(0, \u0026#34;\u0026#34;..., 1) = 0 解引用结构指针，并根据需要显示成员。 在所有情况下，参数都以尽可能类似C的方式格式化。 例如“ls -l /dev/null”：\nlstat(\u0026#34;/dev/null\u0026#34;, {st_mode=S_IFCHR|0666, st_rdev=makedev(1, 3), ...}) = 0 解引用字符指针：\nread(3, \u0026#34;root::0:0:System Administrator:/\u0026#34;..., 1024) = 422 用法 strace [-CdffhiqrtttTvVxxy] [-In] [-bexecve] [-eexpr]... [-acolumn] [-ofile] [-sstrsize] [-Ppath]... -ppid... / [-D] [-Evar[=val]]... [-uusername] command [args] strace -c[df] [-In] [-bexecve] [-eexpr]... [-Ooverhead] [-Ssortby] -ppid... / [-D] [-Evar[=val]]... [-uusername] command [args] 选项 -c 统计系统调用的次数、出错次数。在Linux上，这会尝试显示系统时间（在内核中运行的CPU时间），与墙上时间无关。 如果 -c 和 -f 或 -F 一起使用，仅保留所有跟踪进程的聚合总计。 -C 与-c类似，但在进程运行时也会打印常规输出。 -D 将跟踪器进程作为分离的孙子(detached grandchild)进程运行，而不是作为tracee的父进程。 这通过将tracee保持为调用进程的直接子进程来减少strace的可见效果 -d 在标准错误上输出strace的debug信息。 -f 跟踪由fork/vfork/clone调用所产生的子进程。 注意，如果是多线程，则\u0026#34;-p PID -f\u0026#34;将附加到PID进程的所有线程，而不仅是附加到带有 \u0026#34;thread_id = PID\u0026#34; 的线程。 -ff 如果\u0026#34;-o filename\u0026#34;选项生效，则每个进程的跟踪信息都将写入filename.pid中，其中pid是每个进程的进程ID。 这与-c不兼容，因为不保留每进程计数。 -F 此选项现已过时，它具有与-f相同的功能。 -h 打印帮助。 -i 在系统调用时打印指令指针。 -q 不显示有关附加/分离(attaching/detaching)的消息。 当输出重定向到文件并且命令是直接运行的(而不是附加(attaching))的，会自动发生这种情况。 -qq 不显示有关进程退出状态的消息。 -r 在进入每个系统调用时打印相对时间戳。 这记录了连续系统调用开始之间的时间差。 -t 在每一行跟踪信息前面添加时间（一天中的时间），最小单位是秒。 -tt 在每一行跟踪信息前面添加时间（一天中的时间），最小单位是毫秒。 -ttt 打印的时间将包括微秒，并且前导部分将被打印为自纪元以来的秒数。 -T 显示系统调用花费的时间。 这记录了每个系统调用的开始和结束之间的时间差。 -v 打印environment、stat、termios等调用的未缩写版本。 这些结构在调用中非常常见，因此默认行为显示结构成员的合理子集。 使用此选项可获得所有细节。 -V 打印strace的版本. -x 以十六进制字符串格式打印所有非ASCII字符串。 -xx 以十六进制字符串格式打印所有字符串。 -y 打印与文件描述符参数关联的路径。 -a column 对齐特定列中的返回值（默认列40）。 -b syscall 如果到达指定的系统调用，则从跟踪的进程中分离。 目前，仅支持execve系统调用。 这个选项很有用，如果你想要跟踪多线程的进程(需要-f)，但不想跟踪其（可能非常复杂的）孩子。 -e expr 用于修改要跟踪的事件或如何跟踪它们的一个限定表达式。 表达式的格式是： [qualifier=][!]value1[,value2]... qualifier是trace，abbrev，verbose，raw，signal，read，write之一，value是依赖于限定符的符号或数字。 默认限定符是trace。使用感叹号会取消该组值。 例如，\u0026#34;-e open\u0026#34;表示字面意思\u0026#34;-e trace=open\u0026#34;，这意味着仅跟踪“open”的系统调用。 相比之下，“-e trace=open”表示跟踪除open之外的每个系统调用。 此外，特殊值all和none都有明显的含义。 请注意，即使在引用的参数中，某些shell也会使用感叹号进行历史记录扩展。 注意，有些shell使用\u0026#34;!\u0026#34;来执行历史记录里的命令，如果是这样，您必须使用反斜杠转义感叹号。 -e trace=set 只跟踪指定的系统调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认为set=all。 -e trace=file 只跟踪有关文件操作的系统调用。（跟踪所有以一个文件名作为参数的系统调用） 你可以看做是：-e trace=open,stat,chmod,unlink,... 这对于查看进程引用的文件很有用。 此外，使用缩写将确保您不会意外忘记在列表中包含类似lstat的调用。 -e trace=process 只跟踪有关进程控制的系统调用。 这对于查看进程的fork，wait和exec步骤非常有用。 -e trace=network 跟踪所有与网络相关的系统调用. -e trace=signal 跟踪所有与信号相关的系统调用. -e trace=ipc 跟踪所有与IPC相关的系统调用. -e trace=desc 跟踪所有与文件描述符相关的系统调用. -e trace=memory 跟踪与内存映射相关的所有系统调用. -e abbrev=set 设定strace输出的系统调用的结果集。\u0026#34;-v\u0026#34;选项等于“abbrev=none”，默认为“abbrev=all”. -e verbose=set 对指定系统调用集的结构进行解引用。 默认值为 \u0026#34;verbose=all\u0026#34;。 -e raw=set 将指定的系统调用的参数以十六进制显示。（为指定的系统调用集打印原始的，未解码的参数。） 如果您不信任解码或者您需要知道参数的实际数值，这将非常有用。 -e signal=set 指定跟踪的系统信号.默认为all.如\u0026#34;signal=!SIGIO\u0026#34;(或者signal=!io),表示不跟踪SIGIO信号. -e read=set 以完整的16进制或ASCII形式，输出所有从指定文件描述符集中读取的数据。例如: \u0026#34;-e read=3,5\u0026#34;，读文件描述符3和5上的所有输入活动。 请注意请注意，这与read(2)系统调用的正常跟踪无关，该调用由选项\u0026#34;-e trace=read\u0026#34;控制。 -e write=set 以完整的16进制或ASCII形式，输出所有写到指定文件描述符集的数据。 -I interruptible 当strace可以被信号中断（例如按^C） 1：没有信号被阻挡; 2：解码系统调用时阻塞致命信号（默认）; 3：致命信号总是被阻止（默认为\u0026#39;-o FILE PROG\u0026#39;）; 4：致命信号和SIGTSTP（^Z）始终被阻止（有助于使strace -o FILE PROG不在^Z上停止）。 -o filename 把跟踪信息输出到filename指定的文件而不是输出到stderr。 如果指定\u0026#34;-ff\u0026#34;则会使用filename.pid。 如果参数以\u0026#34;|\u0026#34;或\u0026#34;!\u0026#34;开始，则参数的其余部分会被视作一个命令，并且所有输出都会通过管道给它(此命令)。【？？？】 这样可以方便地将调试输出传递给程序，而不会影响已执行程序的重定向。【？？？】 [If the argument begins with `|\u0026#39; or with `!\u0026#39; then the rest of the argument is treated as a command and all output is piped to it. This is convenient for piping the debugging output to a program without affecting the redirections of executed programs.] -O overhead 将跟踪系统调用的overhead（开销）设置为overhead微秒。 这对于覆盖默认启发式方法非常有用，可以猜测在使用-c选项进行计时系统调用时仅花费多少时间。 可以通过在没有跟踪的情况下对给定程序运行进行计时（使用time(1)）并将累积的系统调用时间与使用-c产生的总数进行比较来测量启发式的准确性。 -p pid 使用进程ID pid附加到进程并开始跟踪。 可以通过键盘中断信号（CTRL-C）随时终止跟踪。 strace会通过将自己从跟踪过程中分离出来而让它（它们）继续运行。 多个-p选项可用于附加到许多进程。 支持-p\u0026#34;`pidof PROG`\u0026#34;语法。 -P path 仅跟踪系统调用访问的路径。 多个-P选项可用于指定多个路径。 -s strsize 指定要打印的最大字符串大小（默认值为32）。 请注意，文件名不被视为字符串，并且始终完整打印。 -S sortby 按指定条件对-c选项打印的直方图的输出进行排序。 合法值是时间(time)，系统调用(call)，名称(name)，默认为时间。(根据什么来排序的意思) -u username 使用用户名所在的\u0026#34;用户ID\u0026#34;，“组ID“和”补充组“来运行命令。 此选项仅在以root身份运行，并且能够正确执行setuid（和/或）setgid二进制文件时有用。 除非使用此选项，否则setuid和setgid程序在没有有效权限的情况下执行。 -E var=val 在其环境变量列表中运行带有var=val的命令。 -E var 在将var传递给命令前，从继承的环境变量列表中将var删除。 示例 显示每个系统调用的相对时间  strace -r ls ls表示ls命令\n 显示系统调用时间（一天当中的时间/纪元时间）  strace -t ls strace -tt ls strace -ttt ls\n 打印与文件描述符相关联的路径  strace -y ls\n 跟踪指定进程  strace -p 123\n 把输出存在文件中  strace -o ls.log ls\n 相关  ltrace(1) time(1) ptrace(2) proc(5)  参考  https://man.linuxde.net/strace Linux man page  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-strace/image_hud0302cb28f3acf717dc2c63099887f29_175873_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-strace/","title":"Linux 命令 —— strace"},{"content":"tcpdump tcpdump - dump traffic on a network（转储网络上的流量）。\n用法 tcpdump [ -AbdDefhHIJKlLnNOpqStuUvxX# ] [ -B buffer_size ] [ -c count ] [ -C file_size ] [ -G rotate_seconds ] [ -F file ] [ -i interface ] [ -j tstamp_type ] [ -m module ] [ -M secret ] [ --number ] [ -Q in|out|inout ] [ -r file ] [ -V file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ --time-stamp-precision=tstamp_precision ] [ --immediate-mode ] [ --version ] [ expression ] 选项 -A 以ASCII格式打印每个数据包（减去其链接级别标题）。方便捕获网页。 -b 以ASDOT表示法而不是ASPLAIN表示法打印BGP数据包中的AS编号。 -B buffer_size --buffer-size=buffer_size 将操作系统捕获缓冲区大小设置为buffer_size。 -c count 收到count个包后退出。 -C file_size 在将原始数据包写入保存文件之前，检查该文件当前是否大于file_size，如果是，关闭当前保存文件并打开一个新文件。 第一个文件之后的文件将使用 -w 标志指定名称 ，后面带一个数字，从1开始向上。 file_size的单位是数百万字节（1,000,000字节，而不是1,048,576字节）。 -d 将编译后的数据包匹配代码以人类可读的形式转储到标准输出并停止。 -dd 将数据包匹配代码转储为 C 程序片段。 -ddd 将数据包匹配代码转储为十进制数字（以计数开头）。 -D --list-interfaces 打印系统上可用的网络接口列表以及 tcpdump 可以捕获数据包的列表。 对于每个网络接口，打印数字和接口名称，可能后跟接口的文本描述。 可以将接口名称或编号提供给 -i 标志以指定要捕获的接口。 这对于没有列出命令的系统很有用。 如果tcpdump是用缺少pcap_findalldevs()的libpcap建立的，则不支持此选项(-D)。 -e 在每个转储行上打印链接级标题。例如，这可以用于打印诸如以太网和IEEE 802.11之类的协议的MAC层地址。 -E 使用 spi@ipaddr algo:secret来解密发送到addr并包含安全参数索引值 spi的 IPsec ESP数据包。 可以用逗号或换行符分隔重复该组合。 请注意，此时支持为IPv4 ESP数据包设置机密。 算法可以是 des-cbc， 3des-cbc， blowfish-cbc， rc3-cbc， cast128-cbc或 none。默认为des-cbc。 只有在启用加密编译tcpdump的情况下才能解密数据包。 secret是ESP密钥的ASCII文本。如果前面带有0x，则将读取十六进制值。 此选项在RFC2406提出，不是在RFC1827。 该选项仅用于调试目的，不鼓励使用此选项和真正的“secret”密钥。通过在命令行上显示IPsec密钥，您可以通过ps和其他场合将其显示给其他人。 除了上面的语法之外，语法文件名可以用来让tcpdump读取提供的文件。 文件在收到第一个ESP数据包后打开，所以tcpdump应该具备所有可能需要的特殊权限。 -f 以数字方式而不是符号方式打印“外来(foreign)”IPv4地址。 “外部”IPv4地址的测试是使用正在进行捕获的接口的IPv4地址和网络掩码完成的。 -F file 使用file作为过滤器表达式的输入。命令行上给出的附加表达式将被忽略。 -G rotate_seconds 如果指定，每rotate_second秒回转(rotate)-w指定的文件。【回转？？？】 保存文件将具有-w指定的名称，该名称 应包含strftime定义的时间格式。 如果未指定时间格式，则每个新文件都将覆盖前一个。 每当生成的文件名不唯一时，tcpdump将覆盖预先存在的数据; 因此，不建议提供比捕获周期更粗糙的时间规范。 如果与 -C 选项一起使用，文件名将采用\u0026#34;file\u0026lt;count\u0026gt;\u0026#34;的形式。 -h --help 打印tcpdump和libpcap版本字符串，打印用法消息，然后退出。 --version 打印tcpdump和libpcap版本字符串并退出。 -H 尝试检测802.11s草图网格标头。 -i interface --interface=interface 指定监听的接口。 如果未指定，tcpdump将在系统接口列表中搜索编号最小的已配置接口（不包括环回），这可能会变成例如“eth0”。 在具有2.2或更高版本内核的Linux系统上， 可以使用“any” 的 接口参数来捕获来自所有接口的数据包。 请注意，“any”设备上的捕获将不会以混杂模式完成。 如果 支持-D标志，则如果系统上没有任何接口将该数字作为名称，则该标志打印的接口号可用作 接口参数。 -I --monitor-mode 将接口置于“监控模式(monitor mode)”; 这仅在IEEE 802.11 Wi-Fi接口上受支持，并且仅在某些操作系统上受支持。 请注意，在监视器模式下，适配器可能与与其关联的网络取消关联，因此您将无法使用具有该适配器的任何无线网络。 如果您在监视器模式下捕获并且未使用其他适配器连接到另一个网络，则可能会无法访问网络服务器上的文件或解析主机名或网络地址。 该标志将影响-L 标志的输出 。 如果未指定-I，则仅显示未处于监控模式时可用的链路层类型; 如果指定-I，则仅显示处于监视模式时可用的链接层类型。 --immediate-mode 在“立即模式(immediate mode)”下进行数据包捕获。 在此模式下，数据包一到达就会传送到tcpdump，而不是为了提高效率而进行缓冲。 这是打印数据包时的默认设置。 -j tstamp_type --time-stamp-type=tstamp_type 将捕获的时间戳类型设置为tstamp_type。 pcap-tstamp中给出时间戳类型的名称; 并非所有列出的类型都必须对任何给定的接口有效。 -J --list-time-stamp-types 列出接口支持的时间戳类型并退出。如果无法为接口设置时间戳类型，则不会列出时间戳类型。 --time-stamp-precision=tstamp_precision 捕获时，将捕获的时间戳精度设置为 tstamp_precision。 请注意，高精度时间戳（纳秒）的可用性及其实际精度取决于平台和硬件。 还要注意，当以纳秒级精度将捕获写入保存文件时，时间戳以纳秒分辨率写入，并且文件使用不同的幻数编写，以指示时间戳以秒和纳秒为单位; 并非所有读取pcap文件的程序都能读取这些捕获。 读取保存文件时，将时间戳转换为timestamp_precision指定的精度，并以该分辨率显示它们。 如果指定的精度小于文件中时间戳的精度，则转换将失去精度。 为支持的值timestamp_precision是微为微秒分辨率和纳米为十亿分之一秒分辨率。 默认值为微秒分辨率。 -K --dont-verify-checksums 不尝试验证IP，TCP或UDP校验和。 这对于在硬件中执行部分或全部校验和计算的接口非常有用; 否则，所有传出的TCP校验和都将被标记为错误。 -l 使stdout行缓冲。 如果您想在捕获数据时查看数据，则非常有用。 例如：tcpdump -l | tee dat 或： tcpdump -l \u0026gt; dat \u0026amp; tail -f dat 请注意，在Windows上，“行缓冲”意味着“无缓冲”，因此如果指定了-l，WinDump将单独写入每个字符。 -U 在其行为上类似于 -l，但它会导致输出为“数据包缓冲” 因此输出在每个数据包的末尾而不是在每行的末尾写入stdout; 这是在所有平台上缓冲的，包括Windows。 -L --list-data-link-types 在指定模式下列出接口的已知数据链接类型，然后退出。 已知数据链接类型列表可能取决于指定的模式; 例如，在某些平台上，Wi-Fi接口可能在不处于监控模式时支持一组数据链路类型和处于监控模式时的另一组数据链路类型。 -m module 从文件模块加载SMI MIB模块定义。可以多次使用此选项将多个MIB模块加载到tcpdump中。 -M secret 使用secret作为共享密钥，使用TCP-MD5选项（RFC 2385）验证TCP段中的摘要（如果存在）。 -n 不要将地址（即主机地址，端口号等）转换为名称。 -N 不要打印主机名的域名限定。例如，如果你指定这个标记，那么tcpdump将打印\u0026#34;nic\u0026#34;而不是\u0026#34;nic.ddn.mil\u0026#34;。 -# --number 在行的开头打印一个可选的包号。 -O --no-optimize 不要运行数据包匹配代码优化器。仅当您怀疑优化器中存在错误时，此选项才有用。 -p --no-promiscuous-mode 不要将接口置于混杂模式。 请注意，由于某些其他原因，接口可能处于混杂模式; 因此，\u0026#34;-p\u0026#34;不能用作\u0026#34;ether host {local-hw-addr}\u0026#34;或\u0026#34;ether broadcast\u0026#34;的缩写。 -Q direction --direction=direction 选择发送/接收方向上的哪些数据包应该被捕获。可能的值是“in”，“out”和“inout”。并非适用于所有平台。 -q 快速（安静？）输出。打印较少的协议信息，因此输出线更短。 -r file 从文件读取数据包（使用 -w 选项或其他编写pcap或pcapng文件的工具创建 ）。如果文件是\u0026#34;-\u0026#34;，则使用标准输入。 -S --absolute-tcp-sequence-numbers 打印绝对而非相对的TCP序列号(sequence numbers)。默认是相对。 -s snaplen --snapshot-length=snaplen Snarf snaplen来自每个数据包的数据字节而不是默认值262144字节。 由于快照有限而被截断的数据包在输出中用\u0026#34;[|proto]\u0026#34;，其中proto 是发生截断的协议级别的名称。 请注意，拍摄较大的快照会增加处理数据包所需的时间，并有效地减少数据包缓冲量。这可能会导致数据包丢失。 另请注意，拍摄较小的快照会丢弃传输层上方协议的数据，这会丢失可能很重要的信息。 例如，NFS和AFS请求和回复非常大，如果选择了太短的快照长度，则很多细节将不可用。 如果您需要将快照大小减小到默认值以下，则应将snaplen限制为捕获您感兴趣的协议信息的最小数量。 将snaplen设置 为0会将其设置为默认值262144，以便向后兼容最近的旧版本tcpdump的版本 。 -T type 强制将\u0026#34;expression\u0026#34;选择的数据包解释为指定的类型。 目前已知的类型是 aodv（Ad-hoc按需距离矢量协议），carp（通用地址冗余协议）， cnfp（Cisco NetFlow协议）， lmp（链路管理协议）， pgm（实用通用多播）， pgm_zmtp1（ZMTP/1.0内部PGM/EPGM），resp（REdis序列化协议）， radius（RADIUS）， rpc（远程过程调用）， rtp（实时应用程序协议）， rtcp（实时应用程序控制协议）， snmp（简单网络管理协议）， tftp（普通文件传输协议）， 增值税（视觉音频工具）， wb（分布式白板）， zmtp1（ZeroMQ消息传输协议1.0）和 vxlan（虚拟可扩展局域网）。 请注意，上面的pgm类型仅影响UDP解释，无论如何，本机PGM始终被识别为IP协议113。 UDP封装的PGM通常称为\u0026#34;EPGM\u0026#34;或\u0026#34;PGM/UDP\u0026#34;。 请注意，上面的pgm_zmtp1类型会同时影响本机PGM和UDP的解释。 在本机PGM解码期间，ODATA/RDATA分组的应用数据将被解码为具有ZMTP/1.0帧的ZeroMQ数据报。 在UDP解码期间，除了任何UDP分组之外，任何UDP分组都将被视为封装的PGM分组。 -t 不在每个转储行上打印时间戳。 -tt 打印时间戳，自1970年1月1日00:00:00，UTC以及自该时间以来的每秒分数，在每个转储行上。 -ttt 在每个转储行上的当前行和上一行之间 打印增量（微秒或纳秒分辨率，具体取决于--time-stamp-precision选项）。 默认值为微秒分辨率。 -tttt 在每个转储行上打印一个时间戳，以小时，分钟，秒和从午夜开始的一小时一秒为止。 -ttttt 在每个转储行上的当前行和第一行之间打印增量（微秒或纳秒分辨率，具体取决于 --time-stamp-precision选项）。默认值为微秒分辨率。 -u 打印未解码的NFS句柄。 -U --packet-buffered 如果未指定 -w 选项，或者如果指定了 -w 选项但是也指定了 --print 标志，则使打印的数据包输出\u0026#34;packet-buffered\u0026#34;； 即，当打印每个数据包的内容的描述时，它将被写入标准输出，而不是，在不写入终端时，仅在输出缓冲器填满时写入。 ( i.e., as the description of the contents of each packet is printed, it will be written to the standard output, rather than, when not writing to a terminal, being written only when the output buffer fills.) 如果指定了 -w 选项，则保存的原始数据包输出\u0026#34;packet-buffered\u0026#34;; 即，在保存每个数据包时，它将被写入输出文件，而不是仅在输出缓冲区填满时才写入。 该 -U 如果标志将不被支持, 如果旧版本tcpdump内置的libpcap缺少pcap_dump_flush（3PCAP） 函数。 -v 解析和打印时，产生（略多）详细输出。 例如，打印IP包中的生存时间，标识，总长度和选项。 还可以启用其他数据包完整性检查，例如验证IP和ICMP标头校验和。 使用-w 选项写入文件时 ，每秒报告一次捕获的数据包数。 -vv 更详细的输出。例如，从NFS回复数据包打印其他字段，并完全解码SMB数据包。 -vvv 更详细的输出。例如，telnet SB ... SE选项全部打印。与 -X 的Telnet选项被印刷在十六进制为好。 -V file 从文件中读取文件名列表。如果文件是\u0026#34;-\u0026#34;，则使用标准输入。 -w file 将原始数据包写入文件而不是解析并打印出来。 稍后可以使用-r选项打印它们。如果文件是“ - ”，则使用标准输出。 如果写入文件或管道，则此输出将被缓冲，因此从文件或管道读取的程序在收到后可能无法在任意时间内看到数据包。 使用 -U 标志可以在收到数据包后立即写入数据包。 MIME类型application/vnd.tcpdump.pcap已在IANA注册pcap文件。 文件扩展名.pcap是最常用的。 但是，许多操作系统和应用程序将使用扩展（如果存在）并建议添加一个（例如.pcap） 读取捕获文件时Tcpdump本身不检查扩展名，并且在写入时不添加扩展名（它在文件头中使用幻数）。 有关文件格式的说明，请参阅 pcap-savefile。 -W 与 -C 选项一起使用时 ，这将限制创建的文件数量达到指定的数量，并从头开始覆盖文件，从而创建一个“旋转”缓冲区。 此外，它会将具有足够前导0的文件命名为支持最大文件数，从而允许它们正确排序。 与 -G 选项一起使用时 ，这将限制创建的旋转转储文件的数量，在达到限制时退出状态0。 如果两者配合使用 -C 和 -G， 该 -W 选项将目前被忽略，并且只会影响的文件名。 -x 解析和打印时，除了打印每个数据包的标头外，还要以十六进制格式打印每个数据包的数据（减去其链接级别标题）。 将打印整个数据包或snaplen字节中较小的一个 。 请注意，这是整个链路层数据包，因此对于填充（例如以太网）的链路层，当较高层数据包短于所需填充时，也将打印填充字节。 -xx 解析和打印时，除了打印每个数据包的标头外，还要打印每个数据包的数据， 包括其链接级别标题，以十六进制表示。 -X 解析和打印时，除了打印每个数据包的标题外，还要以十六进制和ASCII格式打印每个数据包的数据（减去其链接级别标题）。 这对于分析新协议非常方便。 -XX 解析和打印时，除了打印每个数据包的标头外，还要以 十六进制和ASCII格式打印每个数据包的数据， 包括其链接级别标题。 -y datalinktype --linktype=datalinktype 设置要在将数据包捕获到datalinktype时使用的数据链接类型。 -z postrotate-command 与-C 或 -G 选项一起使用时 ，这将使 tcpdump 运行\u0026#34;postrotate-command file\u0026#34;， 其中 file 是每次轮换后关闭的savefile（保存文件，-w创建）。 例如，指定 -z gzip 或 -z bzip2 将使用gzip或bzip2压缩每个savefile。 请注意，tcpdump将使用最低优先级并行执行命令，以便不会干扰捕获过程。 如果您想使用一个本身带有标志或不同参数的命令，您总是可以编写一个shell脚本， 它将保存文件名作为唯一参数，制作标志和参数排列并执行您想要的命令。 -Z user --relinquish-privileges=user 如果 tcpdump 以root运行，打开所述捕获装置或输入savefiles之后， 但在打开任何savefiles输出之前，将用户ID改为user和组ID改为user的主组。 默认情况下，在编译时也可以启用此行为。 expression 选择要转储的数据包。如果没有给出表达式(expression)，则网络上的所有数据包都将被转储。 否则，只会转储表达式为\u0026#34;true\u0026#34;的数据包。 有关表达式语法，请参阅 pcap-filter。 该表达式(expression)参数可被传递给和tcpdump作为单一壳牌参数，或作为多个shell参数，取其更方便。 通常，如果表达式包含Shell元字符，例如用于转义协议名称的反斜杠，则更容易将其作为单个引用参数传递， 而不是转义Shell元字符。在解析之前，多个参数与空格连接在一起。 示例 指定接口+主机，写到文件  tcpdump -i br-lan1 -w x_xxxx.cap -v host xx.xx.xx.xx\n 指定端口范围  tcpdump -i ens33 udp portrange 67-68 -v\n 捕获和指定主机相关的数据包  tcpdump host sundown\n 打印指定主机间的流量  tcpdump host helios and ( hot or ace )\n  helios 和 hot 、 helios 和 ace之间的流量。  打印所有本地主机和Berkeley主机间的流量  tcpdump net ucb-ether\n 通过互联网网关snup打印所有ftp流量(请注意，引用该表达式是为了防止shell（错误地）解释括号）  tcpdump \u0026lsquo;gateway snup and (port ftp or ftp-data)\u0026rsquo;\n 要打印既不是来自本地主机也不是发往本地主机的流量(如果你通往另一个网络，那么这些东西永远不应该进入你的本地网络)  tcpdump ip and not net localnet\n 打印涉及非本地主机的每个TCP对话的开始和结束数据包（SYN和FIN数据包）  tcpdump \u0026lsquo;tcp[tcpflags] \u0026amp; (tcp-syn|tcp-fin) != 0 and not src and dst net localnet\u0026rsquo;\n 打印与端口80之间的所有IPv4 HTTP数据包  仅打印包含数据的数据包，而不打印例如SYN和FIN数据包以及仅ACK数据包 tcpdump \u0026lsquo;tcp port 80 and (((ip[2:2] - ((ip[0]\u0026amp;0xf)\u0026laquo;2)) - ((tcp[12]\u0026amp;0xf0)\u0026raquo;2)) != 0)\u0026rsquo;\n 打印通过网关snup发送的长度超过576字节的IP数据包  tcpdump \u0026lsquo;gateway snup and ip[2:2] \u0026gt; 576\u0026rsquo;\n 打印未通过以太网广播或多播发送的IP广播或多播数据包  tcpdump \u0026lsquo;ether[0] \u0026amp; 1 = 0 and ip[16] \u0026gt;= 224\u0026rsquo;\n 打印所有不是回应请求/回复的ICMP数据包（即不ping数据包）  tcpdump \u0026lsquo;icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply\u0026rsquo;\n 参考  https://www.tcpdump.org/manpages/tcpdump.1.html linux man page\n ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-tcpdump/image_hu8886b919104ef84c776323591f53caab_196334_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-tcpdump/","title":"Linux 命令 —— tcpdump"},{"content":"vmstat 报告虚拟内存统计信息：进程，内存，分页，块IO，陷阱(traps)、磁盘和cpu活动。\n用法 vmstat [options] [delay [count]] vmstat [-f] [-s] [-m] vmstat [-S unit] vmstat [-d] vmstat [-p disk partition] vmstat [-V] 选项 delay 更新之间的延迟，以秒为单位。如果未指定延迟，则仅打印一个报告：自引导以来的平均值。 count 更新次数。如果未指定计数且指定了延迟(delay)，则count默认为无穷大。 -a, --active 显示活动和非活动内存（2.5.41及之后的版本） -f, --forks 显示自引导以来的fork数。 这包括fork，vfork和clone系统调用，并且是相当于创建的任务总数。 每个进程由一个或多个任务表示，具体取决于线程用法。此显示不重复（也就是只显示一次）。 -m, --slabs 显示slabinfo。【相关字段含义见下面部分】 -n, --one-header 标题仅显示一次而不是定期显示。 -s, --stats 显示各种事件计数器和内存统计信息。此显示不重复（也就是只显示一次）。 -d, --disk 报告磁盘信息（2.5.70及之后版本） -D, --disk-sum 报告一些有关磁盘活动的摘要统计信息。 -p, --partition device 分区的详细统计信息。 (2.5.70及之后版本). -S, --unit character 更换输出的单位：1000(k)，1024(K)，1000000(m)，1048576(M) 字节。 注意，这不会改变交换(si/so)或块(bi/bo)字段。 -t, --timestamp 为每一行附加时间戳。 -w, --wide 宽屏输出模式（对于具有较高内存量的系统非常有用，其中默认输出模式会受到不必要的列断裂影响）。 输出宽度会超过每行80个字符。 -V, --version 显示版本信息并退出。 -h, --help 显示帮助信息并退出。 字段描述 VM 模式字段描述  进程  r: 可运行进程的数量 (正在运行+就绪状态)。 b: 处于不可中断睡眠的进程数量。   内存  swpd: 使用的虚拟内存量。 free: 空闲内存量。(idle) buff: 用作缓冲区(buffer)的内存量。 cache: 用作缓存(cache)的内存量。 inact: 非活动内存量。（-a选项） active: 活动内存量。（-a选项）   交换内存  si: 从磁盘交换的内存量（/s）。 so: 交换到磁盘的内存量（/s）。   IO  bi: 从块设备接收的块数（blocks/s）。 bo: 发送到块设备的块数（blocks/ s）。   系统  in: 每秒的中断数，包括时钟。 cs: 每秒上下文切换次数。   CPU  这些是总CPU时间的占比。 us: 运行非内核代码所花费的时间。 (用户时间, 包括nice时间) sy: 运行内核代码所花费的时间。 (系统时间) id: 空闲时间。在2.5.41版本之前，这包括IO等待时间。 wa: 等待IO的时间。在2.5.41版本之前，包含在空闲状态。 st: 从虚拟机中窃取的时间。在Linux 2.6.11之前，未知。【？？？】    DISK 模式字段描述  读(reads)  total: 完全成功的读总数（次数还是字节？应该是次数，因为换单位(K或M)，数值也不改变）。 merged: 分组(groups)读取(导致一个I/O)。 sectors: 成功读取的扇区数。 ms: 花在读上的毫秒数。   写(writes)  total: 完全成功的写总数。 merged: 分组写 (导致一个I/O)。 sectors: 成功写的扇区数。 ms: 花在写上的毫秒数。   IO(input/output)  cur: 正在处理的IO。 s: 花在I/O上的秒数。    DISK PARTITION 模式字段描述  reads: 发送到此分区上的读的总数。 read sectors: 分区上读的扇区总数。 writes: 发送到此分区上的写的总数。 requested writes: 此分区发出的写请求总数。  SLAB 模式字段描述  cache: 缓存名称。 num: 当前活动对象数量。 total: 有效/可用对象总数。 size: 每个对象的大小。 pages: 具有至少一个活动对象的页面数。  示例 显示内存、CPU、中断、fork等总览信息  vmstat -s\n 保持更新固定次数  vmstat -a 2 // 每2s更新一次，一直更新 vmstat -a 1 100 // 每1s更新一次，更新100次\n 显示启动以来的fork数量  vmstat -f\n 显示某个分区统计信息  vmstat -p sda1\n 更换输出单位  vmstat -s -S M\n 显示slab内存对象信息  vmstat -m\n 疑问  st: 从虚拟机中窃取的时间？ 磁盘分区的相关字段不理解？  参考  Linux man page  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-vmstat/image_hu85aaf5f0d41b0975ba4c41b921fc00cc_279865_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/linux-%E5%91%BD%E4%BB%A4-vmstat/","title":"Linux 命令 —— vmstat"},{"content":"全局函数重载 在我个人的开源项目 xway 的中有一个需求：允许用户写 Lua 来自定义一些模块，提供最大的灵活性，但是不把 Lua 模块保存成文件。要如何实现呢？怎么才能从内存中 require 一个模块？答案是重载 require 函数。 利用 Lua 的环境（Environment）特性，在某个独立的环境中重载 require 函数。同时独立的环境也允许我们进行一些限制，例如每个用户只能访问自己的资源。不过，xway 项目计划是不支持多租户，所以限制相关的实现，还未进行相关探索及验证。\n下面直接通过一个例子来说明。\n示例 local ctype_count = require \u0026#34;ctype.count\u0026#34; local ma = [[ local _M = {} function _M.hello() print(\u0026#34;a hello\u0026#34;) end return _M ]] local mb = [[ local ma = require(\u0026#34;ma\u0026#34;) local _M = {} function _M.hello() ma.hello() print(\u0026#34;b hello\u0026#34;) end return _M ]] local module_map = { [\u0026#34;ma\u0026#34;] = ma, [\u0026#34;mb\u0026#34;] = mb, } local function new_require(name) return loadstring(module_map[name])() end local new_env ={ require = new_require, } setmetatable(new_env, {__index = _G}) local m1 = loadstring(mb) setfenv(m1, new_env) print(ctype_count()) local ret, mod = pcall(m1) if not ret then print(ret) end print(ctype_count()) mod.hello()  ma 和 mb 是两个用户自定义模块，形式是存于内存中的字符串。 new_require 是我们重载的新的 require 函数，按我们的需要来编写。 new_env 是一个继承于全局环境(_G)的新环境，用于执行自定义代码。 setfenv 设置函数的环境（mb 模块被 loadstring 成函数了） ctype.count 模块的作用是用于区分是否调用了 ffi 模块，当加载了 ffi 模块时，ctype.count 将增加，因此可以通过判断 pcall 前后 ctype.count 是否变化来判断使用调用了 ffi 模块。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/lua-%E9%87%8D%E8%BD%BD%E5%85%A8%E5%B1%80%E5%87%BD%E6%95%B0-require/image_hu488b2f82ab20ee50f487200f2be764c2_242367_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/lua-%E9%87%8D%E8%BD%BD%E5%85%A8%E5%B1%80%E5%87%BD%E6%95%B0-require/","title":"Lua —— 重载全局函数 require"},{"content":"VLAN VLAN - 虚拟局域网（Virtual Local Area Network）。 在IEEE 802.1Q中，给定以太网上的最大VLAN数为4094。（12位VID。减去头尾的0和4095）\n作用  VLAN可以为网络提供以下作用：  广播控制 带宽利用 降低延迟 安全性（非设计作用，本身功能所附加出的）   采用虚拟局域网技术实现交换机以太网的广播隔离。 一个VLAN相当于OSI模型第2层的广播域，它能将广播控制在一个VLAN内部。 不同VLAN之间或VLAN与LAN/WAN的数据通信必须通过第3层（网络层）完成。  原理（划分方式） 物理层(physical layer)  以交换机端口作为划分VLAN的基础。 适合规模不大的组织。  数据链路层(data link layer)  以每台主机的MAC地址作为划分VLAN的基础。 实现方法：  创建一个MAC与VLAN映射的数据库。 当网络设备连接到端口后，交换机向VMPS(VLAN管理策略服务器)请求这个数据库。 找到相应的映射，完成VLAN的分配。   优点：  计算机物理位置的不同，也不影响VLAN的运作。   缺点：  人为建立MAC与VLAN的映射关系；因此导致管理复杂度增加。    网络层  以IP地址作为划分VLAN的基础；以子网视为VLAN设置的依据。【？？？】 优点：  网管人员已经将内部网段做好规划与分配后，将可大辐降低规划并设置VLANs架构的复杂度。   缺点：  交换机需要对帧进行处理（原本不需要），降低交换机接收和分派分组的效率。    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/vlan-%E4%BB%8B%E7%BB%8D/image_hu6dd6ce6c6dc89dbbcc548f1b0a61c1d9_261937_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/vlan-%E4%BB%8B%E7%BB%8D/","title":"VLAN 介绍"},{"content":"SSL/TLS为了更安全的通信\n什么是SSL/TLS？  是世界上应用最广泛的密码通信方法。 SSL: Secure Socket Layer. TLS: Transport Layer Security.  相当于SSL的后续版本。 由(下层)TLS记录协议(TLS record protocol)和(上层)TLS握手协议(TLS handshake protocol)这两层协议叠加而成。    TLS记录协议 TLS记录协议负责：消息的压缩、加密、数据的认证。\nTLS握手协议  TLS握手协议：加密之外的其他各种操作。  握手协议 密码规格变更协议 警告协议 应用数据协议    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC14%E7%AB%A0-ssl-tls/image_hu413041019d95a132c5e6526329e5bb43_166854_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC14%E7%AB%A0-ssl-tls/","title":"图解密码技术 —— 第14章-SSL-TLS"},{"content":"第一章 环游密码世界 名词 明文：加密前的消息。 密文：加密后的消息。 加密：把明文转换为密文的操作。 解密：把密文还原为明文的操作。 破译：接收者以外的人试图将密文还原为明文。 秘钥：加密解密的钥匙。 对称密码：加密、解密使用同一秘钥。 非对称密码：加密、解密使用不同秘钥。（也称为公钥密码） 混合密码系统：结合对称密码和公钥密码的加密方式。 单向散列函数(one-way hash function)：用于保证数据的完整性(integrity)。防篡改。 消息认证码(message authentication code)：用于确认消息是否来自期望的对象。防篡改、防伪装(认证)。 数字签名(digital signature): 防篡改、防伪装、防止否认。 伪随机数生成器(Pseudo Random Number Generator, PRNG): 一种模拟产生随机数的算法。\n密码常识  不要使用保密的密码算法 使用低强度的密码比不进行任何加密更危险 任何密码总有一天都会被破解 密码只是信息安全的一部分  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%8E%AF%E6%B8%B8%E5%AF%86%E7%A0%81%E4%B8%96%E7%95%8C/image_hubd17b0d0eb5805f5f9f0eeb2ca84f8e7_240962_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%8E%AF%E6%B8%B8%E5%AF%86%E7%A0%81%E4%B8%96%E7%95%8C/","title":"图解密码技术 —— 第一章-环游密码世界"},{"content":"第七章 单向散列函数 单向散列函数(one-way hash function): 可以根据消息的内容，计算出散列值。\n 散列值可以被用于检查消息的完整性。 输入：消息(message)；输出：散列值(hash value)。  性质 抗碰撞性：collision resistance，难以发生碰撞。 单向性：one-way，无法通过散列值反算出消息的性质。\n术语  单向散列函数：消息摘要函数、哈希函数、杂凑函数。 消息：原像。 散列值：消息摘要、指纹。 完整性：一致性。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E5%8D%95%E5%90%91%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B0/image_hu818ee36d4363169fc9a3aaeaa8549fc5_273897_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B8%83%E7%AB%A0-%E5%8D%95%E5%90%91%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B0/","title":"图解密码技术 —— 第七章-单向散列函数"},{"content":"对称密码 用相同的秘钥进行加密和解密。\n比特序列  编码：将现实中的东西映射为比特序列。  ASCII UTF-8    XOR——异或 XOR: exclusive or, 异或。\n 异或类似于加密解密过程：  消息A异或秘钥B = X X 异或 B = A    一次性密码本 原理：将明文与一串随机的比特序列进行XOR运算。 无法破解的原因：密文 XOR 破解秘钥得到的有意义明文，可能有多个，无法确定具体是哪个明文。\nDES DES: Data Encryption Standard。\n 美国联邦信息处理标准中采用的一种对称密码。 一种将64bit明文加密成64bit密文的对称密码算法。 秘钥长度是56bit。（实际64bit，但由于每隔7bit设置一个错误检查bit，因此是56bit） 如果明文长于64bit，则需要迭代加密。  差分分析 思路：改变一部分明文并分析密文如何随之改变。\n线性分析 思路：将明文和密文的一些对应比特进行XOR并计算其结果为0的概率。\n三重DES 3DES(TDEA)：将DES重复3次。 分组长度为：64 * 3 = 192\nAES 分组长度为：128\n","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81/image_hu3beecb1316a348fa5f605548c01c17ba_220606_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81/","title":"图解密码技术 —— 第三章-对称密码"},{"content":"数字签名 公钥密码：存在加密秘钥(公钥)和解密秘钥（私钥）。用公钥加密。 数字签名：签名秘钥（私钥）和验证秘钥（公钥）。用私钥加密。 数字签名并不是为了保证机密性。\n签名的生成和验证 签名秘钥：私钥。用于对消息进行签名——生成签名。只能一人持有。 验证秘钥：公钥。用于验证消息的签名——验证签名。可以多人持有。\n对消息签名的过程  A用自己的私钥进行加密。 A将签名和消息发送给B。 B用A的公钥进行解密（签名验证）。 B将解密后的消息与A发过来的消息进行对比。一致，则验证成功，否则，验证失败。  对消息散列值签名的过程  公钥密码算法较慢，如果直接对消息进行签名，会比较耗时。\n  A用单向散列函数计算消息的散列值。 A用私钥对散列值进行加密。 A将消息和签名发送给B。 B用A的g公钥对收到的签名进行解密。 B将签名解密后得到的散列值与A发送的消息的散列值进行对比。一致，验证成功，否则，验证失败。  应用场景  信息公告  确保是目标组织发布的目标公告，法制被篡改。   软件下载  软件下载完成后，验证签名，防止软件遭到篡改。（并不能检测软件是否是恶意的）   公钥证书。  验证数字签名时，需要合法的公钥。对公钥进行签名得到的就是公钥证书。【第三方？？？】   SSL/TLS。  使用服务器证书验证服务器身份。 服务器证书：加上数字签名的服务器公钥。    总结 对称密码的秘钥是机密性的精华，单向散列函数的散列值是完整性的精华。\n","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/image_hu259a9b0847f5189e86c9f8b99fcb671e_257372_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/","title":"图解密码技术 —— 第九章-数字签名"},{"content":"第二章 历史上的密码 历史上著名的密码  凯撒密码 简单替换密码 Enigma  破译方法  暴力攻击 频率分析  凯撒密码 通过将明文中使用的字母表\u0026quot;平移\u0026quot;来进行加密。 秘钥空间：26 破解方式：直接暴力破解。\n简单替换密码  更改26个字母的对应关系。如A表示X（A不再是A）。 秘钥空间：26 x 25 x 24 x \u0026hellip; x 1 = 403291461126605635584000000 破解方式：频率分析  Enigma 略\n","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%8E%86%E5%8F%B2%E4%B8%8A%E7%9A%84%E5%AF%86%E7%A0%81/image_hu6dd6ce6c6dc89dbbcc548f1b0a61c1d9_261937_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%8E%86%E5%8F%B2%E4%B8%8A%E7%9A%84%E5%AF%86%E7%A0%81/","title":"图解密码技术 —— 第二章-历史上的密码"},{"content":"第五章 公钥密码 秘钥配送问题  解决方法  事先共享秘钥 密钥分配中心 Diffie-Hellman密钥交换 公钥密码    RSA RSA是一种公钥密码算法。名字来源于三位作者的姓。\n Ron Rivest、Adi Shamir、Leonard Adleman  RSA加密 密文 = 明文 ^ E mode N  在RSA中，明文、密钥、密文都是数字。 密文等于明文的E次方对N取模） E = Encryption N = Number E和N的组合就是公钥。  RSA解密 明文 = 密文 ^ D mod N  D = Decryption N = Number D和N的组合就是私钥。  求N N = p x q  p和q是质数，由伪随机数生成器生成。  求L L = lcm(p - 1, q - 1)  lcm：取最小公倍数  求E 1 \u0026lt; E \u0026lt; L gcd(E, L) = 1  gcd: 最大公约数 E和L最大公约数是1（互质）  求D 1 \u0026lt; D \u0026lt; L E x D mode L = 1 中间人攻击  攻击方式：  A和B用公钥密码通讯。 中间人X对A冒充B，对B冒充A。   中间人攻击对所有公钥密码对是有效的。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%85%AC%E9%92%A5%E5%AF%86%E7%A0%81/image_hud37660a567da8df0403875e6c802b8b7_242254_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%85%AC%E9%92%A5%E5%AF%86%E7%A0%81/","title":"图解密码技术 —— 第五章-公钥密码"},{"content":"消息认证码-消息被正确传送了吗 消息认证码： Message Authentication Code，MAC。\n 是一种确认完整性并进行认证的技术。 是一种与秘钥相关联的单向散列函数。 输入：任意长度的消息 + 共享秘钥。 输出：固定长度的数据。 消息认证码使用的秘钥必须是密码学安全的、高强度的伪随机生成器。如果是人为选定，则会增加秘钥被推测的风险  消息验证码能与不能  不能保证消息的机密性； 不能防止否认； 能识别出篡改行为； 能对消息进行认证；（合法）  消息验证码的局限性  无法防止否认；  无法防止否认的本质是：相同的秘钥有多于1个人获得。    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%B6%88%E6%81%AF%E8%AE%A4%E8%AF%81%E7%A0%81/image_huf847cb5c306e77516f0a4bc72ff03aec_308630_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%B6%88%E6%81%AF%E8%AE%A4%E8%AF%81%E7%A0%81/","title":"图解密码技术 —— 第八章-消息认证码"},{"content":"第六章 混合密码系统 用对称密码提高速度，用公钥密码保护会话密钥。\n 对称密码：用于加密消息/数据。 公钥密码：用于加密密钥/会话密钥。 对称密码和公钥密码的密钥长度必须具备同等强度。  考虑长期运用时，公钥密码的强度应该要高于对称密码。 因为对称密码的会话密钥被破解，只会影响到本次通信，而公钥被破译，会影响过去到未来所有通信内容。    密钥强度对比：\n   对称密码AES 公钥密码RSA     128 3072   192 7680   256 15360    问题  对称密码：  密钥传送问题   公钥密码：  中间人攻击 速度慢    混合密码加密过程  混合密码加密过程 \n混合密码解密过程  混合密码解密过程 \n","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%B7%B7%E5%90%88%E5%AF%86%E7%A0%81%E7%B3%BB%E7%BB%9F/%E5%8A%A0%E5%AF%86_huaffa7cd0d92005921c7eed2441c40670_130886_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%B7%B7%E5%90%88%E5%AF%86%E7%A0%81%E7%B3%BB%E7%BB%9F/","title":"图解密码技术 —— 第六章-混合密码系统"},{"content":"第11章 秘钥——秘密的精华 什么是秘钥？ 秘钥：一个巨大的数字。\n 数字本身的大小不重要，重要的是秘钥空间的大小。 秘钥与明文是等价的。\n 常见的秘钥？  DES秘钥：实质长度56bit(7bytes)。 DES-EDE2秘钥：实质长度112bit(14bytes)。 DES-EDE3秘钥：实质长度168bit(21bytes)。 AES秘钥：128/192/256bit  如何管理秘钥？  需要清楚：信息的机密性不应该依赖于密码算法本身，而是应该依赖于妥善保管的秘钥。\n  生成秘钥：  用随机数生成秘钥；  密码学用途的伪随机数生成器必须是专门针对密码学用途而设计的。   用口令生成秘钥；   配送秘钥：  事先共享秘钥;   更新秘钥：  定期更新，例如每发送1000字节数据更新一次。 更新方式：将当前秘钥的散列值作为下一个秘钥。     这种防止破译过去的通信内容的机制，称为向后安全。\n   保存秘钥\n 对秘钥进行加密：有助于减少需要保管的秘钥数量。    作废秘钥\n 为什么要作废秘钥？  不再需要的秘钥及时作废，防止被解密。   如何作废秘钥？  彻底删除秘钥。      秘钥的分类？  对称、非对称。 用于认证、用于机密性。  Diffie-Hellman秘钥交换  实际并没有交换秘钥，而是通过计算生成相同的秘钥，因此也称为Diffie-Hellman秘钥协商。  什么是基于口令的密码(password based Encryption, PBE)？  根据口令生成秘钥，再用秘钥进行加密的方法。 KEK：通过口令生成的秘钥。 CEK：通过随机数生成器生成的秘钥。  什么是盐？盐的作用是什么？  盐：伪随机数生成器生成的随机数，和口令一起通过单向散列函数生成秘钥(KEK)。 作用：用来防御字典攻击。  字典攻击：准备大量候选KEK，逐一进行尝试。    什么是拉伸？  拉伸：讲单向散列函数进行多次迭代的方法。 通过拉伸可以改良PBE。  如何生成安全的口令？  使用只有自己才能知道的信息。（大原则）  不要使用对自己重要的事物的名字。 不要使用关于自己的信息。 不要使用别人见过的信息。   将多个不同的口令分开使用。 有效利用笔记。 理解口令的局限性。  当对口令字符/长度进行限制时，秘钥的长度(bit)并不太长，可能可以通过暴力破解。   使用口令生成器和管理工具。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E7%A7%98%E9%92%A5/image_hu488b2f82ab20ee50f487200f2be764c2_242367_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E7%A7%98%E9%92%A5/","title":"图解密码技术 —— 第十一章-秘钥"},{"content":"PGP——密码技术的完美组合 什么是PGP？  PGP: Pretty Good Privacy. 是Philip Zimmermann编写的密码软件。  PGP有什么用？  可以保护处于极端状况(如:性命攸关)下的人们的隐私。  什么是OpenGPG？  OpenGPG：对秘闻和数字签名进行定义的标准规范：RFC1991/RFC2440/RFC4880/RFC5581/RFC6637。 GUN遵照OpenGPG(RFC4880)规范编写了GnuPG自由软件。  什么是信任网？  PGP采用的确认公钥合法性的方法。 注意：公钥是否合法和所有者是否可信是两个不同的问题，因为尽管公钥合法，其所有者也可以是不可信的。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-pgp/image_hu3d31a301b4a4c10b2474d5b0f818cf15_279379_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-pgp/","title":"图解密码技术 —— 第十三章-PGP"},{"content":"第12章 随机数——不可预测性的源泉 随机数的作用？使用场景是什么？  生成秘钥：用于对称密码和消息认证码。 生成秘钥对：用于公钥密码和数字签名。 生成初始化向量(IV)：用于分组密码的CBC/CFB/OFB模式。 生成nonce：用于防御重放共计以及分组密码的CTR模式等。 生成盐：用于基于口令的密码等。  随机数的性质  随机性——不存在统计学偏差，是完全杂乱的数列。 不可预测性——不能从过去的数列推测下一个出现的数。 不可重现性——除非将数列本身保存下来，否则不能重现相同的数列。 以上3个性质，越往下越严格。  随机数强度  弱伪随机数：只有随机性。 强伪随机数：具有随机性+不可预测性。 真随机数：同时具备上面三个性质。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E6%95%B0/image_hu9c649052cb6030efdb52e5be8a8c5477_319393_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E6%95%B0/","title":"图解密码技术 —— 第十二章-随机数"},{"content":"证书——为公钥加上数字签名  这章不是太理解。\n 什么是证书？ 证书：记录个人信息及公钥，并由认证机构施加数字签名. 证书是公钥证书的简称。\n证书的应用场景？ 什么是公钥基础设施？ 公钥基础设施(PKI, Public-key Infrastructure): 为了能更有效运用公钥而制定的一系列规范和规格的总称。\n公钥基础设置（PKI）的组成要素是什么？  用户：使用PKI的人。 认证机构：颁发证书的人。 仓库：保存证书的数据库。  为什么需要证书？ ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E7%AB%A0-%E8%AF%81%E4%B9%A6/image_hu85aaf5f0d41b0975ba4c41b921fc00cc_279865_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%8D%81%E7%AB%A0-%E8%AF%81%E4%B9%A6/","title":"图解密码技术 —— 第十章-证书"},{"content":"第四章 分组密码的模式 DES和AES都属于分组密码，它们只能加密固定长度的明文。 如果需要加密任意长度的明文，则需进行迭代，而分组密码的迭代方法，就称为分组密码的模式。\n分组密码与流密码 密码算法可以分为分组密码和流密码。 流密码：一次性密码本 分组密码：DES、AES、3DES等大多数堆成密码算法。\n模式分类  ECB：Electronic CodeBook mode，电子密码本模式。 CBC：Cipher Block Chaining mode，密码分组链接模式。 CFB：Cipher FeedBack mode，密文反馈模式。 OFB：Output FeedBack mode，输出反馈模式。 CTR：CounTeR mode，计数器模式。 GCM：Galois/Counter Mode, 。  初始化向量 由于加密第一个分组时，不存在“前一个密文分组”，因此事先准备一个长度为一个分组的bit序列来代替。此序列称为初始化向量(Initialization Vector, IV)\n 初始化向量必须使用不可预测的随机数。  ECB模式 电子密码本模式：切割明文为多个分组，逐个加密。（容易有安全漏洞，不要使用）\n 加解密过程图示  加解密过程图示   CBC模式 密码分组链接模式：密文分组像链条一样互相连接在一起。（前一个密文分组用于后一个分组的加密）\n 特点  无法直接对中间分组进行加密。 一个密文分组损坏，解密时最多只有两个明文分组受影响。（在密文长度没变的情况下）   加解密过程图示  加解密过程图示   CFB模式 密文反馈模式：前一个密文分组被送到密码算法的输入端，用于生成下一个密文分组。\n 特点  依赖上一个密文分组。   加解密过程图示  加解密过程图示   OFB模式 输出反馈模式：加密算法的输出作为下一个分组加密算法的输入。\n 特点  不依赖上一个密文分组。生成秘钥流的操作和进行XOR运算的操作可以并行。   加解密过程图示  加解密过程图示1   加解密过程图示2   CTR模式 计数器模式：通过将逐次累加的计数器进行加密来生成密钥流的流密码。\n 加解密过程图示  加解密过程图示   计数器的生成方法 以128bit长度分组为例：\n 前8个字节为nonce，每次加密时必须都不同。 后8字节为分组序号，逐次累加。  GCM模式  第八章  模式对比  模式对比 \n","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E7%9A%84%E6%A8%A1%E5%BC%8F/OFB%E6%A8%A1%E5%BC%8F1_hu508cf6a6abac82f5e009a0c8d3ab1ab6_74921_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E5%9B%BE%E8%A7%A3%E5%AF%86%E7%A0%81%E6%8A%80%E6%9C%AF-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E7%9A%84%E6%A8%A1%E5%BC%8F/","title":"图解密码技术 —— 第四章-分组密码的模式"},{"content":"漏洞扫描 本文主要介绍如何使用 nessus 进行主机扫描以及使用 snyk 进行 Docker 镜像扫描。\n1. 主机扫描 1.1 安装 nessus 注意：需要空间 20 GB。\n  打开 nessus 官网\n  注册：  \n  进入 nessus 下载页 下载：  \n  安装\nrpm -i Nessus-8.15.1-es7.x86_64.rpm   启动\n/bin/systemctl start nessusd.service   进入管理界面: https://10.0.0.199:8834/\n  设置账号密码\n  初始化及编译插件  \n  1.2 使用 nessus   添加 scan    \n  执行 scan 并查看结果    \n  2. 容器扫描 2.1 安装 snyk 如果你的容器在 docker hub 等 registries 中，可以不用在本地安装 snyk。\nwget https://static.snyk.io/cli/latest/snyk-linux mv ./snyk-linux /usr/local/bin/snyk chmod +x /usr/local/bin/snyk 2.2 使用 snyk 无论使用云端还是本地版本，都需要注册 snyk 账号。 请在 snyk 官网注册。\n2.2.1 使用云端 snyk   添加项目：点击 Add Project  \n  选择 registries  \n  选择镜像  \n  查看结果    \n  可以看到具体的漏洞情况以及解决方法。\n2.2.1 使用本地 snyk   登录：snyk auth \u0026lt;Token\u0026gt;\n Token 在页面端生成    扫描：snyk container test \u0026lt;Image name\u0026gt;\n  结果：  \n  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E5%AE%89%E5%85%A8-%E4%BD%BF%E7%94%A8-snyk-%E5%8F%8A-nessus-%E8%BF%9B%E8%A1%8C%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/images/snyk-result-2_hu0d136ca52f2a1e49a588ff1642afd4cf_334601_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E5%AE%89%E5%85%A8-%E4%BD%BF%E7%94%A8-snyk-%E5%8F%8A-nessus-%E8%BF%9B%E8%A1%8C%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/","title":"安全 —— 使用 Snyk 及 Nessus 进行漏洞扫描"},{"content":"epoll I/O事件通知设施(I/O event notification facility)。\n1. epoll_create #include \u0026lt;sys/epoll.h\u0026gt; int epoll_create(int size); int epoll_create1(int flags);  作用：打开一个epoll文件描述符。 参数：  size： Linux 2.6.8后不再使用，但是必须大于0。 flags：  0：和epoll_create行为一样。 O_CLOEXEC: 进程退出时关闭文件描述符。     返回：  失败：-1，设置errno；否则： 返回一个指向一个新epoll实例的文件描述符；当不再使用此描述符时，应使用close关闭。 当所有指向此epoll实例的描述符都被关闭时，内核会释放相关资源。    2. epoll_ctl typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);  作用：epoll文件描述符的控制接口。 参数：  epfd: epoll fd，epoll文件描述符； op:  EPOLL_CTL_ADD：注册fd到epfd； EPOLL_CTL_MOD：修改与fd的关联evnet事件。 EPOLL_CTL_DEL：从epfd中删除fd；   fd: 要操作(op)的fd； event: 与fd关联的事件。EPOLL_CTL_DEL时这个参数被忽略，也可以直接为NULL；   返回：  正常：0； 异常：-1，设置errno；   数据结构说明；  struct epoll_event的events的是位掩码的形式，取值是：  EPOLLIN: 相关文件可读。(read) EPOLLOUT: 相关文件可写。(write) EPOLLRDHUP: 流套接字对端关闭连接，或关闭写入一半的连接。(在使用边沿触发时，此标志对于编写简单代码以检测对端关闭特别有用。) EPOLLPRI: 有紧急数据可读。 EPOLLERR: 相关文件描述符发生错误。（默认设置，不用手动设置） EPOLLHUP: 相关文件描述符被挂起。（默认设置，不用手动设置） EPOLLET: 相关文件描述符设置为边缘触发。（默认是水平触发） EPOLLONESHOT: 对相关描述符设置一次性行为。 epoll_wait一次后，不会再wait，除非使用EPOLL_CTL_MOD重新设置。 EPOLLWAKEUP: 设置此标记，使事件排队时系统保持唤醒。  当系统设置了自动休眠模式(/sys/power/autosleep)时，为了保持设备唤醒直到事件处理完成，必须使用此标记。   EPOLLEXCLUSIVE：为附加到目标文件描述符fd的epoll文件描述符设置独占唤醒模式。【？？？】      3. epoll_wait int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); int epoll_pwait(int epfd, struct epoll_event *events, int maxevents, int timeout, const sigset_t *sigmask);  作用：等待epoll文件描述符上的I/O事件。 参数：  epfd：epoll文件描述符； events：等待的目标事件； maxevents：返回的最大事件数量； timeout：epoll_wait阻塞超时，单位微秒。发生以下事件解除阻塞：  监听的文件描述符有事件发出/传递； 被信号处理函数中断； 超时；   sigmask：屏蔽信号集？！【疑问】   返回：  正常：就绪的文件描述符数量 异常：-1，并设置errno    4. 触发形式   水平触发：（默认是水平触发）\n 触发条件：只要有数据可读/可写，即可触发。    边缘触发：（使用EPOLLET设置为边缘触发）\n 触发条件：有新数据可读/可写，即可触发。    两种触发的不同在于：一次新数据，水平触发可能触发多次，边缘触发只会触发一次。\n  epoll的优点 select/poll的两个主要性能问题，就是epoll的优点：\n select/poll需要轮询查找就绪的描述符，epoll直接返回就绪的信息。 描述符集合需要从用户空间拷贝到内核空间。  epoll的add/remove也是需要拷贝； 对于就绪描述符，使用mmap进行内存共享，避免拷贝；    A. 问题/拓展  可读：缓冲区非空，并且数据量超过读阈值。 可写：缓冲区未满。 什么时候使用poll/select, 什么时候使用epoll?  满足以下几个条件，用epoll，否则用poll：  使用的是Linux系统，并且有epoll系统调用； 需要处理得是大的活动描述符集（至少1000）； 描述符集是相对稳定的。（因为epoll添加/删除描述符花销和poll一样很大，需要进入/离开内核空间）；      ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-epoll/image_hu3d31a301b4a4c10b2474d5b0f818cf15_279379_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-epoll/","title":"操作系统 —— IO 多路复用之 epoll"},{"content":"poll 相关函数 #include \u0026lt;poll.h\u0026gt; struct pollfd { int fd; /* file descriptor */ short events; /* events to look for */ short revents; /* events returned */ }; int poll(struct pollfd fds[], nfds_t nfds, int timeout);  作用：类似于select。（指示内核等待多个事件，并在有一个或多个时间或经历指定时间后唤醒进程。） 参数：  fds[]: 指向一个结构数组第一个元素的指针。 nfds: 指定fds中的元素个数。 timeout:  INFTIM： 永远等待；(INFTIM被定义为一个负值) 0：立即返回； \u0026gt; 0: 等待指定数据的毫秒数。     返回：  成功：就绪描述符数目 超时：0 出错：-1   数据结构说明：  events: 要测试的条件； revents: 返回描述符的状态。   events/revents标记：    常值 说明 能作为evnets的输入吗？ 能作为revents的输入吗？     POLLIN 普通或优先级带数据可读 + +   POLLRDNORM 普通数据可读 + +   POLLRDBAND 优先级带数据可读 + +   POLLPRI 高优先级数据可读 + +   POLLOUT 普通数据可写 + +   POLLWRNORM 普通数据可写 + +   POLLWRBAND 优先级带数据可写 + +   POLLERR 发生错误  +   POLLHUP 发生挂起  +   POLLNVAL 描述符不是一个打开的文件  +      数据分类 poll识别三类数据：普通(normal)、优先级带(priority band)、高优先级(high priority)\n 普通数据：  所有正规TCP、UDP数据； TCP连接读半部关闭时；（FIN） TCP连接存在错误；（RST、超时） 监听套接字上游新的连接可用；（多数实现为普通，也有实现为优先级带数据）   优先级带：  TCP的带外数据；   高优先级：  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-poll/image_hu9a6e15c100f49a1259729f1a9f46ad7a_252829_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-poll/","title":"操作系统 —— IO 多路复用之 poll"},{"content":"select select函数允许进程指示内核等待多个事件，并在有一个或多个时间或经历指定时间后唤醒进程。\n1. select #include \u0026lt;sys/select.h\u0026gt; int select(int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout);  作用：指示内核等待多个事件，并在有一个或多个时间或经历指定时间后唤醒进程。 参数：  nfds: 待测试的最大描述符+1； readfds: 监听读的fd集合； writefds: 监听写得fd集合； errorfds: 监听异常的fd集合； timeout: 等待超时时间。  NULL: 永远等下去； 非NULL且不为值0: 等待指定时间； 非NULL且值为0: 不等待，检查描述符后立即返回。（轮询）     返回： 返回：  成功：就绪描述符数目 超时：0 出错：-1    2. 描述符就绪条件  读就绪：  该套接字接收缓冲区的数据字节数\u0026gt;=套接字缓冲区低水位标记的当前大小。  高于水位，认为可读。   该套接字的读半部关闭(接收了FIN的TCP连接)。  返回EOF   该套接字是一个监听套接字且已完成的连接数不为0。  此时accept通常不阻塞。   其上有一个套接字错误待处理。  读操作不阻塞、返回-1，并设置errno。 待处理错误，可通过getsockoptvidkSO_ERROR套接字获取并清除。     写就绪：  发送缓冲区的数据字节数\u0026gt;=套接字缓冲区低水位标记的当前大小。 该连接的写半部关闭。  此时写，会产生SIGPIPE信号。   使用非阻塞connect的套接字已建立连接，或者connect已经以失败告终。 其上有一个套接字错误待处理。   异常就绪：（？！）  套接字存在带外数据或者仍处于带外标记。  注意：当某个套接字上发生错误时，它将由select标记为可读又可写。     汇总：    条件 可读吗？ 可写吗？ 异常吗？     有数据可读 +     关闭连接的读一半 +     给监听套接字准备好新连接 +     有可用于写得空间  +    关闭连接的写一半  +    待处理错误 + +    TCP带外数据   +      3. shutdown 终止网络连接的通常方法是close函数，但是close有两个限制：（可以用shutdown来避免）。\n close把描述符的引用计数-1，仅在计数为0时才关闭套接字。 close终止读和写两个方向的数据传送。  #include \u0026lt;sys/socket.h\u0026gt; int shutdown(int sockfd, int howto);   作用：关闭网络连接。\n  参数：\n howto:  SHUT_RD: 关闭连接的读一半。 SHUT_WR: 关闭连接的写一半。 SHUT_RDWR: 读写都关闭。（与调用两次shutdown等效。）      返回：\n 成功：0 失败：Exxx值    A. 注意、拓展  timeval结构允许指定微秒级的分辨率，然而内核支持的真实分辨率往往粗糙得多。 timeval结构能支持select不支持的值。 如果select的三个fds都设置为NULL，则可以得到一个比sleep函数更为精确的定时器。 使用select的最常见错误：  忘记对最大描述符+1； 忘记描述符集是值——结果参数。   接收低水位标记和发送低水位标记的作用是什么？  目的在于：允许应用进程控制在select返回可读/可写条件之前，有多少数据可读或有多大空间可用于写。 例如：如果我们知道除非至少存在64字节数据，否则我们的应用程序无事可做，那么可以将接受低水位标记设置为64。防止过早唤醒。   任何UDP套接字只要其发送低水位标记``\u0026lt;=发送缓冲区大小，就总是可写的。（因为UDP不需要连接）  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-select/image_hu2eb95bf5c5ba7e990e649bbb75c2aacc_298769_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-io-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B9%8B-select/","title":"操作系统 —— IO 多路复用之 select"},{"content":"信号  一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。 每种信号类型都对应于某种系统事件。 信号的默认行为：  1.信号发送和信号接收  待处理信号：一个发出而没有被接收的信号。 内核通过更新目的进程上下文的某个状态，发送一个信号给目的进程。 当目的进程被内核强迫以某种方式对信号的发送做出反应时，目的进程就接收了信号。 Unix系统提供了大量向进程发送信号的机制，所有这些机制都是基于进程组(process group)的。 相关函数:  #include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;signal.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; // 发送sig指定信号到pid进程 int kill(pid_t pid, int sig); // 向自己发送SIGALRM信号 unsigned int alarm(unsigned int secs); typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); 2.信号处理问题   待处理信号被阻塞。\n 例如：一个进程捕获一个信号SIGINT然后去处理程序处理信号，此时又来一个SIGINT信号，此信号会被阻塞。[疑问][1] （第2个信号不是SIGINT信号，那是否也还是阻塞？）    待处理信号不会排队等待。\n 任意类型至多只有一个待处理信号。[疑问][2] （不同类型的信号就可以有多个吗？）    系统调用可以被中断。\n 如read、wait、accept这样的慢速系统调用被信号打断，但是信号处理函数返回后不再继续被打断的系统调用，而是立即返回错误，errno为EINTR。    详见ex_SIGCHLD.c\n  教训：不可以用信号来对其他进程中发生的时间计数\n  3. 显式地阻塞和取消阻塞信号 这2个操作在某些情况下也是什么有用的，且必须的，能消除一些竞争条件。（详见ex3和ex4）\n 相关函数  #include \u0026lt;signal.h\u0026gt;// 设置阻塞、不阻塞、添加到阻塞 int sigprocmask(int how, const sigset_t *restrict set, sigset_t *restrict oset); // 添加signo到set中 int sigaddset(sigset_t *set, int signo); // 吧signo从set中删除 int sigdelset(sigset_t *set, int signo); // 初始化set为空集 int sigemptyset(sigset_t *set); // 将每个(所有？)信号添加到set中 int sigfillset(sigset_t *set); // 判断signo是否是set的成员，是返回1，否则0 int sigismember(const sigset_t *set, int signo); A.拓展  进程组。详见1.进程 Linux信号  Linux信号  回收子进程的方式：用SIGCHLD信号。子进程终止时，会发送SIGCHLD信号给其父进程。【详见ex_SIGCHILD.c】 可移植的signal函数。【详见isshe_signal.h和isshe_signal.c】 非本地跳转：可和信号一起实现程序重启功能。【详见ex_restart，macOS上行为和书本有所不同】  相关函数  #include \u0026lt;setjmp.h\u0026gt;int setjmp(jmp_buf env); void logjmp(jmp_buf env, int retval); // 下面两个可以和信号一起用 int sigsetjmp(sigjmp_buf env, int savesige); void siglongjmp(sigjmp_buf env, int retval);   B.疑问  2.信号处理问题中： [1]第2个信号不是SIGINT信号，那是否也还是阻塞？ [2]不同类型的信号就可以有多个吗？  C.参考  《深入理解计算机系统》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E4%BF%A1%E5%8F%B7/Linux_signal_huec7bd37c00e9f0f66a7da81ead81d61e_182649_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E4%BF%A1%E5%8F%B7/","title":"操作系统 —— 信号"},{"content":"线程  当一个程序由exec启动执行时，系统将创建一个称为初始线程(initail thread)或主线程(main thread)的单个线程。 线程取消在8.5章，被取消的线程要释放相关资源（锁等），需要注意。 线程创建可能比进程创建快10~100倍； 线程或者是可汇合的(joinable)或者是脱离/分离的(detached)。（默认可汇合的）  可汇合的线程可以被其他线程回收其资源和杀死。  当可汇合的线程终止时，其线程ID和退出状态将保留，直到另一个线程调用pthread_join;   脱离的线程则像守护进程：终止时，所有资源都释放，因此不能等待它终止；   线程是运行在进程上下文中的逻辑流。  1. 共享及私有 线程共享的内容：\n 进程指令； 大多数数据； 打开的文件（如描述符）； 信号处理程序和信号处置； 当前工作目录； 用户ID和组ID； 线程私有的内容： 线程ID； 寄存器集合（包括程序计数器和栈指针）； 栈； 栈指针； 程序计数器； errno； 信号掩码； 优先级；  2. 相关函数 2.1 pthread_create #include \u0026lt;pthread.h\u0026gt; int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg);  作用：创建线程 参数：  tid：线程ID；这是结果参数； attr: 线程属性，如优先级、初始栈大小、是否是一个守护线程等；通常采用默认值； start_routine: 创建的线程所需要执行的函数；称为线程启动函数(thread start function); arg: 参数；如果有多个，则打包成一个结构即可；   返回：  成功：0 失败：Exxx值    2.2 pthread_join int pthread_join(pthread_t tid, void **status);  作用：等待一个线程结束/终止；（不是任意一个线程的终止都能等待） 参数：  tid：等待线程的线程id； status：等待线程的终止状态；   返回：  成功：0 失败：Exxx值    2.3 pthread_self pthread_t pthread_self(void);  作用：获取自身的线程ID； 参数：无 返回：调用线程的线程ID；  2.4 pthread_detach int pthread_detach(pthread_t tid);  作用：将指定线程变为脱离的。 参数：  tid：线程id；   返回：  成功：0 失败：Exxx值   通常用法：pthread_detach(pthread_self());  2.5 pthread_exit void pthread_exit(void *status);  作用：线程退出 参数：  status: 退出状态；不能指向局部于调用线程的对象，如该线程启动函数中的某个局部变量；   返回：  成功：0 失败：Exxx值   通常用法：pthread_detach(pthread_self());  2.6 pthread_cancel int pthread_cancel(pthread_t tid);  作用：退出指定线程 参数：  tid: 线程ID；   返回：  成功：0 失败：Exxx值    2.7 pthread_once #include \u0026lt;pthread.h\u0026gt; pthread_once_t once_control = PTHREAD_ONCE_INIT; int pthread_once(pthread_once_t *once_control, void (*init_routine)(void));  作用：初始化线程——初始化与线程例程相关的状态。  当需要动态初始化多个线程共享的全局变量时，pthread_once是很有用的；   参数：  once_control：全局或者静态变量，总是被初始化为PTHREAD_ONCE_INIT; init_routine：初始化例程。第一次用once_control调用pthread_once时，会调用init_routine;   返回：  成功：0 失败：Exxx值    3. 共享变量 一个变量是共享的，当且仅当多个线程引用这个变量的某个实例。（访问相同的东西） 解答以下问题，有助于理解C程序中一个变量是否是共享的：\n 线程的基础存储器模型是什么？  一组并发线程运行在一个进程的上下文中；每个线程有自己的线程上下文； 寄存器是不共享的；虚拟存储器是共享的；   根据这个模型，变量实例是如何映射到存储器的？ 有多少线程引用这些实例？  4. 线程的终止  线程的终止方式：  自身显式终止：pthread_exit; 他人显式终止：pthread_join; 隐式终止：函数返回； 某个线程调用exit函数；    5. 线程安全 线程安全：被多个并发线程反复调用，仍然能一直产生正确的结果。 4类线程不安全函数：\n 不保护共享变量的函数； 保持跨越多个调用的状态的函数；  当前结果依赖前面的结果。    unsigned int next = 1; // 返回0-32767的伪随机书 int rand(void) { next = next * 1103515245 + 12345; return (unsigned int)(next / 65536) % 32768; } // 为rand()设置种子 void srand(unsigned int seed) { next = seed; }  返回指向静态变量的指针的函数；  正在被一个线程使用的结果可能会被另一个线程悄悄覆盖。 解决方法：  1.重写；传递结果参数； 2.使用加锁-拷贝技术；     调用线程不安全函数的函数；  加锁可能可以转变为线程安全函数；    6. 可重入性  可重入性：被多个线程调用时，不会引用任何共享数据。（因此不需要同步操作）  可重入函数是线程安全函数的一个真子集。   显式可重入：函数都是值传递，所有数据引用都是本地的自动栈变量。（没有引用静态或全局变量） 隐式可重入：显式重入基础上，允许引用传递的参数（即传递指针）。  // 隐式可重入示例 int rand_r(unsigned int *nextp) { *nextp = *nextp * 1103515245 + 12345; return (unsigned int)(*nextp / 65536) % 32768; } 7. 竞争  现成话的程序必须对任何可行的轨迹线都正确工作。 示例1_3_ex  8. 死锁  信号量引入一种潜在的运行时错误：死锁(deadlock)。  一组线程被阻塞，等待一个永远不会为真的条件。   互斥锁加锁规则：用相同的顺序加锁。  A.拓展  预线程化：生成一个管理线程+多个工作线程；  用一个有限缓冲区存储数据，这些数据被工作线程处理。      ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%BA%BF%E7%A8%8B/prethreading_hu6d86b1b4a5aabba4c58c9dd2ddcba887_57880_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%BA%BF%E7%A8%8B/","title":"操作系统 —— 线程"},{"content":"进程 进程是操作系统中最核心的概念。\n 定义：一个执行中的程序的实例。（对正在运行程序的一个抽象） 是资源分配的基本单位。 进程提供给应用程序的关键抽象：  一个独立的逻辑控制流，它提供一个假象，好像程序独占地使用处理器。 一个私有的地址空间，它提供一个假象，好像程序独占地使用存储器系统。   逻辑流(逻辑控制流）：程序计数器PC值的序列。  异常处理程序、进程、信号处理程序、线程和Java进程都是逻辑流的例子。   并发流(concurrent flow)：一个逻辑流的执行在时间上与另一个流重叠。 并发：多条流并发地执行的一般现象称为并发(concurrecy)。 多任务(multitasking)：一个进程和其他进程轮流运行的概念称为多任务。 时间片(time slice)：一个进程执行它的控制流的一部分的每一时间段。 并行流(parallel flow)：两个流运行在不同的处理器上或者不同的计算机上。 上下文(context)：内核重新启动一个被抢占的进程所需要的状态。 上下文切换：内核为每个进程维护一个上下文(context)，多任务的实现依赖上下文切换。  1）保存当前进程的上下文； 2）恢复某个先前被抢占的进程被保存的上下文； 3）将控制传递给这个新恢复的进程；    1.进程地址空间 1.1 典型进程地址空间1  典型进程地址空间1 \n 代码段起始地址：  32位：0x08048000 64位：0x00400000   进程从用户模式变为内核模式的方法是：中断、故障、陷入系统调用。  1.2 典型进程地址空间2  典型进程地址空间2 \n2. 进程状态 2.1 状态转换图   状态转换图   2.2 基本状态  1）运行态：进程实际占用CPU； 2）就绪态：可运行； 3）阻塞态：除非某种外部事件发生(使进程满足运行条件)，否则进程不能运行。  2.3 引入的状态：  创建状态； 终止状态； 挂起状态；（图中没有）  3. 进程控制 3.1 进程创建与终止  导致进程创建的主要事件：  1）系统初始化； 2）正在运行的程序执行了创建进程的系统调用； 3）用户请求创建一个新进程； 4）一个批处理作业的初始化；   导致进程终止的主要事件：  1）正常退出（自愿的）  A.从main返回； B.调用exit； C.调用_exit或_Exit; D.最后一个线程从其启动例程返回； E.从最后一个线程调用pthread_exit()；   2）出错退出（自愿的）  调用abort   3）严重错误/被其他进程杀死（非自愿）  接到终止信号； 最后一个线程对取消(cancellation)请求做出响应；     相关函数  #include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; // 进程创建 pid_t fork(void); // 进程退出 // 进行一些清理（关闭文件描述符之类的）,然后返回内核 void exit(int status); // 下面两个直接返回内核 void _Exit(int status); void _exit(int status);  fork失败的主要原因：  系统中已经有太多进程。 该实际用户ID的进程数超过了系统限制。    4. 守护进程  守护进程：  一种生存期长的进程。 后台运行； 没有控制终端；    4.1 编程规则  1）调用umask将文件模式创建屏蔽字设置为一个已知的值（通常是0）；【疑问？！】 2）调用fork，然后使父进程exit； 3）调用setsid创建一个新会话；  a）进程成为新会话的首进程； b）成为一个新进程组的组长进程； c）没有控制终端；   4）将当前工作目录更改为根目录； 5）关闭不再需要的文件描述符； 6）[选]打开/dev/null使进程具有文件描述符0/1/2。  使所有读标准输入，写标准输出/错误输出的库例程都不会产生效果。    4.2 示例  见守护进程示例  4.3 守护进程的惯例  锁文件放/var/run目录，命名为name.pid。 配置放/etc目录，命名为name.conf。 可用命令行启动。  通常由/etc/rc*或/etc/init.d/*启动。 守护进程终止时，应当自动重启。(/etc/inittab中为守护进程添加respawn记录项【macOS没有此文件！】)   守护进程可通过SIGHUP信号，重新读取配置（当配置更新时）。  5. 进程实现  进程表：操作系统维护的一张表格——一个结构数组。 进程表项：也称进程控制块，是进程表的表项。 典型系统中的一些关键字段：     进程管理 存储管理 文件管理     寄存器 正文段指针 根目录   程序计数器 数据段指针 工作目录   程序状态字 堆栈段指针 文件描述符   堆栈指针  用户ID   进程状态  组ID   优先级     调度参数     进程ID     父进程     进程组     信号     \u0026hellip;      A.拓展 A.1 进程组  进程组：在类UNIX系统中，进程和它的所有子进程以及后裔进程共同组成一个进程组。 进程组相关函数:  #include \u0026lt;unistd.h\u0026gt; // 获取进程组ID pid_t getpgrp(void); // 改变自己或其他进程的进程组 // pid == 0: 使用当前进程 // pgid== 0: pid进程的PID作为进程组ID。 int setpgid(pid_t pid, pid_t pgid);  僵死进程/僵尸进程：终止，但未被回收的进程。  进程已经终止了，但内核仍保留它的某些状态直到父进程回收它为止。   相关函数:  #include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;sys/wait.h\u0026gt; pid_t waitpid(pid_t pid, int *status, int options); pid_t wait(int *status); unsigned int sleep(unsigned int secs); int pause(void); A.2 子进程回收方式  回收子进程的方式：用SIGCHLD信号。子进程终止时，会发送SIGCHLD信号给其父进程。 【详见ex_SIGCHLD.c】  A.3 C程序的启动和终止  C程序的启动和终止 \n 内核使程序执行的唯一方法：exec!  A.4 进程资源限制  见《Unix环境高级编程》p175  A.5 7个exec的关系  7个exec的关系 \nA.6 ps命令中进程状态  R: TASK_RUNNING，可执行状态。 S: TASK_INTERRUPTIBLE，可中断的睡眠状态。 D: TASK_UNINTERRUPTIBLE，不可中断的睡眠状态。 T: TASK_STOPPED/TASK_TRACED，暂停状态或跟踪状态。 Z: TASK_DEAD – EXIT_ZOMBIE，退出状态，进程成为僵尸进程。 X: TASK_DEAD – EXIT_DEAD，退出状态，进程即将被销毁。  B.疑问/不懂  孤儿进程组? 文件模式创建屏蔽字是什么？有何作用？(umask()设置的那个))  C.参考  https://blog.csdn.net/i_scream_/article/details/51569355 《Unix环境高级编程》 《现代操作系统》 《深入理解计算机系统》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B/process_address_map_hu575c6395d5e84185e674e7125c58f205_133704_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B/","title":"操作系统 —— 进程"},{"content":"Posix信号量 信号量是一种提供不同进程间或一个进程的不同线程间同步手段的原语。 Posix提供两类信号量：\n 有名(named)信号量 基于内存(memory-base)的信号量。【macOS不支持】  Posix信号量的函数调用  Posix有名信号量至少具有岁内核的持续性。 Posix信号量是计数信号量。  1.相关函数 #include \u0026lt;fcntl.h\u0026gt; /* For O_* constants */#include \u0026lt;sys/stat.h\u0026gt; /* For mode constants */#include \u0026lt;semaphore.h\u0026gt; // 打开 sem_t *sem_open(const char *name, int oflag); sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value); // 关闭 int sem_close(sem_t *sem); // 删除 int sem_unlink(const char *name); // \u0026#34;加锁\u0026#34;——测试指定信号量的值，如果大于0，将它-1 int sem_wait(sem_t *sem); int sem_trywait(sem_t *sem); int sem_timedwait(sem_t *sem, const struct timespec *abs_timeout); // “解锁”——信号量+1 int sem_post(sem_t *sem); // 获取信号量的值(macOS不支持) int sem_getvalue(sem_t *sem, int *sval); // 基于内存的信号量(macOS不支持) int sem_init(sem_t *sem, int shared, unsigned int value); int sem_destroy(sem_t *sem); A.拓展  信号量、互斥锁、条件变量之间的差异：  互斥锁必须由给它上锁的线程解锁；信号量的挂出(解锁)却不必在同一线程执行。 互斥锁要么被锁住，要么被解开。（二值状态） 信号量有一个与之关联的状态（计数值），信号量的挂出操作总是被记住。【？】   macOS不支持基于内存的信号量。 使用FIFO实现Posix信号量  打开读fd和写fd； sem_wait()读出一个字节；没有字节可读，就阻塞； sem_post()写入一个字节； 这个实现应该不能用于进程间。（除非共享内存？）    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-posix-%E4%BF%A1%E5%8F%B7%E9%87%8F/posix_semabphore_functions_hu4c4a95ca1f84995e0b95f38afb7a4234_34003_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-posix-%E4%BF%A1%E5%8F%B7%E9%87%8F/","title":"操作系统 —— 进程间通信之 Posix 信号量"},{"content":"Posix共享内存区 Posix.1提供了两种无亲缘关系进程间共享内存区的方法：（都需要调用mmap）\n 内存映射文件(memory-mapped file)：由open函数打开，由mmap函数把得到的描述符映射到当前进程地址空间中的一个文件。 共享内存区对象(share-memory object)：由shm_open打开一个Posix.1 IPC名字，所返回的描述符由mmap函数映射到当前进程的地址空间。  1. 相关函数 #include \u0026lt;sys/mman.h\u0026gt;#include \u0026lt;fcntl.h\u0026gt;#include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;sys/stat.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; // 只是打开一个内存区对象，返回fd // oflag: 必须函数O_RDONLY、O_RDWR中的一个。 // mode: // * 指定权限为，在指定了O_CREAT的前提下使用。 // * 与mq_open和sem_open不同，shm_open的mode参数必须指定。 int shm_open(const char *name, int oflag, ...); // 删除一个共享内存区对象的名字。（删除一个名字不会影响低层支撑对象的现有引用。） int shm_unlink(const char *name); // 裁剪普通文件或者共享内存区对象 int ftruncate(int fd, off_t length); //获取打开的共享内存对象的信息 int fstat(int fildes, struct stat *buf); 2. 示例  共享计数器持续+1  示例6_1 示例6_2   向服务器发送消息        A.注意  在macOS 10.14.5中，shm_open并不会创建对应的同名文件。  详见示例1    B.问题  为什么shm_open不直接返回共享内存的地址？  因为Posix.1的共享内存发明之前，mmap已经存在。 mmap使用的是已打开的描述符。   是否支持亲缘进程间使用？先映射，再fork，是否还能使用？  支持。父进程中open/shm_open；fork后，分别mmap。 详见示例5_ex   是否支持无亲缘进程间使用？  支持。    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-posix-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/one_server_multi_client_hu884d2f2f6c651f24e84f37946b6832f5_75534_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-posix-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/","title":"操作系统 —— 进程间通信之 Posix 共享内存"},{"content":"Posix 信息队列  消息队列可认为是一个消息链表。具有随内核的持续性 有读权限的线程可以从队列中取走信息； 有写权限的线程可以从队列中放置信息； 允许异步事件通知。  1. 相关函数 #include \u0026lt;mqueue.h\u0026gt;// 打开消息队列 mqd_t mq_open(const char *name, int oflag, ... /* mode_t mode, struct mq_attr *attr */); // 关闭消息队列，调用进程不用，但不会被删除消息队列 int mq_close(mqd_t mqdes); // 从系统中删除消息队列 // mq_unlink(const char *name);  // int mq_notify(mqd_t mqdes, const struct sigevent *notification); A. Posix消息队列和SystemV消息队列的区别  Posix消息队列的读总是返回最高优先级的最早消息；System V消息队列的读可以返回任意指定优先级的消息。 往空队列放置一个消息时，Posix消息队列允许产生一个信号或者启动一个线程。System V没有类似的机制。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-posix-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image_hu43fd9dd67e88f65321bb52f25c31188e_174771_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-posix-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","title":"操作系统 —— 进程间通信之 Posix 消息队列"},{"content":"System V 信号量 1. 概述  二值信号量(binary semaphore): 其值为0或1的信号量； 计数信号量(counting semaphore): 其值为0~某个限制值之间的信号量；    以上两种信号量，等待(waiting)操作都等待信号量的值变为大于0；    计数信号量集(set of counting semaphores): 一个或多个信号量(构成一个集合), 其中的每个都是计数信号量。  System V信号量通过此概念给信号量增加了一级复杂度。     当讨论System V信号量时，都是指计数信号量集；当讨论Posix信号量时，都是指计数信号量。\n  约定：  semval: 信号量当前值 semncnt: 等待semval变为大于其当前值的线程数； semzcnt: 等待semval变为0的线程数； semadj: 所指定信号量针对调用进程的调整值；【？？？】    2.信号量集相关数据结构  信号量集结构图 \nstruct semid_ds { struct ipc_perm sem_perm; // 操作权限 struct sem *sem_base; // 指向信号量集数组的指针 ushort sem_nsems; // 信号量集中信号量的数量 time_t sem_otime; // 最后semop()的时间 time_t sem_ctime; // 最后创建或IPC_SET的时间 } struct sem { ushort_t semval; // 信号量值 short sempid; // 最后成功semop()/SETVAL, SETALL的PID ushort_t semncnt; // awaiting semval \u0026gt; current vale的数量 ushort_t semzcnt; // awaiting semval = 0 的数量 } // 给信号量集中某个特定的信号量指定一个操作 // 不能静态初始化，顺序根据实现不同而不同 struct sembuf { short sem_num; // 信号量号：0, 1, ..., nsems-1 short sem_op; // 信号量操作：\u0026lt;0, 0, \u0026gt;0 short sem_flg; // 操作标记：0, IPC_NOWAIT, SEM_UNDO } // 此数据结构由用户定义，系统中没有定义 union semun { int val; // SETVAL使用 struct semid_ds *buf; // IPC_SET/IPC_STAT使用 ushort *array; // GETALL/SETALL使用 } 3. 相关函数 #include \u0026lt;sys/sem.h\u0026gt; // 创建或访问一个信号量集 // @nsems: 指定集合中的信号量数 // @oflag: // * IPC_CREAT: 不存在就创建，返回ID // * IPC_EXCL: 不管是否存在，都返回-1； // * IPC_CREAT|IPC_EXCL: 存在返回-1；不存在，创建，返回ID； int semget(key_t key, int nsems, int oflag); // 信号量操纵函数 // @opsptr-\u0026gt;sem_op: // * \u0026gt; 0：加到信号量当前值上(semval)；如果指定SEM_UNDO标志，从相应信号量的semadj值中减去sem_op; // * = 0: 调用者希望等待信号量变为0； // * \u0026lt; 0: 等待信号量值变为`\u0026gt;=sem_op的绝对值` int semop(int semid, struct sembuf *opsptr, size_t nops); // 对一个信号量执行各种控制操作 // @cmd: GETVAL/SETVAL/GETPID/GETNCNT/GETZCNT/GETALL/SETALL/IPC_RMID/IPC_SET/IPC_STAT int semctl(int semid, int semnum, int cmd, ... /*union semun org*/); 3. 注意  semget()并不初始化信号量，初始化工作需要通过semctl来完成。这会存在问题如多次初始化。【详见示例6_ex】  解决方案是：指定IPC_CREAT|IPC_EXCL，保证只有一个进程创建信号量并初始化信号量。  其他进程semget会放着EEXIST错误，并再次调用semget()。（一次不指定IPC_CREAT，也不指定IPC_EXCL） 创建和初始化分为两步，这个方案还是存在竞争问题：  进程A进行创建(semget)后，未进行初始化(semctl), 时间片到；进程B进行信号量操作（但是信号量还未初始化）。 解决办法是：  调用以IPC_STAT命令semctl，等待sem_otime变为非零值。 原因：System V手册保证semget创建一个新的信号量集时，semid_ds的sem_otime成员一定被初始化为0。         semop()睡眠时, 如果被中断，会返回EINTR错误；  semop()是需被所捕获的信号中断的慢系统调用。   删除信号量将导致等待此信号量的(睡眠中的)线程返回EIDRM(identifier removed)错误。 指定SEM_UNDO时，进程结束后，信号量会被还原。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-systemv-%E4%BF%A1%E5%8F%B7%E9%87%8F/%E4%BF%A1%E5%8F%B7%E9%87%8F%E9%9B%86%E7%BB%93%E6%9E%84%E5%9B%BE_hud9a8ce691ceb8a1dec4e4cada9270f74_93751_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-systemv-%E4%BF%A1%E5%8F%B7%E9%87%8F/","title":"操作系统 —— 进程间通信之 SystemV 信号量"},{"content":"System V 共享内存区 1. 概述  System V 共享内存区在概念上类似于Posix共享内存区；  Posix共享内存区：先调用shm_open，后调用mmap; System V 共享内存区：先调用shmget, 后调用shmat;    2. shmget函数 #include \u0026lt;sys/shm.h\u0026gt; int shmget(key_t key, size_t size, int shmflg);  作用：创建一个新的共享内存区或者访问一个已存在的共享内存区。 参数：  key: ftok的返回值或者IPC_PRIVATE。  如果key=IPC_PRIVATE并且shmflg指定IPC_CREAT标记，则创建共享内存区。 如果没有key对应的共享内存标识符并且指定IPC_CREAT，则创建共享内存区。 创建内存区会初始化内存区为0。（size字节） 创建共享内存区会分配shmid_ds结构  struct shmid_ds { struct ipc_perm shm_perm; /* operation permissions */ int shm_segsz; /* size of segment in bytes */ pid_t shm_lpid; /* pid of last shm op */ pid_t shm_cpid; /* pid of creator */ short shm_nattch; /* # of current attaches */ time_t shm_atime; /* last shmat() time*/ time_t shm_dtime; /* last shmdt() time */ time_t shm_ctime; /* last change by shmctl() */ void *shm_internal; /* sysv stupidity */ };  size: 大小 shmflg： 标记   返回：共享内存区标识符(整数)  3. shmat函数 void *shmat(int shmid, const void *shmaddr, int shmflg);  作用：把shmget创建/打开的共享内存区连接到调用进程的地址空间； 参数：  shmid: shmget返回的标识符，共享内存区的ID； shmaddr：如果是NULL，则系统进行选址（推荐）；  不为NULL：  shmflg指定了SHM_RND，连接到shmaddr指定的地址； shmflg没有指定SHM_RND，连接到shmaddr指定的地址向下舍入的一个SHMLBA常值； LBA表示：低端边界地址(lower bounder address)【？？？】     shmflg: 标记/权限；   返回：成功，映射区的起始地址；失败，-1。  4. shmdt函数 int shmdt(const void *shmaddr)  作用：断开与共享内存区的连接。 参数：  shmaddr：共享内存区地址   返回：成功0，失败-1  5. shmctl函数 int shmctl(int shmid, int cmd, struct shmid_ds *buf);  作用：对一个共享内存区进行控制/操作。 参数：  shmid: 共享内存区ID； cmd: 控制命令，IPC_RMID/IPC_SET/IPC_STAT; buff: 传参/传结果的结构   返回：成功0，失败-1  6. System V共享内存区的限制 和System V消息队列、System V信号量一样，System V共享内存区也存在特定的系统限制。\n 详见示例5_ex  A. 问题  shmget是否要求文件存在？  要求文件存在。   是否支持亲缘进程间使用？  支持。 具体哪里进行拆分，没有进行测试。   是否支持无亲缘进程间使用？  支持。   读/写超过共享内存区范围会怎样？  大小分页后，最后不足1页：  访问不超过此页，不会报错； 超过，则段错误(segmentation fault)。   【和7.B类似】   Posix共享内存区和SystemV共享内存区有什么差别？  Posix共享内存区对象的大小可以再任意时刻通过调用ftruncate改变； SystemV共享内存区对象的大小是调用shmget创建时固定的。    B. 注意  shmget创建或打开共享内存区时，并没有给调用进程提供访问该内存区的手段。（因此要调用shmat）  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-systemv-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/image_hu70675371b4d01d0ec6d16ae0abb1373c_296698_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-systemv-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/","title":"操作系统 —— 进程间通信之 SystemV 共享内存"},{"content":"消息队列  在新的应用程序中，不应再使用消息队列。【分布式系统里面，好像很常用！需要时再了解！】  详见此Readme 2.4节 若需要客户进程和服务器进程之间的双向数据流，用UNIX域套接字或全双工管道。   队列：消息队列。信息的链接表，存储在内核中，由标识符标识。 队列ID：消息队列标识符。 与队列关联的数据结构：定义队列的当前状态  struct msqid_ds { struct ipc_perm msg_perm; msgqnum_t msg_qnum; // 队列里的消息长度/数量  msglen_t msg_qbytes; // 队列中能容纳的最大字节数  pid_t msg_lspid; // 最后msgsnd()的pid  pid_t msg_lrpid; // 最后msgrcv()的pid  time_t msg_stime; // 最后msgsnd()的时间  time_t msg_rtime; // 最后msgrcv()的时间  time_t msg_ctime; // 最后改变时间 } 1. 消息队列的系统限制  消息队列的系统限制 \n 导出的：这种限制来源于其他限制。  如：Linux系统中，最大消息数受限于最大队列数，最大队列数受限于系统安装的RAM大小/数量。    2. 相关函数  key转换标识符的规则，见Readme 创建新队列、引用现有队列。  #include \u0026lt;sys/msg.h\u0026gt; // key: 键 // 返回：标识符/队列ID int msgget(key_t key, int flag);  队列控制函数  #include \u0026lt;sys/msg.h\u0026gt;// cmd: // * IPC_STAT: 取队列的smqid_ds结构，存放在buf中 // * IPC_SET: 将buf中的msg_perm.uid/gid/mode/msg_qbytes等复制到队列对应的msqid_ds结构中。 // * IPC_RMID: 删除队列及其中的所有数据，删除立即生效。 int msgctl(int msqid, int cmd, struct msqid_ds *buf)  放数据到队列中  #include \u0026lt;sys/msg.h\u0026gt; /* * msqid: 队列标识 * ptr: 指向类似以下的结构 * * struct my_msg { * long my_type; // 数据类型【？？？】 * char my_test[nbytes]; // 数据 * } * nbytes: 数据大小 * flag: * * IPC_NOWAIT: 队列满，返回-1，errno = EAGAIN * * 否则，阻塞到 * * 等待到队列空； * * 队列被删除, 返回-1, errno = EIDRM； * * 收到信号，并从信号处理程序返回；返回-1, errno = EINTR； */ int msgsnd(int msqid, const void *ptr, size_t nbytes, int flag);  从队列中取数据  #include \u0026lt;sys/msg.h\u0026gt; /* * type: 指定想要消息的类型。 * * type == 0: 队列中的第一个消息； * * type \u0026gt; 0 : 队列中第一个类型为type的消息； * * type \u0026lt; 0 : 返回队列中消息类型值\u0026lt;=`type绝对值`的消息。如果多个，则返回类型值最小的[第一个]消息。 * flag: * * IPC_NOWAIT: 队列空，立即返回-1, errno = ENOMSG; * * 否则，阻塞到 * * 等待到队列有需要的数据； * * 队列被删除, 返回-1, errno = EIDRM； * * 收到信号，并从信号处理程序返回；返回-1, errno = EINTR； */ int msgrcv(int msqid, const void *ptr, size_t nbytes, long type, int flag); 3. 注意  对于\u0026quot;在新的应用程序中，不应再使用消息队列\u0026quot;，貌似现在很多系统还在使用，不确定是否说的是一个东西，需要时要再了解。  A.拓展  分布式消息队列 消息队列  B. 参考  《UNIX环境高级编程 第三版》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-systemv-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/System_V_msg_queue_struct_in_kernel_hu498ddc20215e05cce1e1ed9d386c01d9_106974_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B-systemv-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","title":"操作系统 —— 进程间通信之 SystemV 消息队列"},{"content":"FIFO  FIFO有时被称为命名管道。 FIFO是一种文件类型。 支持在无亲缘进程间使用。  1. FIFO创建  创建FIFO类似于创建文件；FIFO的路径名存在于文件系统中。  2. 创建FIFO  相关函数  #include \u0026lt;sys/stat.h\u0026gt;int mkfifo(const char *path, mode_t mode); // 在fd表示的目录相关位置，创建一个FIFO。 // * path为绝对路径，则忽略fd // * path为相对路径，则fd参数是一个打开的目录的文件描述符。路径名和目录有关【？？？】 // * path为相对路径，并且fd参数有特殊值AT_FDCWD，则路径名以当前目录开始。 int mkfifoat(int fd, const char *path, mode_t mode); 3. 其他  open一个FIFO时，非阻塞标记(O_NONBLOCK)会产生的影响：  一般情况下(没有指定O_NONBLOCK)，  只读open要阻塞到其他进程为写打开此FIFO为止； 只写open要阻塞到其他进程为读打开此FIFO为止；   如果指定了O_NONBLOCK，则：  只读open时，立即返回。【返回啥？正常返回？】 只写open时，如果没有其他进程为读打开此FIFO，则此只写open返回-1，errno置为ENXIO。     若write一个没有进程为读打开的FIFO，则产生信号SIGPIPE。（类似pipe） 若FIFO的最后一个写进程关闭了该FIFO，则将为改FIFO的读进程产生一个文件结束标记。（类似于pipe） FIFO的两种用途：  shell命令使用FIFO将数据从一条管道传送到另一条时，无需创建中间临时文件； 客户——服务器进程应用中，FIFO用作汇聚点，在客户和服务器进程间传递数据；    4.管道和FIFO的限制  OPEN_MAX: 一个进程在任意时刻打开的最大描述符数。（sysconf函数获取）  示例见3_ex_pipeconf.c   PIPE_BUF: 可原子写管道/FIFO的最大数据量。（pathconf/fpathconf函数获取）  示例见3_ex_pipeconf.c    A. 疑问 B. 参考  《unix环境高级编程 第三版》 《UNIX网络编程 卷2 进程间通信 第2版》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8Bfifo/image_hu919e7e7429058a953ed0cc72caeca2a5_166812_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8Bfifo/","title":"操作系统 —— 进程间通信之FIFO"},{"content":"Posix共享内存区  共享内存区是可用IPC形式中最快的。 一旦内存区映射到共享它的进程的地址空间，这些进程间的数据传递就不需要经过内核了；但是读写内存区时，需要进行同步。 非共享缓冲区读文件传给另一个进程写：4次内核与内核的交互  非共享缓冲区读文件传给另一个进程写  共享缓冲区读文件传给另一个进程写：2次内核与进程的交互  共享缓冲区读文件传给另一个进程写   1. 相关函数 1.1 mmap  mmap: 把一个文件或一个Posix共享内存区对象映射到调用进程的地址空间。 使用此函数有3个目的：  使用普通文件以提供内存映射I/O； 使用特殊文件以提供匿名内存映射； 使用shm_open以提供无亲缘关系进程间的Posix共享内存区。   映射文件示意图：  映射文件示意图   #include \u0026lt;sys/mman.h\u0026gt; // addr: 指定fd映射到的进程内空间的起始地址； // len: 映射的长度——字节数； // offset: 从被映射文件开头起offset字节开始映射； // prot: 属性/模式(PROT_READ|PROT_WRITE|PROT_EXEC|PROT_NONE) // * PROT_NONE Pages may not be accessed. // * PROT_READ Pages may be read. // * PROT_WRITE Pages may be written. // * PROT_EXEC Pages may be executed. // flag: 很多歌，具体见man // * MAP_PRIVATE: 变动私有，不改变低层支撑对象； // * MAP_SHARED: 变动共享，其他进程可见，改变低层支撑对象； // * MAP_FIXED: 准确地解释addr参数；【？？？】 // 返回：成功——映射起始地址；失败——MAP_FAILED，设置errno void *mmap(void *addr, size_t len, int prot, int flags, int fd, off_t offset); 1.2 munmap  munmap: 从某个进程的地址空间删除一个映射关系。  #include \u0026lt;sys/mman.h\u0026gt; int munmap(void *addr, size_t len); 1.3 msync  msync: 同步内存与硬盘上的内容。  #include \u0026lt;sys/mman.h\u0026gt; // flags: // * MS_ASYNC: 执行异步写（写操作入内核队列，就返回） // * MS_SYNC: 执行同步写（写操作完成后才返回） // （以上两个指定一个，但不能都指定） // * MS_INVALIDATE: 使高速缓存的数据失效 int msync(void *addr, size_t len, int flags); 2. 文件内存映射 内存映射一个普通文件时，内存中映射区的大小(mmap的第2个参数)通常等于改文件的大小。 详见示例\n3. 匿名内存映射 使用非匿名内存映射时，需要在文件系统中创建一个文件，进行open并write一些数据进行初始化。 如果目的是提供一个父子进程共享的内存映射，匿名内存映射则能简化上述流程。 创建匿名映射的方法：\n mmap的flag参数指定MAP_SHARED|MAP_ANON, fd = -1。 这样的内存区会被初始化为0； 详见示例  A. 注意  从移植性考虑，MAP_FIXED不应该指定。 可移植的代码，应该把addr指定为NULL，并且不指定MAP_FIXED。 mmap成功返回后，fd可关闭。 不是所有文件都能mmap。  B.问题  为什么使用mmap？  不用调用read/write/lseek，简化了代码。   当映射的内存大于文件大小？等于文件大小？  macOS的man手册中，明确说明，文件映射的内存不是页的倍数时会被扩充。【详见示例】 等于：      大于：  SIGBUS意味着：是在内存映射区访问，但是超出了低层支撑对象的大小。       如何映射一个持续增长的文件？  映射比文件大的多的区域，随着文件增长再对相应区域进行访问。 详见示例    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/map_file_hu2b38632246c801a0071d06acf9f6a1dc_72126_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/","title":"操作系统 —— 进程间通信之共享内存"},{"content":"管道  管道的局限性  半双工：数据只能在一个方向上流动； 只能在具有共同祖先的两个进程间使用。    1. 管道创建  相关函数  #include \u0026lt;unistd.h\u0026gt; int pipe(int fd[2]);   fd[0]为读而打开；\n  fd[1]为写而打开；\n  fd[1]的输出是fd[0]的输入；【？！】\n  PIPE_BUF规定内核的管道缓冲区的大小。\n pathconf及fpathconf可以确定PIPE_BUF的值。    当管道的一端被关闭后，适用的规则：\n 当读(read)一个写端被关闭的管道，在所有数据被读取后，read返回0； 当写(write)一个读端被关闭的管道，则产生信号SIGPIPE。  忽略/捕捉信号并从信号处理程序返回后，write返回-1，errno=EPIPE。      A. 疑问  fd[1]的输出是fd[0]的输入？  fd[1]写端往管道写数据，即fd[1]的输出。 fd[0]读端从管道读数据，即fd[0]的输入。 详见示例：2_ex_pipe_copy_file_toless_or_more.c   多个进程使用相同的fd[2]的时候，管道的读写是怎么样的？  管道是多个进程共用的，谁都可以写，也都可以读。因此写入/读取的信息可能混杂在一起。 详见示例：3_ex_read_and_write.c    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B%E7%AE%A1%E9%81%93/image_hua7dd9656545c33c7233f1072aca164a6_218829_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B9%8B%E7%AE%A1%E9%81%93/","title":"操作系统 —— 进程间通信之管道"},{"content":"互斥锁与条件变量  互斥锁及条件变量是同步的基本组成部分。 互斥锁及条件变量出自Posix.1线程标准；  可以用来同步一个进程内的各个线程； 也可以用在进程间同步：互斥锁放在多个进程的共享内存区中。    1.互斥锁  互斥锁：相互排斥，是最基本的同步形式。 作用：保护临界区（critical region）。  保护的是数据：临界区中被操纵的数据；进程/线程共享的数据。   互斥锁是协作性锁，也就是锁无法防止一些进程/线程不先获取锁就访问数据。（需要靠自觉）  1.1 相关函数  静态分配使用PTHREAD_MUTEX_INITIALIZER进行初始化  #include \u0026lt;pthread.h\u0026gt; // 互斥锁初始化、销毁 int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr); int pthread_mutex_destroy(pthread_mutex_t *mutex); // 上锁、解锁 int pthread_mutex_lock(pthread_mutex_t *mptr); int pthread_mutex_trylock(pthread_mutex_t *mptr); int pthread_mutex_unlock(pthread_mutex_t *mptr); // 属性初始化、销毁 int pthread_mutexattr_init(pthread_mutexattr_t *attr); int pthread_mutexattr_destroy(pthread_mutexattr_t *attr) // 属性设置：进程间共享等（MACOS和LINUX相关函数有所不同）  // 均返回：成功：0，失败：正的Exxx值 2. 条件变量  互斥锁用于上锁，条件变量用于等待。 每个条件变量总是与一个互斥锁相关联。  2.1 相关函数  静态分配使用PTHREAD_COND_INITIALIZER进行初始化  #include \u0026lt;pthread.h\u0026gt; // 条件变量初始化、销毁 int pthread_cond_init(pthread_cond_t *cond, const pthread_condattr_t *attr); int pthread_cond_destroy(pthread_cond_t *cond); // 线程睡眠，进行等待 int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); // 唤醒等待线程——等待在相应条件变量上的线程 int pthread_cond_signal(pthread_cond_t *cond); // 唤醒等待线程——等待在相应条件变量上的多个线程 int pthread_cond_broadcast(pthread_cond_t *cond); // 时间是绝对时间：返回时刻的系统时间。不是时间差。 int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex_t *mutex, const struct timespec *abstime); struct timespec { time_t tv_sec; // seconds  long tv_nsec; // nanoseconds } // 属性初始化、销毁 int pthread_condattr_init(pthread_condattr_t *attr); int pthread_condattr_destroy(pthread_condattr_t *attr); // 属性设置：进程间共享等（MACOS和LINUX相关函数有所不同: MACOX没有条件变量属性设置函数） 2. 注意  条件的检测是在互斥锁的保护下进行的；  条件变量进行等待前，会释放持有的互斥锁。 【详见2_ex】    A. 拓展  生产者-消费者问题，也称为有界缓冲区问题。  当生产者-消费者使用管道、消息队列(SystemV/Posix)进行通信时，同步是隐式的(implicit)，由内核执行同步。 当使用内存共享时，生产者/消费者必须执行某种显式的(explicit)的同步。    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B9%8B%E4%BA%92%E6%96%A5%E9%94%81%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/image_hu488b2f82ab20ee50f487200f2be764c2_242367_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B9%8B%E4%BA%92%E6%96%A5%E9%94%81%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F/","title":"操作系统 —— 进线程同步之互斥锁、条件变量"},{"content":"读写锁 1. 什么是读写锁  互斥锁把试图进入临界区的(多余)线程都阻塞住，无论是读还是写。（不区分读写）  独占锁。   读写锁区分读和写，同时只能一个线程写(写时不能读)；允许同时多个线程读(读时没有写)。  读为共享锁，写为独占锁。 读比写更频繁的应用中，用读写锁更好。    2. 读写锁的分配规则  只要没有线程持有读写锁用于写，任意数目的线程可以持有该读写锁用于读。 仅当没有线程持有读写锁时(用于读或写)，才能分配读写锁用于写。  3. 相关函数  静态分配用PTHREAD_RWLOCK_INITIALIZER进行初始化。  #include \u0026lt;pthread.h\u0026gt; // 初始化、销毁 int pthread_rwlock_init(pthread_rwlock_t *lock, const pthread_rwlockattr_t *attr); int pthread_rwlock_destroy(pthread_rwlock_t *lock); // 加锁、解锁 int pthread_rwlock_rdlock(pthread_rwlock_t *lock); int pthread_rwlock_tryrdlock(pthread_rwlock_t *lock); int pthread_rwlock_wrlock(pthread_rwlock_t *lock); int pthread_rwlock_trywrlock(pthread_rwlock_t *lock); int pthread_rwlock_unlock(pthread_rwlock_t *lock); // 属性初始化、销毁 int pthread_rwlockattr_init(pthread_rwlockattr_t *attr); int pthread_rwlockattr_destroy(pthread_rwlockattr_t *attr); // 属性设置：设置进程间共享: PTHREAD_PROCESS_SHARED/PTHREAD_PROCESS_PRIVATE int pthread_rwlockattr_getpshared(const pthread_rwlockattr_t *attr, int *pshared); int pthread_rwlockattr_setpshared(pthread_rwlockattr_t *attr, int pshared); ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/image_hud37660a567da8df0403875e6c802b8b7_242254_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/","title":"操作系统 —— 进线程同步之读写锁"},{"content":"ARP协议 ARP（Address Resolution Protocol）：地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议。\n工作过程 当主机A要与主机B通信时，地址解析协议可以将主机B的IP地址解析成主机B的MAC地址(如果A/B不同网段，则A解析的应该是下一跳的MAC地址)，以下为工作流程：\n 第1步：主机A根据路由表内容，确定用于访问主机B的转发IP地址。主机A在本地ARP缓存中查找与主机B的IP匹配MAC地址。 第2步：如果主机A没有找到映射，则将ARP请求帧广播到本地网络上的所有主机。  收到请求的主机检查自己的IP是否匹配，不匹配就丢弃此ARP请求。   第3步：主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。 第4步：主机B将包含其MAC地址的ARP回复消息直接发送回主机A。 第5步：当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。  问题 什么是ARP欺骗？  地址解析协议是建立在网络中各个主机可互相信任的基础上的，收到应答报文的主机，不会校验报文的真实性，就会加到ARP缓存中。 由此，攻击者可以向某一主机发送伪ARP应答报文，使此主机发送的信息无法到达预期的主机或者到达错误的主机，这就是ARP欺骗。  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-arp/image_hu70840ac7263b3ebb6d16250de0b46ff4_264462_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-arp/","title":"网络协议 —— ARP"},{"content":"DHCP DHCP - 动态主机设置协议（Dynamic Host Configuration Protocol）。 DHCP是一个应用层协议。基于UDP。\n作用  用于内网或网络服务供应商自动分配IP给用户。 作为内部管理员对所有计算机进行中央管理的手段。  历史  DHCP在1993年10月成为标准协议，它的前身是BOOTP协议。 BOOTP：BOOTP是一种网络协议，让电脑或其他周边仪器可以从服务器下载启动程序。  数据包类型  DHCP发现（DISCOVER）：client在物理子网上发送广播来寻找可用的服务器。 DHCP提供（OFFER）：当DHCP服务器收到一个来自客户的IP租约请求时，它会提供一个IP租约。 DHCP请求（REQUEST）：当客户PC收到一个IP租约提供时，它必须告诉所有其他的DHCP服务器它已经接受了一个租约提供。 DHCP确认（Acknowledge，ACK）：确认租约，包含租期和客户可能请求的其他所有配置信息。 DHCP释放(RELEASE)：客户端向DHCP服务器发送一个请求以释放DHCP资源，并注销其IP地址。 DHCP NAK：服务器回复客户，客户要求的网址不能被分配。  原理/流程  客户主机发送DHCP服务器发现(DISCOVER)广播包。 服务器收到DISCOVER包后，回复OFFER单播或广播包。【疑问？】 客户主机收到OFFER包后，发送REQUEST广播包。 服务器回复ACK单播或广播包。包含分配的IP及网关IP(next server IP)、租约等。   典型DHCP会话的模式 \n协议结构  +-------+--------+--------+--------+ |8 bits | 8 bits | 8 bits | 8 bits | +-------+--------+--------+--------+ | Op | Htype | Hlen | Hops | +-------+--------+--------+--------+ | Xid | +----------------------------------+ | Secs | Flags | +----------------+-----------------+ | Ciaddr | +----------------------------------+ | Yiaddr | +----------------------------------+ | Siaddr | +----------------------------------+ | Giaddr | +----------------------------------+ | Chaddr (16 bytes) | +----------------------------------+ | Sname (64 bytes) | +----------------------------------+ | File (128 bytes) | +----------------------------------+ | Option (variable) | +----------------------------------+  Op: 信息类型。如：客户端请求为1，服务器回复为2。 Htype：硬件类型。如：Ethernet(0x01) Hlen: 硬件地址长度。如：6。（MAC地址） Hops: 跳数。 Xid：传输ID。 Secs: 过去的时间。【疑问】 Flags：标记。 Ciaddr：客户端IP地址。（这里应该是续约的时候用的） Siaddr：下一个服务器IP地址。 Yiaddr：你的IP。（分配给客户机的IP） Giaddr：中继代理IP。【？？？】 Chaddr：客户机硬件地址。（Ethernet中就是Mac地址） Sname：服务器主机名称。 File：文件名。 Options：选项。详见rfc2132  1：子网掩码； 3：路由(网关)； 12：主机名 50：请求的IP地址 51：租约时间 53：DHCP消息类型。即上面的几种类型。 54：服务器标识。    疑问 DHCP服务器是否可以把一台主机拉黑？  这个应该由DHCP软件提供。  服务器回复为什么是单播或广播包？  Flags中设置BROADCAST = 0时，则是单播；否则是广播。这是为了健壮性，同时兼容单播和多播。  Secs字段是哪一个时间段？  从获取到IP地址或者续约过程开始到现在所消耗的时间。  Giaddr字段作用是什么？  giaddr: 中继代理地址。 中继代理相关详见：博客  相关  DHCP: RFC 2131 DHCP6: RFC 3315 DHCP wiki DHCP wiki中文 rfc2132  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-dhcp/dhcp_hudbf177609d4e03da36b00b06f63101bd_20695_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-dhcp/","title":"网络协议 —— DHCP"},{"content":"DNS DNS - 域名系统（Domain Name System）。\n 是一个将域名和IP地址进行映射的分布式数据库。 DNS是应用层协议，使用TCP和UDP的53端口。 每一级域名长度的限制是63个字符，域名总长度不能超过253个字符。  作用  将对人友好的域名转换为对计算机友好的IP地址。  原理/过程 域名层级\n主机名.次级域名.顶级域名.根域名 host.sld.tld.root www.isshe.xyz.root abc.isshe.xyz.root 分级查询：从根域名开始，依次查询每一级域名的NS记录。\n 从根域名服务器查询顶级域名服务器的NS记录和A记录；  根域名服务器是总所周知的，不用查。   从顶级域名服务器查询次级域名服务器的NS记录和A记录； 从次级域名服务器查询主机名的A记录；  分级查询示例：www.isshe.xyz\n dig +trace www.isshe.xyz 进行查看\n  列出根域名服务器：  . 227343 IN NS e.root-servers.net. . 227343 IN NS k.root-servers.net. . 227343 IN NS i.root-servers.net. . 227343 IN NS d.root-servers.net. . 227343 IN NS j.root-servers.net. . 227343 IN NS m.root-servers.net. . 227343 IN NS b.root-servers.net. . 227343 IN NS c.root-servers.net. . 227343 IN NS h.root-servers.net. . 227343 IN NS f.root-servers.net. . 227343 IN NS l.root-servers.net. . 227343 IN NS a.root-servers.net. . 227343 IN NS g.root-servers.net.  查询xyz.的结果：  xyz. 172800 IN NS x.nic.xyz. xyz. 172800 IN NS y.nic.xyz. xyz. 172800 IN NS z.nic.xyz. xyz. 172800 IN NS generationxyz.nic.xyz. ... ;; Received 669 bytes from 192.58.128.30#53(j.root-servers.net) in 651 ms  查询isshe.xyz.的结果：  isshe.xyz. 3600 IN NS f1g1ns1.dnspod.net. isshe.xyz. 3600 IN NS f1g1ns2.dnspod.net. ... ;; Received 581 bytes from 194.169.218.42#53(x.nic.xyz) in 245 ms  查询www.isshe.xyz.的结果：  www.isshe.xyz. 600 IN CNAME isshe.coding.me. isshe.xyz. 86400 IN NS f1g1ns1.dnspod.net. isshe.xyz. 86400 IN NS f1g1ns2.dnspod.net. ;; Received 135 bytes from 14.215.155.156#53(f1g1ns1.dnspod.net) in 10 ms 协议格式 0 16 32 0 16 32 +-------------------+-------------------+ +---------------------------------------+ | Transaction ID | Flags | / Name / +-------------------+-------------------+ / / | Questions | Answer RRs | +-------------------+-------------------+ +-------------------+-------------------+ | Type | Class | | Authority RRs | Additional RRs | +-------------------+-------------------+ +-------------------+-------------------+ / / Question / +---------------------------------------+ / Answers / +---------------------------------------+ / Authoritaty / +---------------------------------------+ / Additional / +---------------------------------------+ Transaction ID  会话ID，DNS报文的ID标识。 请求和应答报文的这个字段相同。  Flags  标志：  +----+--------+----+----+----+----+--------+-------+ | QR | opcode | AA | TC | RD | RA | (zero) | rcode | +----+--------+----+----+----+----+--------+-------+ 1 4 1 1 1 1 3 4  QR: 查询/响应标记，0查询，1响应。 opcode：0标准查询，1反向查询，2服务器状态请求。 AA：授权回答。 TC：可截断的。 RD：期望递归。 RA：可用递归。 rcode：表示返回码。0没有差错，2服务器错误，3名字差错  Question 0 16 32 +---------------------------------------+ / Name / / / +-------------------+-------------------+ | Type | Class | +-------------------+-------------------+  Name：查询的域名名称。按Lable划分(isshe.xyz，为2个lable)，以'\\0'结尾；可能为奇数个字节。 Type：查询类型。A：主机。 Class：查询的协议类。IN：internet。  Answer/Authority/Additional 0 16 32 +---------------------------------------+ / Name / / / +-------------------+-------------------+ | Type | Class | +-------------------+-------------------+ | TTL | +---------------------------------------+ | RdLength | Rdata / +-------------------+ / | / +---------------------------------------+  Name: 域名。 Type：类型。 Class：Rdata的类。 TTL：资源记录的生存时间。0表示只能被传输，不能被缓存。（无符号整型） RdLenght：Rdata的长度。 Rdata：资源数据，表示记录。格式和Type、Class有关。如Type=A、Class=IN，Rdata就是一个IP地址。  RRs Questions：指明Question的数量。 Answer RRs：指明Answer的数量。 Authority RRs：指明Antuority的数量。 Additional RRs：指明Additional的数量。\n记录类型  详见DNS记录类型列表\n 常见记录类型：\n A：主机记录（Address）。 NS：域名服务器记录（Name Server）。  返回保存下一级域名信息的服务器地址。该记录只能设置为域名，不能设置为IP地址。   CNAME：规范名称记录，当前查询域名是另一个域名的跳转。（即别名记录，指向某个A记录） AAAA：IPv6主机记录。 SRV：服务位置记录。 MX: 邮件记录(Mail eXchange)，返回接收电子邮件的服务器地址。 PTR：逆向查询记录（Pointer Record），从IP查域名。  报文示例 报文示例-查询  +---------------------------------------------------+ Header | OPCODE=SQUERY | +---------------------------------------------------+ Question | QNAME=SRI-NIC.ARPA., QCLASS=IN, QTYPE=A | +---------------------------------------------------+ Answer | \u0026lt;empty\u0026gt; | +---------------------------------------------------+ Authority | \u0026lt;empty\u0026gt; | +---------------------------------------------------+ Additional | \u0026lt;empty\u0026gt; | +---------------------------------------------------+ 报文示例-响应  +---------------------------------------------------+ Header | OPCODE=SQUERY, RESPONSE, AA | +---------------------------------------------------+ Question | QNAME=SRI-NIC.ARPA., QCLASS=IN, QTYPE=A | +---------------------------------------------------+ Answer | SRI-NIC.ARPA. 86400 IN A 26.0.0.73 | | 86400 IN A 10.0.0.51 | +---------------------------------------------------+ Authority | \u0026lt;empty\u0026gt; | +---------------------------------------------------+ Additional | \u0026lt;empty\u0026gt; | +---------------------------------------------------+ 疑问 相关  dig 命令：可用于DNS相关操作。 host 命令：dig的简化版本。 whois 命令: 查看域名注册情况。 nslookup 命令: 可互动式查询域名记录。 DNS 原理入门-阮一峰 wiki wiki中文  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-dns/image_hu2eb95bf5c5ba7e990e649bbb75c2aacc_298769_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-dns/","title":"网络协议 —— DNS"},{"content":"ICMP  ICMP - 互联网控制消息协议（Internet Control Message Protocol） ICMP是互联网协议族的核心协议之一。 IMCP用于发送控制消息，提供可能发生在通信环境中的各种问题反馈。 ICMP消息都是直接封装在一个IP数据包中的，因此，和UDP一样，ICMP是不可靠的。  原理及技术细节  每个路由器在转发数据报的时候都会把IP包头中的TTL值减1。  报文结构 ICMP报头从IP报头的第160位(20字节)开始：（有可选部分另算）\n 8bit 8bit 8bit 8bit +------+------+------+------+ | Type | Code | Checksum | +------+------+------+------+ | ID | Sequence | +------+------+------+------+  Type: ICMP报文类型。 Code：进一步划分ICMP的类型；该字段用来查找产生错误的原因。  例如，ICMP的目标不可达类型可以把这个位设为1至15等来表示不同的意思。   Checksum：校验和。 ID：ID/标识，在Echo Reply类型的消息中需要返回这个字段。 Sequence：序号，在Echo Reply类型的消息中需要返回这个字段。  报文类型    Type Code Status 描述 查询 差错 备注     0：Echo响应 0  Echo响应 ✓  ping中使用   1  未分配   ✓ 保留   2  未分配   ✓ 保留   3：目的不可达 0  目标网络不可达  ✓     1  目标主机不可达  ✓     2  目标协议不可达  ✓     3  目标端口不可达  ✓     4  要求分段并(但)设置DF标记  ✓     5  源路由失败  ✓     6  未知的目标网络  ✓     7  未知的目标主机  ✓     8  源主机隔离（作废不用）  ✓     9  禁止访问的网络  ✓     10  禁止访问的主机  ✓     11  对特定的TOS 网络不可达  ✓     12  对特定的TOS 主机不可达  ✓     13  由于过滤 网络流量被禁止  ✓     14  主机越权  ✓     15  优先权终止生效  ✓    4：源端关闭 0 弃用 源端关闭（拥塞控制）  ✓    5：重定向 0  重定向网络  ✓     1  重定向主机  ✓     2  基于TOS的网络重定向  ✓     3  基于TOS的主机重定向  ✓    6  弃用 备用主机地址      7  未分配 保留      8 0  Echo请求 ✓     9 0  路由通告 ✓     10 0  路由器的发现/选择/请求 ✓     11：超时 0  TTL超时  ✓     1  分片重组超时  ✓    12：参数问题-IP头部错误 0  IP报文首部参数错误  ✓     1  丢失必要选项  ✓     2  不支持的长度      13 0  时间戳请求 ✓     14 0  时间戳应答 ✓     15 0  信息请求 ✓     16 0  信息应答 ✓     17 0  地址掩码请求 ✓     18 0  地址掩码应答 ✓     19  保留 因安全原因保留      20~29  保留 保留用于稳健性实验      30~39  弃用       40   Photuris, Security failures   ？？？   41   用于实验性移动协议，如Seamoby[RFC4065]      42~255  保留       235  实验性 RFC3692      254  实验性 RFC3692                部分报文结构示例 3：目标不可达 目的地不可达由主机或其入站网关生成，以通知客户端由于某种原因目的地不可达。\n0 8 16 24 32 +---------+----------+----------+----------+ | Type=3 | Code=... | Checksum | +---------+----------+----------+----------+ | 未使用 | 下一跳MTU | +------------------------------------------+ | IP报头和原始数据报数据的前8个字节 | +------------------------------------------+ 11: 超时 超时由网关生成，以便通知源，数据报在TTL=0时被丢弃了。\n0 8 16 32 +---------+----------+----------+ | Type=11 | Code=0/1 | Checksum | +---------+----------+----------+ | 未使用 | +-------------------------------+ | IP报头和原始数据报数据的前8个字节 | +-------------------------------+ 相关  RFC 792  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-icmp/image_hua7dd9656545c33c7233f1072aca164a6_218829_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-icmp/","title":"网络协议 —— ICMP"},{"content":"代理模式  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念   定义/意图：为某个对象提供一种代理，以控制对这个对象的访问。\n 控制对象的访问；只有需要时才创建、初始化。    别名：Proxy，Surrogate[ˈsɜ:rəgət]\n  类图：  类图 \n  可能的对象图  对象图 \n  出场嘉宾\n Subject:  定义RealSubject和Proxy的共用接口。使得可以在任何使用RealSubject的地方使用Proxy。   Proxy: 代理。继承自Subject。  保存RealSubject的引用。 提供与RealSubject相同的接口，以代替RealSubject。 控制对RealSubject的存取/访问，并可能负责创建、删除。 针对类型的功能：  远程代理：负责对请求及参数进行编码，编发送给不同地址空间的实体。 虚拟代理：可缓存真实对象的附加信息，以延迟对真实对象的访问/创建。如，图片代理缓存图片的大小，尺寸。 保护代理：检查调用者的权限，保护真实对象。     RealSubject:  真实的对象，被Proxy代表的实体。   Client:  使用Subject。      协作/工作流程\n Client向Proxy进行请求。 Proxy进行相关附加操作后，对请求进行转发或其他操作。    2. 优缺点是什么？ 2.1 优点  可以隐藏被代理对象不再同一地址空间的事实。 可以最优化，根据要求创建对象(管理对象)。 可以对被代理对象进行保护。 可以对被访问对象进行一些额外/附加操作。  2.2 缺点  代码调用层次加深，复杂度更高。  3. 使用场景是什么？  在需要用比较通用和复杂的对象指针代替简单的指针的时候，使用Proxy模式。 使用代理模式的常见情况：  远程代理：为一个对象在不同的地址空间提供局部代表。 虚拟代理：根据需要创建开销很大的对象。一些已知的东西由代理进行提供，只有最必须时，才进行目标对象创建。 保护代理：控制对原始对象的访问，提供访问保护。 智能指引：取代简单指针，访问对象时，执行一些附加操作。典型用途：  对指向的实际对象引用计数，当对象没有引用时，自动释放对象。（也称为智能指针/Smart Pointers） 第一次引用一个持久对象时，将它装入内存。【持久化对象？？？】 访问实际对象前，检查是否锁定，以确保其他对象不能修改它。      4. 注意  实现注意：  Proxy并不总是需要知道RealSubject的类型。  如果Proxy类能通过一个抽象接口处理它的实体，则无需为每一个RealSubject类都生成一个Proxy类；Proxy可以统一处理所有RealSubject类。 如果Proxy要实例化RealSubject，则必须知道具体的类。      5. 应用实例？    w. 待办    x. 疑问    y. 拓展    z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/ObjectDiagram_hu5f455159e5a15331f999b11eee4a3509_10198_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 代理模式"},{"content":"单件模式——独一无二的对象 初看起来好像很简单，实际接触后，发现并不是这么一回事。先给自己几个问题：\n 创建对象的时候，如何知道现在只有一个？ 如何保证创建对象时候的原子性？（不能保证就有可能创建多于1个的对象） 如何获取/访问这个唯一对象？  1. 基础概念  定义/意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 原理：让类自身保存它的唯一实例，并提供一个访问该实例的方法。实例的唯一性由类来保证。 类图：  类图  出场嘉宾  Singleton：单件类。  定义一个接口，允许客户访问唯一实例。此接口是一个类操作。 负责创建唯一实例。      2. 解决什么问题？如何解决？  系统中，有些东西只需要一份就够了，因此要保证只有一份。 解决方法：只允许创建一个。但如何保证只有一个呢，见其他部分。  3. 优缺点是什么？ 3.1 优点  对唯一实例的创建是受控的——不允许直接创建（new或变量）。 对唯一实例的访问是受控的。 缩小命名空间。  此模式是对全局变量的一种改进。 避免了存储唯一实例的全局变量污染命名空间。 （同一命名空间内，两个名字相同，就会冲突。）   允许对操作和表示的精化。【？！】  单件类可以有子类。 可以使用所需的拓展类在运行时配置应用。   允许可变的数目的实例。 比类操作更灵活。  如果使用类操作（C++的静态成员函数、Smalltalk的类方法）的方式来封装单件功能，会使得改变设计以允许多个实例变得困难。   惰性(lazy)初始化，惰性创建——不需要的时候，不会创建。  3.2 缺点    4. 使用场景是什么？  多个模块共用的全局数据库/配置。  5. 注意  保证一个唯一的实例。 C++实现注意：如果将单件定义为一个全局或静态的对象，然后依赖自动的初始化，是不够的，原因：  不能保证静态对象只有一个实例会被声明。 可能没有足够的信息初始化实例。（可能需要在运行时获取信息） C++没有定义转换单元（Translation unit）上全局对象的构造器的调用顺序。【？！】 无论是否使用，都会被创建。（一开始就创建了）    6. 应用实例？    w. 待办    x. 疑问  如何拓展单件类？ 5. 注意里面第2点第3个原因，不理解！ 单件注册表？ 《设计模式：可复用面向对象软件的基础》里面好像没有考虑线程安全？  y. 拓展    z. 参考    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BB%B6%E6%A8%A1%E5%BC%8F/ClassDiagram_hu8ca9ff7362688b461397facff0e6ed9b_16668_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BB%B6%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 单件模式"},{"content":"外观模式——让接口更简单  外观模式：Facade /fəˈsɑːd/\n  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念  定义/意图：让接口更简单  为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。  使用外观模式    别名： 类图/结构：  类图  出场嘉宾  Facade：外观  知道哪些子系统负责处理哪些请求； 将客户请求代理给适当的子系统；   Subsystem Classes：其他子系统类  实现子系统的功能； 处理由Facede指派的任务； 没有Facade的任何信息；     协作/工作流程  客户 -\u0026gt; Facade -\u0026gt; Subsystem 客户发送请求给Facede； Facede将请求适当转发到子系统； 子系统完成请求工作，返回请求结果给Facede； Facede返回请求结果给客户；    2. 解决什么问题？如何解决？  降低系统间的通信和相互依赖关系。  3. 优缺点是什么？ 3.1 优点  对客户屏蔽子系统组件，减少客户处理得对象数目并使得子系统使用更方便。 实现了子系统和客户之间的松耦合关系。 Facade模式有助于建立层次 结构系统。 如应用需要，可以不限制它们使用子系统类。  3.2 缺点    4. 使用场景是什么？  当需要为一个复杂的子系统提供一个简单接口时； 客户程序与抽象类的实现部分之间存在着较大的依赖性。  引入外观模式将这个子系统与客户一级其他子系统分离，提高子系统的独立性和可移植性。   构建一个层次结构的子系统时，可以用外观模式来定义子系统中每层的入口点。  如果子系统间相互依赖，可以让它们仅通过外观模式进行通讯，从而简化依赖关系。    5. 注意  实现时注意：  降低客户-子系统的耦合度。使用抽象类实现Facade而它的具体子类对应于不同的子系统实现。 公共子系统类与私有子系统类。  子系统公共接口：包含所有用户程序可以访问的类。 子系统私有接口：仅用于对子系统进行扩充。 Facade类是公共接口的一部分。      6. 应用实例？    w. 待办    x. 疑问    y. 拓展  将一个系统划分为多个子系统有利于降低系统的复杂度。 个人理解：这个就类似于ios里面的捷径App，一个捷径可以包含多种操作。  z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/Struct_hu769c2cc54f67243d0c04bf7a939c27e8_60141_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 外观模式"},{"content":"工厂方法 工厂方法模式(Factory Method Pattern)又称为：\n 工厂模式； 虚拟构造器(Virtual Constructor)模式 多态工厂(Polymorphic Factory)模式 它属于类创建型模式。  1. 基础概念   定义/意图：\n 定义一个创建对象的接口，让子类决定实例化哪一个类。 工厂方法使一个类的实例化延迟到其子类。 框架使用抽象类定义和维护对象之间的关系。    类图：  类图 \n  出场嘉宾\n 产品/Product: 定义产品。 具体产品/Concrete Product: 定义具体的产品，继承自产品。 创建者/Creator：工厂；工厂的抽象类，声明工厂方法。  创建者可以定义一个默认的缺省实现，返回一个缺省的具体产品。   具体创建者/Concrete Creator: 具体工厂；继承自工厂，用于创建具体产品。    2. 解决什么问题？如何解决？ 3. 优缺点是什么？ 3.1 优点  【简单工厂的优点】 将创建对象的代码集中在一个对象或一个方法中，避免重复代码。 实例化对象时，依赖接口，不依赖具体类。【？！】 添加新产品时，不需修改旧代码，只需添加新的具体产品和具体创建者。  3.2 缺点  必须创建创建者的子类，无论用户想创建的具体产品是一个还是多个。（成对添加）  4. 使用场景是什么？  当一个类不知道它所创建的对象的类的时候。 当一个类希望由它的子类来指定所创建的对象的时候。 当类将创建对象的职责委托给一个或多个子类，并且将这些子类(代理者)是代理者这一信息局部化的时候。  5. 注意   工厂方法模式主要有两种不同情况：\n 1）Creator类是一个抽象类，并且不提供工厂方法的实现。 2）Creator类是具体类，并且提供工厂方法的一个缺省实现。    参数化工厂方法：一个工厂方法可以创建多种产品。\n  特定语言的变化和问题。【？！】\n  C++中，工厂方法通常是需函数并且是纯虚函数。\n  在Creator的构造器中不要调用工厂方法——在具体Concrete Creator中该方法还不可以。【？！】\n  使用模板以避免创建子类。（解决第一个缺点）【？！】\n  进行命名约定。\n  6. 应用实例？  日志记录器：同时支持多种日志记录方式，如文件记录、数据库记录等。  x. 疑问  工厂方法(Factory Method)和创建者(Creator)是否总是抽象的？  不。可以定义一个默认的工厂方法来产生具体产品。这样一来，即使没有具体创建者，也可以创建产品。   工厂方法模式和简单工厂模式的区别？ C++中，模板如何使用？ 什么是依赖倒置原则？  依赖倒置原则：要依赖抽象，不要依赖具体的类。 这个原则说明了：不能让高层组件依赖低层组件，而且，不管是高层还是低层组件，都应该依赖抽象。 示例：  依赖倒置原则示例   Pizza是一个抽象 PizzaStore(高层组件)和XXXStylePizza(低层组件)都依赖Pizza(抽象)，而不是高层组件直接依赖低层组件。     如何避免违反依赖倒置原则？  变量不可以持有具体类的引用。  如果使用new，就会持有具体类的引用，可以用工厂来避开。   不要让类派生自具体类，应派生自一个抽象（接口）  如果派生自具体类，就会依赖具体类。   不要覆盖基类中已实现的方法。  如果覆盖，说明基类不是真正适合被继承的抽象。基类中已实现的方法，应所有子类共享。      y. 拓展  C++模板 使用多个工厂方法：抽象工厂中定义多个工厂方法。 对象复用：具体创建者把创建的对象保存下来，下次创建的时候先查询，如果没有再创建。  只适合某些对象可以复用的情况。    z. 参考  《Head First设计模式》 p118  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/ClassDiagram_HF_hua415b0a2136b6facf24225125fbcde9e_119607_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 工厂方法模式"},{"content":"设计模式Readme模板 1. 基础概念   定义：提供一个创建一系列相关或相互依赖对象的接口，而无需指定他们具体的类。\n  类图：  类图 \n  出场嘉宾\n AbstractFactory: 抽象工厂；声明具体工厂的接口——声明了一个创建抽象产品对象的接口。 ConcreteFactory: 具体工厂；继承自抽象工厂，实现了创建具体产品对象的操作。 AbstractProduct: 抽象产品；声明具体产品的接口——声明了一类产品对象的接口。 ConcreteProduct: 具体产品；继承自抽象产品，定义了一个将被具体工厂创建的产品对象，实现了抽象产品的接口， Client: 仅使用由抽象工厂和抽象产品类声明的接口——不使用具体工厂、具体产品的接口/方法。    工作方式：\n 运行时创建具体工厂对象，具体工厂对象创建具体产品对象。 客户使用不同的具体工厂对象，创建不同的具体产品对象。 抽象工厂将产品对象的创建延迟到具体工厂。    2. 解决什么问题？如何解决？  需联合使用一系列产品的时候，可使用此模式 其他见【4.使用场景】  3. 优缺点是什么？ 3.1 优点  分离了具体的类：  工厂封装创建产品对象的过程，将客户和类的实现分离。客户通过抽象接口操纵实例。 具体产品的类名也在具体工厂的实现中被分离，它们不会出现在客户代码中。   易于交换产品系列：  一个具体工厂类在一个应用中仅出现一次——它初始化的时候； 改变具体工厂类即可改变产品配置——具体工厂类A换为具体工厂类B,则产品配置从A也更换到B。   有利于产品的一致性：【？？？】  一个系列的产品对象被设计成一起工作的时候，一个应用一次只能使用同一个系列中的对象。【？？？】    3.2 缺点  难以添加新种类的产品，需改代码。（拓展性受到限制）  抽象工厂类确定了可以被创建的产品集合，要新增就要修改此类——它及它的子类都要变化。    4. 使用场景是什么？  一个系统要独立于它的产品的创建、组合和表示时。【不理解？！】 一个系统要由多个产品系列中的一个来配置时。 当要强调一系列相关的产品对象的设计以便进行联合使用时。 当你提供一个产品类库，而只想显示它们的接口而不是实现时。  5. 注意/实现  将[具体]工厂作为单件：一个应用中一般每个产品系列只需一个具体工厂的实例。 抽象工厂只声明接口，不创建产品。创建产品由具体工厂来做。  通常做法：每个产品定义一个工厂方法。见工厂方法模式   定义可扩展的工厂：解决3.2中缺点1  更灵活但不太安全的设计：给创建对象的操作增加一个参数，该参数指定将被创建的对象的种类。【？？？】  C++中，只有当产品对象可以被请求它们的客户安全的强制类型转换才能使用。      6. 应用实例？  InterView的Kit ET++  w. 待办  对定义不理解，理解后，进行备注  x. 疑问  工厂方法模式和抽象工厂模式的区别是什么？  抽象工厂模式通常使用工厂方法模式来实现。 添加一个新的产品，工厂方法修改工厂，抽象工厂新建新工厂。 工厂方法模式:  使用的是类; 通过继承创建就对象——拓展一个父类，并覆盖父类的工厂方法【？？？】 用途：把客户代码从实例化的具体类中解耦 或 当不清楚要实例化具体类时使用。   抽象工厂模式  使用的是对象。 通过对象的组合创建对象【？？？】 用途：创建产品家族或把集合所制造的相关产品。   《Head First 设计模式》里的比较图  工厂方法模式  工厂方法模式  抽象工厂模式  抽象工厂模式      5中的定义可扩展的工厂不理解？哪里不安全？类型转换？哪里灵活？怎么灵活？  y. 拓展  依赖倒置原则：要依赖抽象，不要依赖具体的类。 这个原则说明了：不能让高层组件依赖低层组件，而且，不管是高层还是低层组件，都应该依赖抽象。 单件模式 工厂方法模式 如果有多个可能的产品系列，具体工厂也可以使用原型模式来实现。  z. 参考  《Head First设计模式》p144页开始  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/compare_method_abstract2_hub21b9d9ba8c98aea8f5b827a3dfb3432_245501_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 抽象工厂模式"},{"content":"模板方法模式——用继承改变算法  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念  定义/意图：定义一个操作的算法的骨架，将一些步骤延迟到子类中。模板方法模式使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 别名：无 类图：  类图  出场嘉宾  AbstrackClass：抽象类  定义抽象的原语操作(primitive operation)，各个步骤的具体实现交给子类。 实现一个模板方法，定义一个算法的步骤。 实现不变的部分。   ConcreteClass：具体类  实现原语操作，完成特定步骤的具体实现。 实现变动的部分。     协作/工作流程  AbstrackClass实现不变的部分（或骨架）； ConcreteClass实现变动的部分； AbstrackClass 和 ConcreteClass 实现整个操作/算法。   效果  模板方法是一种代码复用的基本技术。在类库中尤为重要。 模板方法导致一种反向的控制结构——\u0026ldquo;好莱坞原则\u0026rdquo;——即\u0026quot;别找我们，我们会找你\u0026quot;——父类调用子类的操作。 模板方法可能调用下列类型的操作：  具体的操作：ConcreteClass或对客户类的操作。 具体的AbstractClass的操作：即通常对子类有用的操作。 原语操作：即抽象操作 工厂方法 钩子操作(hook operation)：提供缺省的行为，子类可在必要时进行扩展。      2. 优缺点是什么？ 2.1 优点  提供更好的扩展性； 减少重复代码。  2.2 缺点  每个算法都要定义一个子类。  3. 使用场景是什么？  一个算法，多数操作相同，少数不同。  一次性实现一个算法不变的部分，并将可变的行为留给子类来实现。 子类中公共行为应该被提取到父类中，避免代码重复。   需要控制子类扩展。在某些特定点调用\u0026quot;hook\u0026quot;操作，允许在这些点进行扩展。  4. 注意  需要注意的实现问题：  使用访问控制。  C++中，模板方法调用的原语操作可以被定义为保护成员，保证它们只被模板方法调用 C++中，必须重定义的原语操作需定义为纯虚函数。（重定义：父类提供接口，子类实现。） C++中，模板方法不需重定义，不需定义为纯虚函数。   尽量减少原语操作。  减少子类需要重定义的原语操作。原语操作越多，子类实现越冗长。   命名约定：给应被重定义的操作加上特定前缀。    5. 应用实例？    w. 待办    x. 疑问  策略模式使用委托，委托是指？ConcreteStrategy委托给Context？  y. 拓展  相关模式：  工厂模式：可被模板方法调用。 策略模式：使用委托来改变整个算法。（模板方法使用继承来改变算法的一部分）  委托【？？？】      z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/ClassDiagram_hub9d6bae174a5f1cfb65be2d66f40f19e_28066_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 模板方法模式"},{"content":"状态(State)模式  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念  定义/意图：允许一个对象再起内部状态改变时改变它的行为。对象看起来似乎修改了它的类。 别名：状态对象(Objects for States) 类图：  类图  出场嘉宾  Context: 上下文、环境  定义客户感兴趣的接口。 维护一个ConcreteState子类的实例，表示当前状态。   State：状态，抽象类/接口  定义一个接口，以封装与Context的特定状态相关的行为。   ConcreteState：具体状态  定义一个具体的状态，实现一个与Context的一个状态的相关的行为。     协作/工作流程  Context保存一个ConcreteState对象，表示当前状态。 Context将与状态相关的请求委托给当前的ConcreteState对象处理。 Context可将自身作为一个参数传递给处理请求的状态对象。 Context是客户使用的主要接口。 Context和ConcreteState都可以决定哪一个状态是后继状态。    2. 优缺点是什么？ 2.1 优点  状态模式将特定状态相关的行为局部化，并且将不同状态的行为分割开。 状态模式使得状态转换显式化。【？？？】  为不同的状态引入独立的对象使得转换变得更加明确。   状态对象可被共享：可被多个Context共享。  2.2 缺点  增加了对象的数目。 C++里面容易导致头文件循环引用。解决方法，见C++示例的TCPState.h文件  3. 使用场景是什么？  一个对象的行为取决于它的状态，并且他必须在运行时刻根据状态改变它的行为。 一个操作中含有庞大/多分支的条件语句，且这些分支依赖于该对象的状态。  状态模式将每一个条件分支放入一个独立的类中。    4. 注意  实现时需要考虑的问题：  谁定义状态转换：Context还是ConcreteState？  Context可以实现，但是用ConcreteState通常更灵活更合适。（需要Context增加接口，供ConcreteState改变状态）   基于表的另一种方法。  详见四人帮《设计模式》204页。   创建和销毁ConcreteState对象。  提前创建，不销毁。  状态改变频繁，则考虑此方法。   需要时创建，不需要时销毁。  当将要进入的状态在运行时是不可知的，并且上下文不经常改变状态，则考虑此方法。 当ConcreteState对象存储大量信息，且不常改变状态，考虑此方法。     使用动态继承。【？？？】    5. 应用实例？    w. 待办    x. 疑问  转换显式化，如何才算显式化？ 什么是动态继承？  y. 拓展  相关模式：  Singleton：单例模式，状态对象通常是单例模式。 Flyweight：享元模式。解释何时、怎样共享状态对象。    z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/ClassDiagram_huc03f68792e55e175b4455a14e3ef74ad_21728_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 状态模式"},{"content":"策略模式——用委托改变算法  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念  定义/意图：  定义一系列算法，把它们一个个封装起来，并使它们可以相互替换。 本模式使得算法可以独立于使用它的客户而变化。   别名：Policy（政策） 类图：  类图  出场嘉宾  Strategy：策略，定义算法的公共接口。  Context使用这个接口来调用某个ConcreteStrategy定义的算法。   ConcreteStrategy：具体策略，实现具体的算法。 Context：上下文  用已成而ConcreteStrategy对象来配置；【？？？】 维护一个对Strategy对象的引用； 可定义一个接口来让Strategy访问它的数据。     协作/工作流程  Strategy和Context相互作用，以实现选定的算法。  Context将算法需要的参数传给Strategy，或 Context将自己作为参数传给Strategy。   Context将它的客户的请求转发给它的Strategy。  客户通常创建并传递一个ConcreteStrategy对象给该Context（客户仅与Context交互）。 客户通常可以选择一系列的ConcreteStrategy。      2. 优缺点是什么？ 2.1 优点  Strategy类层次为Context定义了一系列可供重用的算法/行为。 提供一个代替继承的方法。  继承提供了另一种支持多种算法/行为的方法——直接生成Context的子类，但提供不同的行为。   消除了一些条件语句（客户进行指定，不需要switch和if） 可提供相同行为的不同实现。  2.2 缺点  客户必须了解各种ConcreteStrategy。 Strategy和Context之间的通信开销——某些ConcreteStrategy可能永远用不上某些参数。 增加了对象的数目。   3. 使用场景是什么？  许多相关的类仅仅是行为异。\u0026ldquo;策略\u0026quot;提供了一种用多个行为中的一个来配置一个类的方法。 需要使用一个算法的不同变体。 算法使用客户端不应该知道的数据。 一个类定义类多种行为，并且这些行为在这个类的操作中已多个条件语句的形式出现。  将相关的条件分支移入它们各自的Strategy类中以代替这些条件语句。    4. 注意  需要考虑的实现问题：  Strategy和Context接口必须使得ConcreteStrategy能够有效访问它所需要的Context中的任何数据。  方法一：Context将数据作为参数传递给Strategy  缺点：Context可能发送一些Stratege不需要的数据。 优点：Context和Strategy解耦。   方法二：Context将自身作为参数传递给Strategy，Strategy再显式想Context请求数据或者存储Context的一个引用（这样就根本不需要再传递任何东西）  缺点：Context和Strategy紧密耦合。 优点：传递数据少。     使Strategy对象成为可选的。  如果想要不使用额外的Strategy对象的情况下，Context仍有意义的话，可以：  访问某个Strategy对象前，先检查是否存在，存在就使用，不存在就使用默认（缺省）的行为。 优点：用户只在需要时，才需要了解ConcreteStrategy对象。     C++中，只有满足下面的条件才能将Strategy作为模板参数：  1.可以在编译时选择Strategy； 2.它不需要在运行时改变 示例：  // Context template \u0026lt;class AStrategy\u0026gt; class Context { void Operation() { theStrategy.DoAlgorithm(); } private: AStrategy theStrategy; } // Strategy class MyStrategy { public: void DoAlgorithm(); } Context\u0026lt;MyStrategy\u0026gt; aContext;     5. 应用实例？    w. 待办    x. 疑问    y. 拓展    z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/ClassDiagram_hu771149e49c462b26432a5b0e1acd417c_27093_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 策略模式"},{"content":"简单工厂模式  别称：静态工厂方法 简单工厂并不是一种模式，而是一种编程习惯。——《Head First设计模式》 代码比较简单，就不写代码的Readme了  1. 基础概念  定义/意图：无 类图：  类图  出场嘉宾  产品/Product：产品，抽象类（或接口） 具体产品/Concrete Product：具体产品，继承/实现Product 工厂/Creator：工厂，用于生产Product    2. 解决什么问题？如何解决？ 无\n3. 优缺点是什么？ 3.1 优点  把变化集中到一块，易于管理。 \u0026ldquo;消费对象\u0026quot;不需要直接创建具体产品(Concrete Product)，把对象创建和使用分开。  3.2 缺点  工厂类集中了多个其他类，违反了高内聚责任分配原则。【？！】 有新的具体产品时，需要修改代码，不符合开闭原则。 随着具体产品增加，判断添加回变多，维护回变难。   这些缺点在工厂方法模式中得到解决。\n 4. 使用场景是什么？  工厂类负责创建的对象固定、较小。（变动不频繁） 对创建对象的逻辑不关心。  5. 注意  由于简单工厂模式容易违反高内聚责任分配原则，因此一般只在较简单的情况下应用。  6. 应用实例？  无  x. 疑问    y. 拓展  工厂方法模式 抽象工厂模式  z. 参考  《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/ClassDiagram_hu9641347351fb55904fe95979a1ea9ec9_12938_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 简单工厂模式"},{"content":"组合模式  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念  定义/意图：将对象组合成树形结构以表示部分-整体的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 别名：Composite 类图1：  类图  类图2：  类图  典型对象图：  对象图  出场嘉宾  Component: 组合  为组合中的对象声明接口。 在适当情况下，实现公共接口的缺省行为。 声明一个接口用于访问和管理Component组件。   Leaf: 叶节点，叶子部件  在组合中表示叶节点对象，叶节点没有子节点。 定义节点对象的具体的行为。   Composite: 组合部件，有孩子的部件。  定义有孩子节点的节点的行为。 存储孩子节点。 在Component接口中实现与子节点有关的操作。   Client：  通过Component接口操纵组合部件的对象。     协作/工作流程  Client使用Component接口与组合结构中的对象(Composite/Leaf)进行交互。 如果接收者是叶节点，则直接处理请求。 如果接收者是Composite，通常转发请求给它的子部件，在转发之前或之后，可能执行一些辅助操作。    2. 优缺点是什么？ 2.1 优点  定义包含基本对象和组合对象的类层次结构。  基本对象可以被组合成更复杂的组合对象 组合对象可以被再组合。   简化客户代码。  客户可以统一地使用基本对象和组合对象。   更容易增加新类型的组件。  2.2 缺点  使得设计变得更一般化。  更容易增加新组件的同时，也使得限制组合中的组件变得困难。 有时可能会希望一个组合只能有某些特定的组件。使用Composite时，不能依赖类型系统施加这些约束。    3. 使用场景是什么？  想表示对象的部分-整体层次结构。 希望用户忽略组合对象与单个对象的不同。统一地使用组合结构中的所有对象。  4. 注意  实现组合模式需要考虑的问题：  显式的父组件引用。  保持子组件都父组件的引用能简化组合结构的遍历和管理。 通常在Component类中定义父组件引用。   共享组件。  可以减少对存储的需求。 当一个组件只有一个父组件时，很难共享组件。【？？？】   最大化Component接口。  组合模式的目的之一是：使得用户不知道他们正在使用的是Leaf还是Composite。   声明管理子组件的操作。  是在Component中进行声明，并使得对Leaf也有意义呢？还是只在Composite中声明？  需要在安全性和透明性之间做出权衡：  在Component中声明，会具有更好的透明性——Leaf和Composite有一致的接口。 在Composite中声明，会具有更好的安全性——在类似C++静态类型语言中，任何对Leaf的不必要操作(Remove/Add)，都能在编译时被发现。       Component是否应该事先一个Component列表？  有时候可能想要在Component类中将子节点定义为一个实例变量，方便访问和管理这些子节点。但对于叶节点，会造成空间浪费。   子组件排序。 使用高速缓冲存储改善性能。  Composite可以缓冲存储实际结果。   应该由谁来删除Component。  当一个Composite被销毁时，通常由此Composite负责删除其子节点。   存储组件最好用哪一种数据结构？  存储子节点可以用：链表，数组、树、Hash表。选取取决于效率。      5. 应用实例？    w. 待办    x. 疑问    y. 拓展  相关模式：  装饰者模式(Decorator)：常和组合模式一起使用。当装饰和组合一起使用时，它们通常由一个公共的父类。 Flyweight: 让你共享组件，但不能再引用它们的父组件。 迭代器模式(Iterator): 可以用来遍历Composite。 访问者模式(Visitor): 将本来应该分布在Composite和Leaf类中的操作和行为局部化。【？？？】    z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/ObjectDiagram_hu6b5056fb0e38f8f68f1de8ab5ac4a88a_19258_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 组合模式"},{"content":"装饰者模式——不改变接口，但加入责任 1. 基础概念   定义：动态地给一个对象添加一些额外的职责。\n 注意是针对对象而不是类    类图：  类图 \n  出场嘉宾：\n [基础]组件(Conponent): 被装饰者，定义一个对象接口（Java：接口，C++：抽象类）； 具体[基础]组件(Concrete Conponent): 定义一个具体的基础组件对象，可以给这个对象添加一些职责（装饰该对象）。 装饰者(Decorator): 维持一个指向组件对象的指针，并定义一个与组件接口一致的接口。(指针是为了知道所修饰的是什么) 具体装饰者(Concrete Decorator): 可以向具体组件添加职责（修饰）。    2. 解决什么问题？如何解决？  解决用继承给对象添加功能不够灵活的问题。  通常拓展一个类都是用继承的方法，这是静态拓展，随着拓展增多，子类会膨胀。   解决方法：具体组件和修饰者都继承自公共的类，使一个对象能装饰另一个对象。  3. 优缺点是什么？ 3.1 优点  拓展功能时，提供比继承更有弹性的解决方案。（可增加、删除职责）  比静态继承更灵活。   可通过动态的方式在运行时选择不同的具体装饰类，实现不同的行为。 可以对一个对象进行多次修饰（甚至多次相同的修饰）。 符合开闭原则，具体组件和具体修饰者可以独立变化，用户根据需要添加组件或装饰者，原代码不需修改。 装饰者可以在所委托的装饰者行为之前或之后加上自己的行为，以达到特定的目的  3.2 缺点  可能有许多小对象，排错难度加大、代码阅读难度加大。 可能不同的东西，继承自一个公共类。（个人理解）  4. 使用场景是什么？  在不影响其他对象的情况下，已动态、透明的方式给单个对象添加职责。 处理那些可以撤销的职责。  怎么实现撤销？？？   当不能使用子类/继承的方法进行扩充时。  情况一：类定义被隐藏，因此无法用于生成子类。 情况二：有大量独立的扩展，为支持每一种组合将产生大量子类。（使子类书目爆炸性增长）    5. 注意  1）接口一致性：必须有一个公共的父类。 2）省略抽象的装饰者类：当仅需添加一个职责时，没有必要定义抽象的装饰者类。 3）保持组件(Component)类的简单性：  它是公共接口，保持简单很重要； 它应集中定义接口，不应存储数据 赋予太多功能会使子类存在不需要的功能的可能性大大增加。   4）改变对象外壳与改变对象内核：可以将Decorator看做是对象的外壳。【内核\u0026hellip;: Strategy策略模式】  6. 应用实例？  星巴兹饮料调配——《Head First设计模式》 游戏里面人物捏脸？！ 单个主体组件+多个其他附属组件 这类的东西（人+衣服、首饰？蛋糕+蜡烛、碟子？）。  x. 疑问  如何实现撤销一个对象的职责/功能？ 如何优雅地释放内存？（具体装饰者一个一个被new出来，但是如何释放呢？）  y. 拓展  模式简化：  简化方式一：去除组件(Conponent)——只有一个具体组件时，则直接让装饰者继承自这个具体组件。 简化方式二：去除修饰者(Decorator)——只有一个具体修饰者时，则让具体修饰者继承自组件(Conponent)。   C++编程规则：  在多态基类中，定义析构函数为virtual。 使基类的析构函数为public + virtual或者 protected + nonvirtual；   策略模式：？？？  z. 参考  《Head First设计模式》 《设计模式：可复用面向对象软件的基础》   虚析构函数    ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/xingbazi-classdiagram_hu1f629ad2e90a079156899ab8241b7de5_156283_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 装饰者模式"},{"content":"观察者模式 1. 基础概念  定义：定义了对象之间的一对多依赖，这样依赖，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 类图：  类图  出场嘉宾  主题(Subject)：出版者、被观察者、 观察者(Observer)：订阅者、 具体主题(Concrete Subject): 对主题的实现 具体观察者(Concrete Observer): 对观察者的实现     观察者模式就和报纸订阅/取消订阅、邮件订阅/取消订阅类似。 出版者（主题）+ 订阅者（观察者）=观察者模式\n 2. 解决什么问题？如何解决？  （易用、低耦合、高度协作）解决一个对象状态改变通知其他多个对象的问题。  3. 优缺点是什么？ 3.1 优点  支持一对多通信。 符合开闭原则。【疑问？？？】 在主题和观察者之间建立一个抽象的耦合。【抽象的耦合？？？】  3.2 缺点  当一个主题的观察者过多时，通知会比较耗费时间。 当 主题 和 观察者有循环依赖时，会导致循环调用。 观察者无法知道变化过程，只能知道变化结果。  4. 使用场景是什么？  一个对象要通知其他[多个]对象自己改变时（可能并不知道这些对象是谁）； 一个对象要导致其他[多个]对象自己改变时； 需要创建触发链时；  5. 应用实例？  天气预报服务器数据更新，客户端实时展示更新后的数据。（《Head First设计模式》示例） 电子商务网站向多个用户推送商品信息。  x. 疑问  观察者如何对感兴趣的事情进行订阅、取消订阅？  主题提供注册接口，以供观察者对主题进行订阅； 主题提供取消订阅接口，以供观察者对主题进行取消订阅；   主题如何存储观察者？  可存储在数组或其他数据结构中。   主题如何通知观察者？  遍历所有观察者，一个一个进行通知。   mqtt是否也是观察者模式的一种实现？ 怎么理解开闭原则，在本模式中，哪部分符合开闭原则？  开闭原则是针对类来说的。    y. 拓展  观察者模式有：推和拉两种模式。  推：主题将变更推送给观察者； 拉：主题通知观察者已变更，变更内容由观察者主动获取。（主题提供获取接口）   开闭原则：对修改关闭，对拓展开放  z. 参考  《Head First设计模式》 http://www.runoob.com/design-pattern/observer-pattern.html https://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/observer.html  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/classdiagram_hua4fa13d1bdf22ddd96376562d855ae4a_134997_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 观察者模式"},{"content":"迭代器模式——提供不暴露聚合对象内部表示的访问聚合对象各个元素的方法  目标：  初接触此模式时，熟悉最常用的使用方式。 有更深的理解后，再研究其他使用方法。    1. 基础概念  定义/意图：提供一种方法顺序访问一个聚合对象中各个元素，而又不需暴露改对象的内部表示。 别名：游标（Cursor） 分类：对象行为型模式 类图：  类图  出场嘉宾  Iterator: 迭代器  定义访问和遍历元素的接口。   ConcreteIterator: 具体迭代器  实现对具体聚合对象的迭代器接口。 对聚合对象遍历时，跟踪当前位置。   Aggregate：聚合  定义创建相应迭代器对象的接口。   ConcreteAggregate：具体聚合  实现创建相应迭代器的接口 返回ConcreteIterator的一个适当实例。     协作/工作流程  通过 ConcreteAggregate 创建 ConcreteIterator； 通过 ConcreteIterator 访问/遍历 ConcreteAggregate。    2. 优缺点是什么？ 2.1 优点  支持以不同的方式遍历一个聚合。  复杂的聚合可用多种方式进行遍历。   迭代器简化了聚合的接口。  用了迭代器的遍历接口，聚合就不需要提供遍历接口，于是就简化了聚合的接口。   同一个聚合上可以有多个聚合。  每个迭代器保持自己的遍历状态，因此可以同时进行多个遍历。    2.2 缺点    3. 使用场景是什么？  需要操作聚合对象的时候。  4. 注意  实现需要注意的问题：  谁控制该迭代？迭代器还是客户？  由客户控制迭代时，该迭代器称为外部迭代器。客户主动推动遍历的步伐，显式向迭代器请求下一个元素。 由迭代器控制迭代时，该迭代器称为内部迭代器。客户提交一个待执行操作，迭代器对聚合的内阁元素都实施该操作。 外部迭代器比内部迭代器更灵活。   谁定义遍历算法？  迭代器不是唯一可定义遍历算法的地方。 聚合本身也可以定义遍历算法，并在遍历过程中用迭代器来存储当前迭代的状态。这种迭代器被称为游标(cursor), 因为它仅用来指示当前位置。   迭代器健壮程度如何？  遍历一个聚合时更改这个聚合是危险的。 一个健壮的迭代器保证插入和删除操作不会干扰遍历，且不需要拷贝该聚合。   附加的迭代器操作。  最小接口：First、Next、IsDone、CurrentItem 附加操作：SkipTo、Previous等   在C++中使用多态的迭代器。  代价：要求用一个工厂方法动态地分配迭代器对象。 仅当必须多态时，才使用！ 另一个缺点：客户必须负责删除它们。（这里常常出现bug）   迭代器的特权访问。  迭代器可被看为聚合的一个扩展，迭代器和聚合紧密耦合。   用于复合对象的迭代器。【？？？】 空迭代器——退化的迭代器。  有助于处理边界条件。 常用于遍历树形结构的聚合。      w. 待办    x. 疑问    y. 拓展  相关模式  Composite: 组成模式 Factory Method: 工厂方法模式 Memento：备忘录模式    z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/ClassDiagram_hu897b61bb969f01c171036b03c5d31606_29647_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 迭代器模式"},{"content":"适配器模式——将一个接口转换成另一个接口  目标：  初接触此模式时，熟悉最常用的使用方式。如，对象适配器。 有更深的理解后，再研究其他使用方法。如，类适配器和双向适配器    1. 基础概念  定义/意图：  将一个类的接口转换成另一个接口。适配器(Adapter)模式使得原来接口不兼容的类可以一起工作。 把一个东西，伪装成另一个东西！   别名：包装器（Wrapper） 类图1：类适配器类图（使用多重继承对一个接口与另一个接口进行匹配）  类图  类图2：对象适配器类图  类图  出场嘉宾  Target: 定义Client使用的与特定领域相关的接口。 Client：与符合Target接口的对象协同。 Adaptee：已存在的接口，被适配者。 Adapter：对Adaptee接口与Target接口进行适配，适配器。   协作/工作流程  Client在Adapter实例上调用一些操作。 Adapter调用Adaptee的操作，以实现用户请求。    2. 解决什么问题？如何解决？  在不改变原有Target和Adaptee代码情况下，对Adaptee用Target的方式访问。 解决方法：在两者之间添加一个中间层——Adapter。  3. 优缺点是什么？ 3.1 类适配器的优点  不需要重新实现整个被适配者类只实现部分，因为Adapter是Adaptee的子类。 仅引入了一个对象，不需要额外的指针间接得到adaptee。  3.2 类适配器的缺点  只能适配某个特定的类，不能适配其子类。【疑惑？！】  3.3 对象适配器的优点  更有弹性，使用组合（引用另一个类或其子类），支持适配某个类及其子类。  3.4 对象适配器的缺点  重定义(新增)Adaptee子类的行为变得比较困难。解决方法：直接引用子类对象。  4. 使用场景是什么？  希望使用一个已存在的类，但是它的接口不符合要求。 想要创建一个可以复用的类，该类可以与其他不想管的类或不可预见的类（接口不一定兼容）协同工作。【？？？】 （仅适用于对象适配器）想要使用一些已经存在的子类，但不可能对每个子类都进行类似的匹配。对象适配器可以适配它的父类接口。【？？？】  5. 注意  使用适配器模式时需要考虑的其他一些因素：  Adapter的匹配程度。  适配器的工作量取决于Target接口与Adaptee接口的相似程度。   可插入的Adapter。【不理解？？？】  将接口匹配【？？？】构建为一个类，就不需要嘉定对其他的类可见的是一个相同的接口。 接口匹配使得我们可以将自己的类加入到一些现有的系统中去。   使用双向适配器提供透明操作【？？？】  当两个不同的客户需要用不同的方式查看同一个对象时，双向适配器尤其有用。  双向适配器   Adapter是两个类的子类，使得两个两个类的相关接口可以相互匹配。【疑惑？？？】 有更深理解后，在图里各个类中加入相关操作，以更清楚表达意图。       使用适配器的一个潜在问题是：他们不对所有的客户都透明。 实现时，需要注意以下的一些问题：  使用C++实现适配器类时，Adapter类应该用公共方式继承Target类、用私有方法继承Adaptee类。  因此，Adapter类应该是Target类的子类型，但不是Adaptee类的子类型。   可插入的适配器。以书本中示例有三种实现方法：（具体见：《设计模式》95页）  使用抽象操作。【？？？】 使用代理对象。【？？？】 参数化的适配器。【？？？】      6. 应用实例？    w. 待办  (DONE!)对象适配器——C++示例 (DONE!)对象适配器-Java示例 类适配器——C++示例 类适配器——Java示例  x. 疑问  程序透明性？ 双向适配器？ 可插入的适配器？  y. 拓展  桥接模式(Bridge)和对象适配器(Adapter)的结构类似，但是出发点不同。  桥接模式(Bridge): 将接口部分和实现部分分离，从而对他们可以较为容易地相对独立的加以改变。 对象适配器(Adapter): 把一个对象行为变为另一个。   相关模式：  桥接模式(Bridge) 装饰者模式(Decorator): 增强对象的功能但不改变原有对象的接口。（因此，程序透明性比适配器好） 代理模式(Proxy): 不改变接口情况下，为另一个对象定义一个代理。    z. 参考  《设计模式：可复用面向对象软件的基础》 《Head First设计模式》  ","date":"2022-10-16T12:23:30-03:00","image":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/ClassDiagram_Class_Adapter_hu438732146c882695e65f7eefab3dcf1f_25917_120x120_fill_box_smart1_3.png","permalink":"https://isshe.site/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"设计模式 —— 适配器模式"},{"content":"2021 年国家公祭日有感 我是一个南方人，一直以来，都不太愿意去了解这些同胞受难的事情，不愿意面对；同时，也不知道该以什么样的心情去面对。\n我不确定一个人、一个军队，在祖国强盛、自己满怀荣光的情况下，如何能够做出这样的事情。 一个人为之，或许可以称之为堕落；一个军队，大概是集体兽化了吧。\n何为人？这个提问出自《一人之下》。\n“张三”说：法律是道德的最低标准，我们不应该以不违法来标榜自己。 我也是这么认为的。 但是对于我个人来说，我希望我更有原则，更加旗帜鲜明：\n 旗帜鲜明地表达自己的立场——热爱自己、热爱家人、热爱祖国、热爱这片土地； 旗帜鲜明地反对屠杀之类禽兽行为；  牢记历史，热爱和平。\n","date":"2021-12-25T02:22:19-04:00","image":"https://isshe.site/p/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F-%E5%9B%BD%E5%AE%B6%E5%85%AC%E7%A5%AD%E6%97%A5%E6%9C%89%E6%84%9F/iscream_hub8c91bfe3ab4a8b0a897e9f951468ee1_48729_120x120_fill_q75_box_smart1.jpg","permalink":"https://isshe.site/p/%E4%B8%AA%E4%BA%BA%E6%84%9F%E6%82%9F-%E5%9B%BD%E5%AE%B6%E5%85%AC%E7%A5%AD%E6%97%A5%E6%9C%89%E6%84%9F/","title":"个人感悟 —— 国家公祭日有感"}]